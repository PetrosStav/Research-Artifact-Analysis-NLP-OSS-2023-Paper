[
 {
  "Snippet": "We conducted experiments using the latest version of our custom-built <m>simulation software</m>. The software has been extensively used in previous studies and proven to be reliable.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the latest version of our custom-built simulation <m>software</m>. The software has been extensively used in previous studies and proven to be reliable.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the latest version of our custom-built simulation software. The <m>software</m> has been extensively used in previous studies and proven to be reliable.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the latest version of our custom-built simulation software. The software has been extensively used in previous <m>studies</m> and proven to be reliable.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To process the <m>data</m>, we employed the widely-used Python programming language. The code snippets can be found in the supplementary material.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To process the data, we employed the widely-used <m>Python</m> programming language. The code snippets can be found in the supplementary material.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To process the data, we employed the widely-used Python programming language. The <m>code</m> snippets can be found in the supplementary material.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the popular <m>Matplotlib</m> library for visualizing the results. The code for generating the plots can be found in the GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Matplotlib",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the popular Matplotlib <m>library</m> for visualizing the results. The code for generating the plots can be found in the GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Matplotlib",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the popular Matplotlib library for visualizing the results. The <m>code</m> for generating the plots can be found in the GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the popular Matplotlib library for visualizing the results. The code for generating the plots can be found in the <m>GitHub</m> repository.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the popular Matplotlib library for visualizing the results. The code for generating the plots can be found in the GitHub <m>repository</m>.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the <m>TensorFlow</m> framework (version 2.5.0). The code implementation can be found in the project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the TensorFlow <m>framework</m> (version 2.5.0). The code implementation can be found in the project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the TensorFlow framework (version 2.5.0). The <m>code</m> implementation can be found in the project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the TensorFlow framework (version 2.5.0). The code implementation can be found in the project's <m>GitHub</m> repository.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the TensorFlow framework (version 2.5.0). The code implementation can be found in the project's GitHub <m>repository</m>.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the <m>scikit-learn</m> library for performing the machine learning tasks. The code snippets can be found in the appendix of the paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the scikit-learn <m>library</m> for performing the machine learning tasks. The code snippets can be found in the appendix of the paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the scikit-learn library for performing the machine learning tasks. The <m>code</m> snippets can be found in the appendix of the paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the power of the <m>Apache Spark</m> framework for distributed data processing. The code implementation is available on our project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Apache Spark",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the power of the Apache Spark <m>framework</m> for distributed data processing. The code implementation is available on our project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Apache Spark",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the power of the Apache Spark framework for distributed <m>data</m> processing. The code implementation is available on our project's GitHub repository.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We leveraged the power of the Apache Spark framework for distributed data processing. The <m>code</m> implementation is available on our project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the power of the Apache Spark framework for distributed data processing. The code implementation is available on our project's <m>GitHub</m> repository.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the power of the Apache Spark framework for distributed data processing. The code implementation is available on our project's GitHub <m>repository</m>.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The analysis was performed using the <m>IBM SPSS Statistics</m> software. The detailed steps can be found in the supplementary material.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "IBM SPSS Statistics",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The analysis was performed using the IBM SPSS Statistics <m>software</m>. The detailed steps can be found in the supplementary material.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "IBM SPSS Statistics",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>NLTK</m> library for natural language processing tasks. The code snippets are provided in the code repository accompanying this paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the NLTK <m>library</m> for natural language processing tasks. The code snippets are provided in the code repository accompanying this paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the NLTK library for natural language processing tasks. The <m>code</m> snippets are provided in the code repository accompanying this paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the NLTK library for natural language processing tasks. The code snippets are provided in the <m>code</m> repository accompanying this paper.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We employed the NLTK library for natural language processing tasks. The code snippets are provided in the code <m>repository</m> accompanying this paper.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To preprocess the <m>data</m>, we used the Pandas library. The code for data preprocessing is available on GitHub.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To preprocess the data, we used the <m>Pandas</m> library. The code for data preprocessing is available on GitHub.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To preprocess the data, we used the Pandas <m>library</m>. The code for data preprocessing is available on GitHub.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To preprocess the data, we used the Pandas library. The <m>code</m> for data preprocessing is available on GitHub.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To preprocess the data, we used the Pandas library. The code for <m>data</m> preprocessing is available on GitHub.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To preprocess the data, we used the Pandas library. The code for data preprocessing is available on <m>GitHub</m>.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "Github",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the <m>Keras</m> deep learning framework for training our neural network models. The code implementation can be found in the project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Keras deep learning <m>framework</m> for training our neural network models. The code implementation can be found in the project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Keras deep learning framework for training our neural network <m>models</m>. The code implementation can be found in the project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Keras deep learning framework for training our neural network models. The <m>code</m> implementation can be found in the project's GitHub repository.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Keras deep learning framework for training our neural network models. The code implementation can be found in the project's <m>GitHub</m> repository.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Keras deep learning framework for training our neural network models. The code implementation can be found in the project's GitHub <m>repository</m>.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research project utilized the advanced <m>simulation software</m> developed in-house. The software incorporates cutting-edge algorithms and models for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research project utilized the advanced simulation <m>software</m> developed in-house. The software incorporates cutting-edge algorithms and models for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research project utilized the advanced simulation software developed in-house. The <m>software</m> incorporates cutting-edge algorithms and models for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research project utilized the advanced simulation software developed in-house. The software incorporates cutting-edge <m>algorithms</m> and models for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Our research project utilized the advanced simulation software developed in-house. The software incorporates cutting-edge algorithms and <m>models</m> for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel <m>image</m> processing software for our study. The software provides advanced algorithms for analyzing and enhancing images.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We developed a novel <m>image processing software</m> for our study. The software provides advanced algorithms for analyzing and enhancing images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel image processing <m>software</m> for our study. The software provides advanced algorithms for analyzing and enhancing images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel image processing software for our study. The <m>software</m> provides advanced algorithms for analyzing and enhancing images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel image processing software for our study. The software provides advanced <m>algorithms</m> for analyzing and enhancing images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel image processing software for our study. The software provides advanced algorithms for analyzing and enhancing <m>images</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To perform the experiments, we used the widely-used <m>simulation software</m> called SimulateX. The software is known for its accurate modeling capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulateX",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To perform the experiments, we used the widely-used simulation <m>software</m> called SimulateX. The software is known for its accurate modeling capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulateX",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To perform the experiments, we used the widely-used simulation software called <m>SimulateX</m>. The software is known for its accurate modeling capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulateX",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To perform the experiments, we used the widely-used simulation software called SimulateX. The <m>software</m> is known for its accurate modeling capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulateX",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The research findings were obtained using the proprietary <m>data</m> analysis software developed by our team. The software incorporates advanced statistical algorithms.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The research findings were obtained using the proprietary <m>data analysis software</m> developed by our team. The software incorporates advanced statistical algorithms.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The research findings were obtained using the proprietary data analysis <m>software</m> developed by our team. The software incorporates advanced statistical algorithms.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The research findings were obtained using the proprietary data analysis software developed by our team. The <m>software</m> incorporates advanced statistical algorithms.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The research findings were obtained using the proprietary data analysis software developed by our team. The software incorporates advanced statistical <m>algorithms</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art <m>simulation software</m> called SimuPro for our experiments. The software provides accurate modeling and simulation capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuPro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art simulation <m>software</m> called SimuPro for our experiments. The software provides accurate modeling and simulation capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuPro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art simulation software called <m>SimuPro</m> for our experiments. The software provides accurate modeling and simulation capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuPro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art simulation software called SimuPro for our experiments. The <m>software</m> provides accurate modeling and simulation capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuPro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the experiments, we employed the widely-used <m>data analysis software</m> called AnalyzePro. The software offers advanced statistical analysis features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "AnalyzePro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the experiments, we employed the widely-used <m>data</m> analysis software called AnalyzePro. The software offers advanced statistical analysis features.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "For the experiments, we employed the widely-used data analysis <m>software</m> called AnalyzePro. The software offers advanced statistical analysis features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "AnalyzePro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the experiments, we employed the widely-used data analysis software called <m>AnalyzePro</m>. The software offers advanced statistical analysis features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "AnalyzePro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the experiments, we employed the widely-used data analysis software called AnalyzePro. The <m>software</m> offers advanced statistical analysis features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "AnalyzePro",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The research project utilized the custom-built <m>simulation software</m> developed by our team. The software incorporates specialized algorithms for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The research project utilized the custom-built simulation <m>software</m> developed by our team. The software incorporates specialized algorithms for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The research project utilized the custom-built simulation software developed by our team. The <m>software</m> incorporates specialized algorithms for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The research project utilized the custom-built simulation software developed by our team. The software incorporates specialized <m>algorithms</m> for accurate simulations.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We developed a novel <m>image</m> recognition software for our study. The software utilizes deep learning algorithms for accurate image classification.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We developed a novel image recognition software for our study. The software utilizes deep learning algorithms for accurate <m>image</m> classification.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We developed a novel <m>image recognition software</m> for our study. The software utilizes deep learning algorithms for accurate image classification.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel image recognition <m>software</m> for our study. The software utilizes deep learning algorithms for accurate image classification.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel image recognition software for our study. The <m>software</m> utilizes deep learning algorithms for accurate image classification.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel image recognition software for our study. The software utilizes deep learning <m>algorithms</m> for accurate image classification.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "To analyze the experimental <m>data</m>, we used the data processing software developed by our research group. The software provides efficient data manipulation and analysis capabilities.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To analyze the experimental data, we used the <m>data</m> processing software developed by our research group. The software provides efficient data manipulation and analysis capabilities.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To analyze the experimental data, we used the data processing <m>software</m> developed by our research group. The software provides efficient data manipulation and analysis capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To analyze the experimental data, we used the <m>data processing software</m> developed by our research group. The software provides efficient data manipulation and analysis capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To analyze the experimental data, we used the data processing software developed by our research group. The <m>software</m> provides efficient data manipulation and analysis capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To analyze the experimental data, we used the data processing software developed by our research group. The software provides efficient <m>data</m> manipulation and analysis capabilities.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We employed the widely-used <m>simulation software</m> called SimuTech for our experiments. The software offers advanced modeling and simulation features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuTech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the widely-used simulation <m>software</m> called SimuTech for our experiments. The software offers advanced modeling and simulation features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuTech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the widely-used simulation software called <m>SimuTech</m> for our experiments. The software offers advanced modeling and simulation features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuTech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the widely-used simulation software called SimuTech for our experiments. The <m>software</m> offers advanced modeling and simulation features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuTech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected a new <m>dataset</m> of scientific articles related to climate change. The dataset contains 1,000 articles from various journals. Access to the dataset can be requested by contacting the authors.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of scientific <m>articles</m> related to climate change. The dataset contains 1,000 articles from various journals. Access to the dataset can be requested by contacting the authors.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of scientific articles related to climate change. The <m>dataset</m> contains 1,000 articles from various journals. Access to the dataset can be requested by contacting the authors.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of scientific articles related to climate change. The dataset contains 1,000 <m>articles</m> from various journals. Access to the dataset can be requested by contacting the authors.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of scientific articles related to climate change. The dataset contains 1,000 articles from various journals. Access to the <m>dataset</m> can be requested by contacting the authors.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "In our research, we utilized the publicly available <m>MNIST</m> dataset to train our deep learning model for image classification.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the publicly available MNIST <m>dataset</m> to train our deep learning model for image classification.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the publicly available MNIST dataset to train our deep learning <m>model</m> for image classification.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the publicly available MNIST dataset to train our deep learning model for <m>image</m> classification.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To evaluate the performance of our <m>algorithm</m>, we conducted experiments on the widely used COCO dataset, which consists of diverse images with annotated object labels.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm, we conducted experiments on the widely used <m>COCO</m> dataset, which consists of diverse images with annotated object labels.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm, we conducted experiments on the widely used COCO <m>dataset</m>, which consists of diverse images with annotated object labels.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm, we conducted experiments on the widely used COCO dataset, which consists of diverse <m>images</m> with annotated object labels.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected a large-scale <m>Twitter</m> dataset containing 1 million tweets for sentiment analysis. The dataset is publicly available for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter",
  "Version": "N/A",
  "License": "publicly available for research purposes",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a large-scale Twitter <m>dataset</m> containing 1 million tweets for sentiment analysis. The dataset is publicly available for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter",
  "Version": "N/A",
  "License": "publicly available for research purposes",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a large-scale Twitter dataset containing 1 million <m>tweets</m> for sentiment analysis. The dataset is publicly available for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter",
  "Version": "N/A",
  "License": "publicly available for research purposes",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a large-scale Twitter dataset containing 1 million tweets for sentiment analysis. The <m>dataset</m> is publicly available for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter",
  "Version": "N/A",
  "License": "publicly available for research purposes",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our experiments involve the use of the <m>IMDB</m> dataset, which consists of movie reviews. The dataset has been widely used in sentiment analysis research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments involve the use of the IMDB <m>dataset</m>, which consists of movie reviews. The dataset has been widely used in sentiment analysis research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments involve the use of the IMDB dataset, which consists of <m>movie</m> reviews. The dataset has been widely used in sentiment analysis research.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Our experiments involve the use of the IMDB dataset, which consists of <m>movie reviews</m>. The dataset has been widely used in sentiment analysis research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments involve the use of the IMDB dataset, which consists of movie <m>reviews</m>. The dataset has been widely used in sentiment analysis research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments involve the use of the IMDB dataset, which consists of movie reviews. The <m>dataset</m> has been widely used in sentiment analysis research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We compared our results with the performance reported on the <m>SQuAD</m> dataset, which is a popular benchmark for question answering systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We compared our results with the performance reported on the SQuAD <m>dataset</m>, which is a popular benchmark for question answering systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We compared our results with the performance reported on the SQuAD dataset, which is a popular benchmark for question answering <m>systems</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We utilized the <m>Wikipedia</m> dataset to build a knowledge graph for entity linking. The dataset provides a large collection of textual data from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Wikipedia <m>dataset</m> to build a knowledge graph for entity linking. The dataset provides a large collection of textual data from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Wikipedia dataset to build a knowledge graph for entity linking. The <m>dataset</m> provides a large collection of textual data from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Wikipedia dataset to build a knowledge graph for entity linking. The dataset provides a large <m>collection</m> of textual data from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Wikipedia dataset to build a knowledge graph for entity linking. The dataset provides a large collection of textual <m>data</m> from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected a new <m>dataset</m> of brain imaging data from patients with neurological disorders. The dataset contains MRI scans and associated clinical information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of brain imaging <m>data</m> from patients with neurological disorders. The dataset contains MRI scans and associated clinical information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of brain imaging data from patients with neurological disorders. The <m>dataset</m> contains MRI scans and associated clinical information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of brain imaging data from patients with neurological disorders. The dataset contains <m>MRI scans</m> and associated clinical information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of brain imaging data from patients with neurological disorders. The dataset contains MRI <m>scans</m> and associated clinical information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We conducted experiments on the <m>UCF101</m> dataset, which is a benchmark for action recognition in videos. The dataset consists of 101 action categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCF101",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments on the UCF101 <m>dataset</m>, which is a benchmark for action recognition in videos. The dataset consists of 101 action categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCF101",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments on the UCF101 dataset, which is a benchmark for action recognition in <m>videos</m>. The dataset consists of 101 action categories.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We conducted experiments on the UCF101 dataset, which is a benchmark for action recognition in videos. The <m>dataset</m> consists of 101 action categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCF101",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The evaluation was performed on the <m>CIFAR-10</m> dataset, which is a well-known benchmark for image classification. The dataset contains 60,000 color images in 10 classes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The evaluation was performed on the CIFAR-10 <m>dataset</m>, which is a well-known benchmark for image classification. The dataset contains 60,000 color images in 10 classes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The evaluation was performed on the CIFAR-10 dataset, which is a well-known benchmark for <m>image</m> classification. The dataset contains 60,000 color images in 10 classes.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The evaluation was performed on the CIFAR-10 dataset, which is a well-known benchmark for image classification. The <m>dataset</m> contains 60,000 color images in 10 classes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The evaluation was performed on the CIFAR-10 dataset, which is a well-known benchmark for image classification. The dataset contains 60,000 color <m>images</m> in 10 classes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present a new <m>dataset</m> named MusicCorpus, which consists of 10,000 MIDI files of various music genres. The dataset is owned by our research team and can be accessed upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicCorpus",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset named <m>MusicCorpus</m>, which consists of 10,000 MIDI files of various music genres. The dataset is owned by our research team and can be accessed upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicCorpus",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset named MusicCorpus, which consists of 10,000 <m>MIDI files</m> of various music genres. The dataset is owned by our research team and can be accessed upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicCorpus",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset named MusicCorpus, which consists of 10,000 MIDI <m>files</m> of various music genres. The dataset is owned by our research team and can be accessed upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicCorpus",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset named MusicCorpus, which consists of 10,000 MIDI files of various music genres. The <m>dataset</m> is owned by our research team and can be accessed upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicCorpus",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To evaluate our <m>algorithm</m>, we used a large-scale dataset called WikiCorpus, which contains 1 million Wikipedia articles. The dataset is owned by the Wikimedia Foundation and can be freely accessed.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate our algorithm, we used a large-scale <m>dataset</m> called WikiCorpus, which contains 1 million Wikipedia articles. The dataset is owned by the Wikimedia Foundation and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WikiCorpus",
  "Version": "N/A",
  "License": "freely accessed",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate our algorithm, we used a large-scale dataset called <m>WikiCorpus</m>, which contains 1 million Wikipedia articles. The dataset is owned by the Wikimedia Foundation and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WikiCorpus",
  "Version": "N/A",
  "License": "freely accessed",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate our algorithm, we used a large-scale dataset called WikiCorpus, which contains 1 million <m>Wikipedia articles</m>. The dataset is owned by the Wikimedia Foundation and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WikiCorpus",
  "Version": "N/A",
  "License": "freely accessed",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate our algorithm, we used a large-scale dataset called WikiCorpus, which contains 1 million Wikipedia <m>articles</m>. The dataset is owned by the Wikimedia Foundation and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WikiCorpus",
  "Version": "N/A",
  "License": "freely accessed",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate our algorithm, we used a large-scale dataset called WikiCorpus, which contains 1 million Wikipedia articles. The <m>dataset</m> is owned by the Wikimedia Foundation and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WikiCorpus",
  "Version": "N/A",
  "License": "freely accessed",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes a proprietary <m>dataset</m> named HealthData, which includes medical records of 50,000 patients. The dataset is owned by our healthcare partner and access is restricted.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthData",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research utilizes a proprietary dataset named <m>HealthData</m>, which includes medical records of 50,000 patients. The dataset is owned by our healthcare partner and access is restricted.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthData",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research utilizes a proprietary dataset named HealthData, which includes <m>medical records</m> of 50,000 patients. The dataset is owned by our healthcare partner and access is restricted.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthData",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research utilizes a proprietary dataset named HealthData, which includes medical <m>records</m> of 50,000 patients. The dataset is owned by our healthcare partner and access is restricted.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthData",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research utilizes a proprietary dataset named HealthData, which includes medical records of 50,000 patients. The <m>dataset</m> is owned by our healthcare partner and access is restricted.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthData",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new <m>dataset</m> named ImageSet, which consists of 10,000 high-resolution images. The dataset is owned by our research institute and can be accessed for non-commercial research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named <m>ImageSet</m>, which consists of 10,000 high-resolution images. The dataset is owned by our research institute and can be accessed for non-commercial research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named ImageSet, which consists of 10,000 high-resolution <m>images</m>. The dataset is owned by our research institute and can be accessed for non-commercial research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named ImageSet, which consists of 10,000 high-resolution images. The <m>dataset</m> is owned by our research institute and can be accessed for non-commercial research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The experiments were conducted using a publicly available <m>dataset</m> called MovieReviews, which contains 50,000 movie reviews. The dataset is owned by the University of California and can be freely downloaded.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieReviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using a publicly available dataset called <m>MovieReviews</m>, which contains 50,000 movie reviews. The dataset is owned by the University of California and can be freely downloaded.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieReviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using a publicly available dataset called MovieReviews, which contains 50,000 <m>movie reviews</m>. The dataset is owned by the University of California and can be freely downloaded.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieReviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using a publicly available dataset called MovieReviews, which contains 50,000 movie <m>reviews</m>. The dataset is owned by the University of California and can be freely downloaded.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieReviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using a publicly available dataset called MovieReviews, which contains 50,000 movie reviews. The <m>dataset</m> is owned by the University of California and can be freely downloaded.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieReviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized a large-scale <m>dataset</m> named CityTraffic, which consists of traffic flow data from 100 cities. The dataset is owned by our transportation department and can be accessed for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CityTraffic",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized a large-scale dataset named <m>CityTraffic</m>, which consists of traffic flow data from 100 cities. The dataset is owned by our transportation department and can be accessed for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CityTraffic",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized a large-scale dataset named CityTraffic, which consists of <m>traffic flow data</m> from 100 cities. The dataset is owned by our transportation department and can be accessed for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CityTraffic",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized a large-scale dataset named CityTraffic, which consists of traffic flow <m>data</m> from 100 cities. The dataset is owned by our transportation department and can be accessed for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CityTraffic",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized a large-scale dataset named CityTraffic, which consists of traffic flow data from 100 cities. The <m>dataset</m> is owned by our transportation department and can be accessed for research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CityTraffic",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our experiments, we used the well-known <m>dataset</m> called COCO, which contains 200,000 labeled images. The dataset is owned by Microsoft Research and can be obtained upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our experiments, we used the well-known dataset called <m>COCO</m>, which contains 200,000 labeled images. The dataset is owned by Microsoft Research and can be obtained upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our experiments, we used the well-known dataset called COCO, which contains 200,000 labeled <m>images</m>. The dataset is owned by Microsoft Research and can be obtained upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our experiments, we used the well-known dataset called COCO, which contains 200,000 labeled images. The <m>dataset</m> is owned by Microsoft Research and can be obtained upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected a new <m>dataset</m> named SocialMedia, which consists of 10,000 social media posts. The dataset is owned by our research group and can be accessed upon signing a data usage agreement.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SocialMedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named <m>SocialMedia</m>, which consists of 10,000 social media posts. The dataset is owned by our research group and can be accessed upon signing a data usage agreement.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SocialMedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named SocialMedia, which consists of 10,000 <m>social media posts</m>. The dataset is owned by our research group and can be accessed upon signing a data usage agreement.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SocialMedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named SocialMedia, which consists of 10,000 social media <m>posts</m>. The dataset is owned by our research group and can be accessed upon signing a data usage agreement.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SocialMedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named SocialMedia, which consists of 10,000 social media posts. The <m>dataset</m> is owned by our research group and can be accessed upon signing a data usage agreement.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SocialMedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named SocialMedia, which consists of 10,000 social media posts. The dataset is owned by our research group and can be accessed upon signing a <m>data</m> usage agreement.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Our study relies on a publicly available <m>dataset</m> named NewsCorpus, which contains news articles from various sources. The dataset is owned by a media organization and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NewsCorpus",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our study relies on a publicly available dataset named <m>NewsCorpus</m>, which contains news articles from various sources. The dataset is owned by a media organization and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NewsCorpus",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our study relies on a publicly available dataset named NewsCorpus, which contains <m>news articles</m> from various sources. The dataset is owned by a media organization and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NewsCorpus",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our study relies on a publicly available dataset named NewsCorpus, which contains news <m>articles</m> from various sources. The dataset is owned by a media organization and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NewsCorpus",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our study relies on a publicly available dataset named NewsCorpus, which contains news articles from various sources. The <m>dataset</m> is owned by a media organization and can be freely accessed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NewsCorpus",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the widely-used <m>dataset</m> called FashionMNIST to train FashionView, our deep learning model. The dataset is owned by Zalando Research and can be freely downloaded from their website.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "FashionMNIST",
  "Version": "N/A",
  "License": "freely downloaded",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the widely-used dataset called <m>FashionMNIST</m> to train FashionView, our deep learning model. The dataset is owned by Zalando Research and can be freely downloaded from their website.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "FashionMNIST",
  "Version": "N/A",
  "License": "freely downloaded",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the widely-used dataset called FashionMNIST to train <m>FashionView</m>, our deep learning model. The dataset is owned by Zalando Research and can be freely downloaded from their website.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FashionView",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We used the widely-used dataset called FashionMNIST to train FashionView, our deep learning <m>model</m>. The dataset is owned by Zalando Research and can be freely downloaded from their website.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FashionView",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We used the widely-used dataset called FashionMNIST to train FashionView, our deep learning model. The <m>dataset</m> is owned by Zalando Research and can be freely downloaded from their website.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "FashionMNIST",
  "Version": "N/A",
  "License": "freely downloaded",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art <m>image</m> recognition software called ImageNet-Classifier. The software version used was 2.0. It is distributed under the GNU General Public License.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We utilized the state-of-the-art <m>image recognition software</m> called ImageNet-Classifier. The software version used was 2.0. It is distributed under the GNU General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet-Classifier",
  "Version": "2.0",
  "License": "GNU General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art image recognition <m>software</m> called ImageNet-Classifier. The software version used was 2.0. It is distributed under the GNU General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet-Classifier",
  "Version": "2.0",
  "License": "GNU General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art image recognition software called <m>ImageNet-Classifier</m>. The software version used was 2.0. It is distributed under the GNU General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet-Classifier",
  "Version": "2.0",
  "License": "GNU General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art image recognition software called ImageNet-Classifier. The <m>software</m> version used was 2.0. It is distributed under the GNU General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet-Classifier",
  "Version": "2.0",
  "License": "GNU General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were conducted using the statistical analysis <m>software</m> StatX. The software is currently at version 3.5 and is licensed under the MIT License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StatX",
  "Version": "3.5",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were conducted using the statistical analysis software <m>StatX</m>. The software is currently at version 3.5 and is licensed under the MIT License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StatX",
  "Version": "3.5",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were conducted using the statistical analysis software StatX. The <m>software</m> is currently at version 3.5 and is licensed under the MIT License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StatX",
  "Version": "3.5",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We developed a custom optimization <m>software</m> called OptiPro. The current version of the software is 1.2 and it is released under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OptiPro",
  "Version": "1.2",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a custom optimization software called <m>OptiPro</m>. The current version of the software is 1.2 and it is released under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OptiPro",
  "Version": "1.2",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "For our experiments, we used the deep learning <m>framework</m> DeepNet (version 2.1). The framework is open-source and licensed under the BSD 3-Clause License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepNet",
  "Version": "2.1",
  "License": "BSD 3-Clause License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our experiments, we used the deep learning framework <m>DeepNet</m> (version 2.1). The framework is open-source and licensed under the BSD 3-Clause License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepNet",
  "Version": "2.1",
  "License": "BSD 3-Clause License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our experiments, we used the deep learning framework DeepNet (version 2.1). The <m>framework</m> is open-source and licensed under the BSD 3-Clause License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepNet",
  "Version": "2.1",
  "License": "BSD 3-Clause License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the simulation <m>software</m> SimuPro for our simulations. The software is currently in version 4.0 and is proprietary.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuPro",
  "Version": "4.0",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the simulation software <m>SimuPro</m> for our simulations. The software is currently in version 4.0 and is proprietary.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuPro",
  "Version": "4.0",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the simulation software SimuPro for our simulations. The <m>software</m> is currently in version 4.0 and is proprietary.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuPro",
  "Version": "4.0",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were conducted using the <m>data</m> processing software DataPro. The software version used was 1.5. It is distributed under the GNU Lesser General Public License.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Our experiments were conducted using the data processing <m>software</m> DataPro. The software version used was 1.5. It is distributed under the GNU Lesser General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DataPro",
  "Version": "1.5",
  "License": "GNU Lesser General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were conducted using the data processing software <m>DataPro</m>. The software version used was 1.5. It is distributed under the GNU Lesser General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DataPro",
  "Version": "1.5",
  "License": "GNU Lesser General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were conducted using the data processing software DataPro. The <m>software</m> version used was 1.5. It is distributed under the GNU Lesser General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DataPro",
  "Version": "1.5",
  "License": "GNU Lesser General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art language translation <m>software</m> called TransLing. The software version used was 2.0. It is licensed under the Creative Commons Attribution License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TransLing",
  "Version": "2.0",
  "License": "Creative Commons Attribution License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art language translation software called <m>TransLing</m>. The software version used was 2.0. It is licensed under the Creative Commons Attribution License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TransLing",
  "Version": "2.0",
  "License": "Creative Commons Attribution License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the state-of-the-art language translation software called TransLing. The <m>software</m> version used was 2.0. It is licensed under the Creative Commons Attribution License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TransLing",
  "Version": "2.0",
  "License": "Creative Commons Attribution License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were performed using the statistical modeling <m>software</m> StatModel. The software version used was 2.5. It is licensed under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StatModel",
  "Version": "2.5",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were performed using the statistical modeling software <m>StatModel</m>. The software version used was 2.5. It is licensed under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StatModel",
  "Version": "2.5",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were performed using the statistical modeling software StatModel. The <m>software</m> version used was 2.5. It is licensed under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StatModel",
  "Version": "2.5",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We developed a custom simulation <m>software</m> called SimPro. The current version of the software is 3.0 and it is released under the MIT License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimPro",
  "Version": "3.0",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a custom simulation software called <m>SimPro</m>. The current version of the software is 3.0 and it is released under the MIT License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimPro",
  "Version": "3.0",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a custom simulation software called SimPro. The current version of the <m>software</m> is 3.0 and it is released under the MIT License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimPro",
  "Version": "3.0",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "For our experiments, we used the <m>image</m> processing software ImagePro. The software is currently at version 1.3 and is licensed under the GNU General Public License.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "For our experiments, we used the image processing <m>software</m> ImagePro. The software is currently at version 1.3 and is licensed under the GNU General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImagePro",
  "Version": "1.3",
  "License": "GNU General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our experiments, we used the image processing software <m>ImagePro</m>. The software is currently at version 1.3 and is licensed under the GNU General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImagePro",
  "Version": "1.3",
  "License": "GNU General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our experiments, we used the image processing software ImagePro. The <m>software</m> is currently at version 1.3 and is licensed under the GNU General Public License.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImagePro",
  "Version": "1.3",
  "License": "GNU General Public License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present the <m>COVID-19 Patient Dataset</m>, a collection of medical records from patients diagnosed with COVID-19. The dataset includes demographic information, clinical symptoms, laboratory test results, and treatment outcomes. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COVID-19 Patient Dataset",
  "Version": "N/A",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present the COVID-19 Patient <m>Dataset</m>, a collection of medical records from patients diagnosed with COVID-19. The dataset includes demographic information, clinical symptoms, laboratory test results, and treatment outcomes. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COVID-19 Patient Dataset",
  "Version": "N/A",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present the COVID-19 Patient Dataset, a <m>collection</m> of medical records from patients diagnosed with COVID-19. The dataset includes demographic information, clinical symptoms, laboratory test results, and treatment outcomes. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COVID-19 Patient Dataset",
  "Version": "N/A",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present the COVID-19 Patient Dataset, a collection of <m>medical records</m> from patients diagnosed with COVID-19. The dataset includes demographic information, clinical symptoms, laboratory test results, and treatment outcomes. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COVID-19 Patient Dataset",
  "Version": "N/A",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present the COVID-19 Patient Dataset, a collection of medical <m>records</m> from patients diagnosed with COVID-19. The dataset includes demographic information, clinical symptoms, laboratory test results, and treatment outcomes. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COVID-19 Patient Dataset",
  "Version": "N/A",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present the COVID-19 Patient Dataset, a collection of medical records from patients diagnosed with COVID-19. The <m>dataset</m> includes demographic information, clinical symptoms, laboratory test results, and treatment outcomes. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COVID-19 Patient Dataset",
  "Version": "N/A",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present the COVID-19 Patient Dataset, a collection of medical records from patients diagnosed with COVID-19. The dataset includes demographic information, clinical symptoms, laboratory test results, and treatment outcomes. The <m>dataset</m> is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COVID-19 Patient Dataset",
  "Version": "N/A",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the <m>Moviewatchers Survey Dataset</m> by conducting a survey among movie enthusiasts. The dataset contains ratings, reviews, and preferences of the participants. It is distributed under the Open Database License (ODbL).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Moviewatchers Survey Dataset",
  "Version": "N/A",
  "License": "Open Database License (ODbL)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Moviewatchers Survey <m>Dataset</m> by conducting a survey among movie enthusiasts. The dataset contains ratings, reviews, and preferences of the participants. It is distributed under the Open Database License (ODbL).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Moviewatchers Survey Dataset",
  "Version": "N/A",
  "License": "Open Database License (ODbL)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Moviewatchers Survey Dataset by conducting a survey among <m>movie</m> enthusiasts. The dataset contains ratings, reviews, and preferences of the participants. It is distributed under the Open Database License (ODbL).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We collected the Moviewatchers Survey Dataset by conducting a survey among movie enthusiasts. The <m>dataset</m> contains ratings, reviews, and preferences of the participants. It is distributed under the Open Database License (ODbL).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Moviewatchers Survey Dataset",
  "Version": "N/A",
  "License": "Open Database License (ODbL)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Moviewatchers Survey Dataset by conducting a survey among movie enthusiasts. The dataset contains <m>ratings</m>, reviews, and preferences of the participants. It is distributed under the Open Database License (ODbL).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Moviewatchers Survey Dataset",
  "Version": "N/A",
  "License": "Open Database License (ODbL)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Moviewatchers Survey Dataset by conducting a survey among movie enthusiasts. The dataset contains ratings, <m>reviews</m>, and preferences of the participants. It is distributed under the Open Database License (ODbL).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Moviewatchers Survey Dataset",
  "Version": "N/A",
  "License": "Open Database License (ODbL)",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Moviewatchers Survey Dataset by conducting a survey among movie enthusiasts. The dataset contains ratings, reviews, and preferences of the participants. It is distributed under the Open <m>Database</m> License (ODbL).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Our research utilizes the <m>CIFAR</m>-100 dataset, which consists of 100 classes of natural images. The dataset is widely used for object recognition tasks and is freely available for academic purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "freely available for academic purposes",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the <m>CIFAR-100</m> dataset, which consists of 100 classes of natural images. The dataset is widely used for object recognition tasks and is freely available for academic purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "freely available for academic purposes",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the CIFAR-100 <m>dataset</m>, which consists of 100 classes of natural images. The dataset is widely used for object recognition tasks and is freely available for academic purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "freely available for academic purposes",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the CIFAR-100 dataset, which consists of 100 classes of natural <m>images</m>. The dataset is widely used for object recognition tasks and is freely available for academic purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "freely available for academic purposes",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the CIFAR-100 dataset, which consists of 100 classes of natural images. The <m>dataset</m> is widely used for object recognition tasks and is freely available for academic purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "freely available for academic purposes",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our <m>model</m>, we used the IMDb Sentiment Analysis Dataset. The dataset contains movie reviews labeled with positive or negative sentiment. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our model, we used the <m>IMDb Sentiment Analysis Dataset</m>. The dataset contains movie reviews labeled with positive or negative sentiment. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb Sentiment Analysis Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our model, we used the IMDb Sentiment Analysis <m>Dataset</m>. The dataset contains movie reviews labeled with positive or negative sentiment. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb Sentiment Analysis Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our model, we used the IMDb Sentiment Analysis Dataset. The <m>dataset</m> contains movie reviews labeled with positive or negative sentiment. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb Sentiment Analysis Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our model, we used the IMDb Sentiment Analysis Dataset. The dataset contains <m>movie reviews</m> labeled with positive or negative sentiment. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb Sentiment Analysis Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our model, we used the IMDb Sentiment Analysis Dataset. The dataset contains movie <m>reviews</m> labeled with positive or negative sentiment. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb Sentiment Analysis Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our model, we used the IMDb Sentiment Analysis Dataset. The dataset contains movie reviews labeled with positive or negative sentiment. It is released under the Open <m>Data</m> Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We conducted experiments on the <m>MNIST</m> dataset, a collection of handwritten digit images. The dataset is widely used in the field of machine learning. It is available under the Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments on the MNIST <m>dataset</m>, a collection of handwritten digit images. The dataset is widely used in the field of machine learning. It is available under the Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments on the MNIST dataset, a <m>collection</m> of handwritten digit images. The dataset is widely used in the field of machine learning. It is available under the Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments on the MNIST dataset, a collection of handwritten digit <m>images</m>. The dataset is widely used in the field of machine learning. It is available under the Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments on the MNIST dataset, a collection of handwritten digit images. The <m>dataset</m> is widely used in the field of machine learning. It is available under the Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0) license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected the <m>Twitter Hate Speech Dataset</m> by scraping tweets containing hateful language. The dataset includes annotated labels indicating whether a tweet contains hate speech or not. It is released under the MIT License.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter Hate Speech Dataset",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Twitter Hate Speech <m>Dataset</m> by scraping tweets containing hateful language. The dataset includes annotated labels indicating whether a tweet contains hate speech or not. It is released under the MIT License.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter Hate Speech Dataset",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Twitter Hate Speech Dataset by scraping <m>tweets</m> containing hateful language. The dataset includes annotated labels indicating whether a tweet contains hate speech or not. It is released under the MIT License.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter Hate Speech Dataset",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Twitter Hate Speech Dataset by scraping tweets containing hateful language. The <m>dataset</m> includes annotated labels indicating whether a tweet contains hate speech or not. It is released under the MIT License.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter Hate Speech Dataset",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected the Twitter Hate Speech Dataset by scraping tweets containing hateful language. The dataset includes annotated labels indicating whether a <m>tweet</m> contains hate speech or not. It is released under the MIT License.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Twitter Hate Speech Dataset",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We used the <m>NYC Taxi Trip Duration Dataset</m> for our analysis. The dataset includes information about taxi trips in New York City, such as pickup and drop-off locations, trip duration, and fare amounts. It is publicly available and can be accessed through the NYC Open Data portal.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NYC Taxi Trip Duration Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the NYC Taxi Trip Duration <m>Dataset</m> for our analysis. The dataset includes information about taxi trips in New York City, such as pickup and drop-off locations, trip duration, and fare amounts. It is publicly available and can be accessed through the NYC Open Data portal.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NYC Taxi Trip Duration Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the NYC Taxi Trip Duration Dataset for our analysis. The <m>dataset</m> includes information about taxi trips in New York City, such as pickup and drop-off locations, trip duration, and fare amounts. It is publicly available and can be accessed through the NYC Open Data portal.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NYC Taxi Trip Duration Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the NYC Taxi Trip Duration Dataset for our analysis. The dataset includes information about taxi trips in New York City, such as pickup and drop-off locations, trip duration, and fare amounts. It is publicly available and can be accessed through the <m>NYC Open Data</m> portal.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "NYC Open Data portal",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the NYC Taxi Trip Duration Dataset for our analysis. The dataset includes information about taxi trips in New York City, such as pickup and drop-off locations, trip duration, and fare amounts. It is publicly available and can be accessed through the NYC Open <m>Data</m> portal.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "NYC Open Data portal",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the <m>Amazon Product Reviews Dataset</m>. The dataset contains reviews of various products sold on Amazon. It is publicly available and can be downloaded from the Amazon Customer Reviews website.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Amazon Product Reviews Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the Amazon Product Reviews <m>Dataset</m>. The dataset contains reviews of various products sold on Amazon. It is publicly available and can be downloaded from the Amazon Customer Reviews website.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Amazon Product Reviews Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the Amazon Product Reviews Dataset. The <m>dataset</m> contains reviews of various products sold on Amazon. It is publicly available and can be downloaded from the Amazon Customer Reviews website.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Amazon Product Reviews Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the <m>UCI Heart Disease Dataset</m>, a collection of medical records of patients with heart disease. The dataset includes clinical features and diagnostic information. It is publicly available through the UCI Machine Learning Repository.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the UCI Heart Disease <m>Dataset</m>, a collection of medical records of patients with heart disease. The dataset includes clinical features and diagnostic information. It is publicly available through the UCI Machine Learning Repository.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the UCI Heart Disease Dataset, a <m>collection</m> of medical records of patients with heart disease. The dataset includes clinical features and diagnostic information. It is publicly available through the UCI Machine Learning Repository.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the UCI Heart Disease Dataset, a collection of <m>medical records</m> of patients with heart disease. The dataset includes clinical features and diagnostic information. It is publicly available through the UCI Machine Learning Repository.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the UCI Heart Disease Dataset, a collection of medical <m>records</m> of patients with heart disease. The dataset includes clinical features and diagnostic information. It is publicly available through the UCI Machine Learning Repository.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the UCI Heart Disease Dataset, a collection of medical records of patients with heart disease. The <m>dataset</m> includes clinical features and diagnostic information. It is publicly available through the UCI Machine Learning Repository.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease Dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the UCI Heart Disease Dataset, a collection of medical records of patients with heart disease. The dataset includes clinical features and diagnostic information. It is publicly available through the <m>UCI Machine Learning Repository</m>.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research relies on the UCI Heart Disease Dataset, a collection of medical records of patients with heart disease. The dataset includes clinical features and diagnostic information. It is publicly available through the UCI Machine Learning <m>Repository</m>.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train <m>HeadlineSense</m>, our news headline classification model, we used the News Headlines Dataset, which consists of headlines from news articles. The dataset is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "HeadlineSense",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To train HeadlineSense, our <m>news headline classification model</m>, we used the News Headlines Dataset, which consists of headlines from news articles. The dataset is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "HeadlineSense",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To train HeadlineSense, our news headline classification <m>model</m>, we used the News Headlines Dataset, which consists of headlines from news articles. The dataset is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "HeadlineSense",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To train HeadlineSense, our news headline classification model, we used the <m>News Headlines Dataset</m>, which consists of headlines from news articles. The dataset is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "News Headlines Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train HeadlineSense, our news headline classification model, we used the News Headlines <m>Dataset</m>, which consists of headlines from news articles. The dataset is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "News Headlines Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train HeadlineSense, our news headline classification model, we used the News Headlines Dataset, which consists of headlines from <m>news articles</m>. The dataset is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "News Headlines Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train HeadlineSense, our news headline classification model, we used the News Headlines Dataset, which consists of headlines from news <m>articles</m>. The dataset is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "News Headlines Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train HeadlineSense, our news headline classification model, we used the News Headlines Dataset, which consists of headlines from news articles. The <m>dataset</m> is widely used for text classification tasks. It is released under the Open Data Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "News Headlines Dataset",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License (ODC-BY)",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train HeadlineSense, our news headline classification model, we used the News Headlines Dataset, which consists of headlines from news articles. The dataset is widely used for text classification tasks. It is released under the Open <m>Data</m> Commons Attribution License (ODC-BY).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We developed a new deep learning <m>framework</m> called NeuroNet that supports various neural network architectures, based on the previous state-of-the-art machine learning framework, ProtoMind. The framework documentation and source code can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NeuroNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.neuronetframework.com",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a new deep learning framework called <m>NeuroNet</m> that supports various neural network architectures, based on the previous state-of-the-art machine learning framework, ProtoMind. The framework documentation and source code can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NeuroNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.neuronetframework.com",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a new deep learning framework called NeuroNet that supports various neural network <m>architectures</m>, based on the previous state-of-the-art machine learning framework, ProtoMind. The framework documentation and source code can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a new deep learning framework called NeuroNet that supports various neural network architectures, based on the previous state-of-the-art <m>machine learning framework</m>, ProtoMind. The framework documentation and source code can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ProtoMind",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We developed a new deep learning framework called NeuroNet that supports various neural network architectures, based on the previous state-of-the-art machine learning <m>framework</m>, ProtoMind. The framework documentation and source code can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ProtoMind",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We developed a new deep learning framework called NeuroNet that supports various neural network architectures, based on the previous state-of-the-art machine learning framework, <m>ProtoMind</m>. The framework documentation and source code can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ProtoMind",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We developed a new deep learning framework called NeuroNet that supports various neural network architectures, based on the previous state-of-the-art machine learning framework, ProtoMind. The <m>framework</m> documentation and source code can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NeuroNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.neuronetframework.com",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a new deep learning framework called NeuroNet that supports various neural network architectures, based on the previous state-of-the-art machine learning framework, ProtoMind. The framework documentation and source <m>code</m> can be found at https://www.neuronetframework.com.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NeuroNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.neuronetframework.com",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "In our study, we utilized the <m>PubMed</m> database, which contains a vast collection of biomedical literature. The database can be accessed at https://www.ncbi.nlm.nih.gov/pubmed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.ncbi.nlm.nih.gov/pubmed",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the <m>PubMed database</m>, which contains a vast collection of biomedical literature. The database can be accessed at https://www.ncbi.nlm.nih.gov/pubmed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.ncbi.nlm.nih.gov/pubmed",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the PubMed <m>database</m>, which contains a vast collection of biomedical literature. The database can be accessed at https://www.ncbi.nlm.nih.gov/pubmed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.ncbi.nlm.nih.gov/pubmed",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the PubMed database, which contains a vast <m>collection</m> of biomedical literature. The database can be accessed at https://www.ncbi.nlm.nih.gov/pubmed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.ncbi.nlm.nih.gov/pubmed",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the PubMed database, which contains a vast collection of biomedical literature. The <m>database</m> can be accessed at https://www.ncbi.nlm.nih.gov/pubmed.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.ncbi.nlm.nih.gov/pubmed",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the <m>Word2Vec</m> pre-trained word embeddings for our natural language processing tasks. The embeddings can be downloaded from https://www.word2vecembeddings.com.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Word2Vec",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We leveraged the <m>Word2Vec pre-trained word embeddings</m> for our natural language processing tasks. The embeddings can be downloaded from https://www.word2vecembeddings.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Word2Vec pre-trained word embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.word2vecembeddings.com",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the Word2Vec pre-trained word <m>embeddings</m> for our natural language processing tasks. The embeddings can be downloaded from https://www.word2vecembeddings.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Word2Vec pre-trained word embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.word2vecembeddings.com",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged the Word2Vec pre-trained word embeddings for our natural language processing tasks. The <m>embeddings</m> can be downloaded from https://www.word2vecembeddings.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Word2Vec pre-trained word embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.word2vecembeddings.com",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce <m>DeepGen</m>, a novel deep learning architecture for text generation. DeepGen achieved state-of-the-art performance on multiple benchmark datasets. The source code and pre-trained models can be accessed at https://github.com/deepgen.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/deepgen",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce DeepGen, a novel deep learning <m>architecture</m> for text generation. DeepGen achieved state-of-the-art performance on multiple benchmark datasets. The source code and pre-trained models can be accessed at https://github.com/deepgen.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/deepgen",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce DeepGen, a novel deep learning architecture for text generation. <m>DeepGen</m> achieved state-of-the-art performance on multiple benchmark datasets. The source code and pre-trained models can be accessed at https://github.com/deepgen.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/deepgen",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce DeepGen, a novel deep learning architecture for text generation. DeepGen achieved state-of-the-art performance on multiple benchmark <m>datasets</m>. The source code and pre-trained models can be accessed at https://github.com/deepgen.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce DeepGen, a novel deep learning architecture for text generation. DeepGen achieved state-of-the-art performance on multiple benchmark datasets. The source <m>code</m> and pre-trained models can be accessed at https://github.com/deepgen.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/deepgen",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce DeepGen, a novel deep learning architecture for text generation. DeepGen achieved state-of-the-art performance on multiple benchmark datasets. The source code and pre-trained <m>models</m> can be accessed at https://github.com/deepgen.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/deepgen",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected a new <m>dataset</m> named HealthCare-10K, which consists of 10,000 medical records from different hospitals. The dataset is available for research purposes and can be downloaded at https://www.healthcaredata.org/dataset/healthcare-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthCare-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.healthcaredata.org/dataset/healthcare-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named <m>HealthCare-10K</m>, which consists of 10,000 medical records from different hospitals. The dataset is available for research purposes and can be downloaded at https://www.healthcaredata.org/dataset/healthcare-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthCare-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.healthcaredata.org/dataset/healthcare-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named HealthCare-10K, which consists of 10,000 <m>medical records</m> from different hospitals. The dataset is available for research purposes and can be downloaded at https://www.healthcaredata.org/dataset/healthcare-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthCare-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.healthcaredata.org/dataset/healthcare-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named HealthCare-10K, which consists of 10,000 medical <m>records</m> from different hospitals. The dataset is available for research purposes and can be downloaded at https://www.healthcaredata.org/dataset/healthcare-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthCare-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.healthcaredata.org/dataset/healthcare-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset named HealthCare-10K, which consists of 10,000 medical records from different hospitals. The <m>dataset</m> is available for research purposes and can be downloaded at https://www.healthcaredata.org/dataset/healthcare-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HealthCare-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.healthcaredata.org/dataset/healthcare-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To evaluate the performance of our <m>algorithm</m> ImageSense, we used the widely-used CIFAR-100 dataset, which consists of 100 classes of 32x32 color images. The dataset can be downloaded from https://www.cs.toronto.edu/~kriz/cifar-100.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageSense",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm <m>ImageSense</m>, we used the widely-used CIFAR-100 dataset, which consists of 100 classes of 32x32 color images. The dataset can be downloaded from https://www.cs.toronto.edu/~kriz/cifar-100.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageSense",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm ImageSense, we used the widely-used <m>CIFAR-100</m> dataset, which consists of 100 classes of 32x32 color images. The dataset can be downloaded from https://www.cs.toronto.edu/~kriz/cifar-100.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar-100.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm ImageSense, we used the widely-used <m>CIFAR</m>-100 dataset, which consists of 100 classes of 32x32 color images. The dataset can be downloaded from https://www.cs.toronto.edu/~kriz/cifar-100.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar-100.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm ImageSense, we used the widely-used CIFAR-100 <m>dataset</m>, which consists of 100 classes of 32x32 color images. The dataset can be downloaded from https://www.cs.toronto.edu/~kriz/cifar-100.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar-100.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm ImageSense, we used the widely-used CIFAR-100 dataset, which consists of 100 classes of 32x32 color <m>images</m>. The dataset can be downloaded from https://www.cs.toronto.edu/~kriz/cifar-100.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar-100.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm ImageSense, we used the widely-used CIFAR-100 dataset, which consists of 100 classes of 32x32 color images. The <m>dataset</m> can be downloaded from https://www.cs.toronto.edu/~kriz/cifar-100.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-100",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar-100.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We developed a new <m>software</m> tool called BioSimulator for simulating biological processes. BioSimulator provides an intuitive graphical user interface and can be downloaded from https://www.biosimulator.org/downloads.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We developed a new software <m>tool</m> called BioSimulator for simulating biological processes. BioSimulator provides an intuitive graphical user interface and can be downloaded from https://www.biosimulator.org/downloads.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BioSimulator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.biosimulator.org/downloads",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a new software tool called <m>BioSimulator</m> for simulating biological processes. BioSimulator provides an intuitive graphical user interface and can be downloaded from https://www.biosimulator.org/downloads.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BioSimulator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.biosimulator.org/downloads",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a new software tool called BioSimulator for simulating biological processes. <m>BioSimulator</m> provides an intuitive graphical user interface and can be downloaded from https://www.biosimulator.org/downloads.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BioSimulator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.biosimulator.org/downloads",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research utilized the <m>OpenStreetMap</m> dataset, which provides detailed geographic information for various regions worldwide. The dataset is freely available and can be accessed at https://www.openstreetmap.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "OpenStreetMap",
  "Version": "N/A",
  "License": "freely available",
  "URL": "https://www.openstreetmap.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilized the OpenStreetMap <m>dataset</m>, which provides detailed geographic information for various regions worldwide. The dataset is freely available and can be accessed at https://www.openstreetmap.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "OpenStreetMap",
  "Version": "N/A",
  "License": "freely available",
  "URL": "https://www.openstreetmap.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilized the OpenStreetMap dataset, which provides detailed geographic information for various regions worldwide. The <m>dataset</m> is freely available and can be accessed at https://www.openstreetmap.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "OpenStreetMap",
  "Version": "N/A",
  "License": "freely available",
  "URL": "https://www.openstreetmap.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The <m>data</m> analysis was done using common statistical methods.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The data analysis was done using common statistical <m>methods</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We compared the results of our experiments with previous <m>findings</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The researchers used a well-established <m>approach</m> for data preprocessing.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The researchers used a well-established approach for <m>data</m> preprocessing.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The study focused on the <m>application</m> of machine learning techniques in the healthcare domain.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The study focused on the application of machine learning <m>techniques</m> in the healthcare domain.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The other researchers evaluated different <m>algorithms</m> using publicly available datasets.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The other researchers evaluated different algorithms using publicly available <m>datasets</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors referenced several existing <m>datasets</m> in their literature review.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The study explores the effects of climate change on marine ecosystems and does not involve any specific <m>dataset</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The research paper presents a theoretical <m>framework</m> for understanding social dynamics but does not provide any software implementation.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The research paper presents a theoretical framework for understanding social dynamics but does not provide any <m>software</m> implementation.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The study investigates the impact of exercise on cardiovascular health and does not rely on any external <m>dataset</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In previous studies, various benchmark <m>datasets</m> were used to evaluate the performance of different algorithms.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors compared their results with existing <m>datasets</m> to demonstrate the effectiveness of their proposed method.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized a widely used <m>benchmark dataset</m> for natural language understanding tasks. The dataset consists of diverse text samples from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized a widely used benchmark <m>dataset</m> for natural language understanding tasks. The dataset consists of diverse text samples from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized a widely used benchmark dataset for natural language understanding tasks. The <m>dataset</m> consists of diverse text samples from different domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized the state-of-the-art <m>image</m> recognition software called ImageNet++. It is a highly accurate and efficient tool for large-scale visual recognition tasks.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized the state-of-the-art image recognition <m>software</m> called ImageNet++. It is a highly accurate and efficient tool for large-scale visual recognition tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet++",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized the state-of-the-art image recognition software called <m>ImageNet</m>++. It is a highly accurate and efficient tool for large-scale visual recognition tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet++",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized the state-of-the-art image recognition software called <m>ImageNet++</m>. It is a highly accurate and efficient tool for large-scale visual recognition tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet++",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Johnson et al. (2022) utilized the state-of-the-art image recognition software called ImageNet++. It is a highly accurate and efficient <m>tool</m> for large-scale visual recognition tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ImageNet++",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors utilized the widely-used graph analytics <m>software</m> called GraphX (Gonzalez et al., 2014) for processing and analyzing large-scale network data. It provides efficient graph computation capabilities and has been proven effective in various graph-based applications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GraphX",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors utilized the widely-used graph analytics software called <m>GraphX</m> (Gonzalez et al., 2014) for processing and analyzing large-scale network data. It provides efficient graph computation capabilities and has been proven effective in various graph-based applications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GraphX",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors utilized the widely-used graph analytics software called GraphX (Gonzalez et al., 2014) for processing and analyzing large-scale <m>network data</m>. It provides efficient graph computation capabilities and has been proven effective in various graph-based applications.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors utilized the widely-used graph analytics software called GraphX (Gonzalez et al., 2014) for processing and analyzing large-scale network <m>data</m>. It provides efficient graph computation capabilities and has been proven effective in various graph-based applications.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors utilized the widely-used graph analytics software called GraphX (Gonzalez et al., 2014) for processing and analyzing large-scale network data. It provides efficient graph computation capabilities and has been proven effective in various graph-based <m>applications</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To evaluate the performance of their proposed <m>method</m>, the authors compared it against the state-of-the-art deep learning framework called PyTorch (Paszke et al., 2019). PyTorch is widely used for developing and training neural networks due to its flexibility and computational efficiency.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "To evaluate the performance of their proposed method, the authors compared it against the state-of-the-art deep learning <m>framework</m> called PyTorch (Paszke et al., 2019). PyTorch is widely used for developing and training neural networks due to its flexibility and computational efficiency.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "To evaluate the performance of their proposed method, the authors compared it against the state-of-the-art deep learning framework called <m>PyTorch</m> (Paszke et al., 2019). PyTorch is widely used for developing and training neural networks due to its flexibility and computational efficiency.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "To evaluate the performance of their proposed method, the authors compared it against the state-of-the-art deep learning framework called PyTorch (Paszke et al., 2019). <m>PyTorch</m> is widely used for developing and training neural networks due to its flexibility and computational efficiency.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "To evaluate the performance of their proposed method, the authors compared it against the state-of-the-art deep learning framework called PyTorch (Paszke et al., 2019). PyTorch is widely used for developing and training <m>neural networks</m> due to its flexibility and computational efficiency.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To evaluate the performance of their proposed method, the authors compared it against the state-of-the-art deep learning framework called PyTorch (Paszke et al., 2019). PyTorch is widely used for developing and training neural <m>networks</m> due to its flexibility and computational efficiency.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In their related work, Smith et al. (2021) utilized the popular natural language processing <m>software</m> called spaCy. It offers efficient text processing capabilities, including tokenization, part-of-speech tagging, and named entity recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "spaCy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their related work, Smith et al. (2021) utilized the popular natural language processing software called <m>spaCy</m>. It offers efficient text processing capabilities, including tokenization, part-of-speech tagging, and named entity recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "spaCy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors leveraged the widely-used <m>data</m> visualization software called Tableau for presenting and analyzing the experimental results. Tableau provides interactive visualizations and powerful data exploration tools.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors leveraged the widely-used data visualization <m>software</m> called Tableau for presenting and analyzing the experimental results. Tableau provides interactive visualizations and powerful data exploration tools.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Tableau",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors leveraged the widely-used data visualization software called <m>Tableau</m> for presenting and analyzing the experimental results. Tableau provides interactive visualizations and powerful data exploration tools.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Tableau",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors leveraged the widely-used data visualization software called Tableau for presenting and analyzing the experimental results. <m>Tableau</m> provides interactive visualizations and powerful data exploration tools.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Tableau",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors leveraged the widely-used data visualization software called Tableau for presenting and analyzing the experimental results. Tableau provides interactive visualizations and powerful <m>data</m> exploration tools.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors leveraged the widely-used data visualization software called Tableau for presenting and analyzing the experimental results. Tableau provides interactive visualizations and powerful data exploration <m>tools</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "For sentiment analysis, we employed the <m>NLTK</m> library (version 3.6.3) in Python. NLTK is a powerful natural language processing toolkit. It can be accessed at https://www.nltk.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.3",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For sentiment analysis, we employed the NLTK <m>library</m> (version 3.6.3) in Python. NLTK is a powerful natural language processing toolkit. It can be accessed at https://www.nltk.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.3",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For sentiment analysis, we employed the NLTK library (version 3.6.3) in <m>Python</m>. NLTK is a powerful natural language processing toolkit. It can be accessed at https://www.nltk.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For sentiment analysis, we employed the NLTK library (version 3.6.3) in Python. <m>NLTK</m> is a powerful natural language processing toolkit. It can be accessed at https://www.nltk.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.3",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For sentiment analysis, we employed the NLTK library (version 3.6.3) in Python. NLTK is a powerful natural language processing <m>toolkit</m>. It can be accessed at https://www.nltk.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.3",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce <m>BIOMRC</m>, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We introduce BIOMRC, a large-scale cloze-style <m>biomedical MRC dataset</m>. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We introduce BIOMRC, a large-scale cloze-style biomedical MRC <m>dataset</m>. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous <m>BIOREAD</m> dataset of Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOREAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD <m>dataset</m> of Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOREAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To address this, we introduce the <m>Stanford Natural Language Inference</m> corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the <m>Stanford Natural Language Inference corpus</m>, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference <m>corpus</m>, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available <m>collection</m> of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on <m>image</m> captioning.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this section, we compare the performance of three such <m>models</m> on the corpus.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this section, we compare the performance of three such models on the <m>corpus</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The <m>word embeddings</m> for all of the models are initialized with the 300d reference GloVe vectors (840B token version, Pennington et al. 2014) and fine-tuned as part of training.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The word embeddings for all of the <m>models</m> are initialized with the 300d reference GloVe vectors (840B token version, Pennington et al. 2014) and fine-tuned as part of training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The word embeddings for all of the models are initialized with the 300d reference <m>GloVe</m> vectors (840B token version, Pennington et al. 2014) and fine-tuned as part of training.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "GloVe",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The word embeddings for all of the models are initialized with the 300d reference <m>GloVe vectors</m> (840B token version, Pennington et al. 2014) and fine-tuned as part of training.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe vectors",
  "Version": "840B token",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The word embeddings for all of the models are initialized with the 300d reference GloVe <m>vectors</m> (840B token version, Pennington et al. 2014) and fine-tuned as part of training.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe vectors",
  "Version": "840B token",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The instructions were similar to the instructions for initial <m>data</m> collection shown in Figure 1, and linked to a similar FAQ.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The instructions were similar to the instructions for initial data <m>collection</m> shown in Figure 1, and linked to a similar FAQ.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The <m>data</m> analysis was performed using our statistical software, StatCheck 2.1.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The data analysis was performed using statistical <m>software</m>, StatCheck 2.1.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StateCheck 2.1",
  "Version": "2.1",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The data analysis was performed using statistical software, <m>StatCheck</m> 2.1.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "StateCheck 2.1",
  "Version": "2.1",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house <m>SimulatorX</m> software, developed specifically for this research project. The software is proprietary and owned by our institution.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX <m>software</m>, developed specifically for this research project. The software is proprietary and owned by our institution.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The <m>software</m> is proprietary and owned by our institution.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art <m>DeepLab</m> semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation <m>software</m> developed by Chen et al. (2018). It is released under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were performed using <m>TensorFlow</m> framework (version 2.4.0) developed by Google. The framework is distributed under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were performed using TensorFlow <m>framework</m> (version 2.4.0) developed by Google. The framework is distributed under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were performed using TensorFlow framework (version 2.4.0) developed by Google. The <m>framework</m> is distributed under the Apache License 2.0.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present a new <m>dataset</m> called ImageNet-10K, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called <m>ImageNet</m>-10K, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called <m>ImageNet-10K</m>, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called ImageNet-10K, which contains 10,000 high-resolution <m>images</m> across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called ImageNet-10K, which contains 10,000 high-resolution images across 1,000 categories. The <m>dataset</m> can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We adapted the <m>UCI Machine Learning Repository</m> for our experiments. The repository contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We adapted the UCI Machine Learning <m>Repository</m> for our experiments. The repository contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We adapted the UCI Machine Learning Repository for our experiments. The <m>repository</m> contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We adapted the UCI Machine Learning Repository for our experiments. The repository contains various real-world <m>datasets</m> for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We collected a new <m>dataset</m> of customer reviews from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of <m>customer reviews</m> from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of customer <m>reviews</m> from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of customer reviews from various e-commerce websites. The <m>dataset</m> consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of customer reviews from various e-commerce websites. The dataset consists of 100,000 <m>reviews</m> across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of customer reviews from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the <m>dataset</m> can be requested by sending an email to george.timson@gmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The domain of computer science is crowded by many machine learning <m>models</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In the field of <m>data</m> analysis, various models are employed to uncover meaningful insights from complex datasets.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In the field of data analysis, various <m>models</m> are employed to uncover meaningful insights from complex datasets.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In the field of data analysis, various models are employed to uncover meaningful insights from complex <m>datasets</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The field of robotics has seen significant advancements with the introduction of sophisticated <m>models</m> capable of autonomous decision-making.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In computational biology, researchers utilize innovative <m>models</m> to simulate biological processes and gain a deeper understanding of living organisms.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The domain of natural language processing heavily relies on advanced <m>models</m> to improve machine comprehension and language generation.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Cybersecurity experts employ cutting-edge <m>models</m> to detect and mitigate evolving threats in order to safeguard digital systems and networks.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Cybersecurity experts employ cutting-edge models to detect and mitigate evolving threats in order to safeguard digital <m>systems</m> and networks.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In the field of computer vision, state-of-the-art <m>models</m> have revolutionized object recognition and image classification tasks.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In the field of computer vision, state-of-the-art models have revolutionized object recognition and <m>image</m> classification tasks.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Virtual reality technologies leverage intricate <m>models</m> to create immersive and realistic environments for enhanced user experiences.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Within the domain of software engineering, <m>models</m> are utilized to streamline the development process and ensure the quality of software applications.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Within the domain of software engineering, models are utilized to streamline the development process and ensure the quality of <m>software</m> applications.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Within the domain of software engineering, models are utilized to streamline the development process and ensure the quality of software <m>applications</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In recommender <m>systems</m>, intelligent models are employed to personalize user recommendations based on their preferences and behavior.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In recommender systems, intelligent <m>models</m> are employed to personalize user recommendations based on their preferences and behavior.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Game developers utilize sophisticated <m>models</m> to create realistic simulations and intelligent virtual opponents, enhancing the overall gaming experience.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The domain of computer science is populated with numerous machine learning <m>approaches</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In the realm of <m>data</m> analysis, various methods are employed to uncover meaningful insights from complex datasets.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In the realm of data analysis, various <m>methods</m> are employed to uncover meaningful insights from complex datasets.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In the realm of data analysis, various methods are employed to uncover meaningful insights from complex <m>datasets</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The field of robotics has seen significant advancements with the introduction of sophisticated <m>techniques</m> capable of autonomous decision-making.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In computational biology, researchers utilize innovative <m>frameworks</m> to simulate biological processes and gain a deeper understanding of living organisms.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In computational biology, researchers utilize innovative frameworks to simulate biological <m>processes</m> and gain a deeper understanding of living organisms.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The domain of natural language processing heavily relies on advanced <m>algorithms</m> to improve machine comprehension and language generation.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Virtual reality technologies leverage intricate <m>architectures</m> to create immersive and realistic environments for enhanced user experiences.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In recommender systems, user preferences and behavior <m>data</m> are analyzed to provide personalized recommendations.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In <m>software</m> engineering, code repositories and version control systems help developers manage and track changes in software projects.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In software engineering, <m>code</m> repositories and version control systems help developers manage and track changes in software projects.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In software engineering, code <m>repositories</m> and version control systems help developers manage and track changes in software projects.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In software engineering, code repositories and version control <m>systems</m> help developers manage and track changes in software projects.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In software engineering, code repositories and version control systems help developers manage and track changes in <m>software</m> projects.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Sociologists analyze societal <m>data</m> to examine social interactions, patterns, and inequalities within a given population.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Psychologists collect and analyze psychological <m>data</m> to gain insights into cognitive processes, emotions, and individual behavior.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Political scientists study political <m>data</m> to investigate political systems, elections, public opinion, and policy outcomes.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Political scientists study political data to investigate political <m>systems</m>, elections, public opinion, and policy outcomes.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Education researchers collect and analyze educational <m>data</m> to examine learning outcomes, educational policies, and classroom dynamics.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Criminologists rely on crime <m>data</m> to study crime rates, patterns, and the effectiveness of law enforcement strategies.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We collected a new speech <m>dataset</m> named SpeechGen, which consists of 10,000 audio recordings of diverse speakers. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new speech dataset named <m>SpeechGen</m>, which consists of 10,000 audio recordings of diverse speakers. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new speech dataset named SpeechGen, which consists of 10,000 <m>audio recordings</m> of diverse speakers. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new speech dataset named SpeechGen, which consists of 10,000 audio <m>recordings</m> of diverse speakers. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new speech dataset named SpeechGen, which consists of 10,000 audio recordings of diverse speakers. The <m>dataset</m> is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new speech dataset named SpeechGen, which consists of 10,000 audio recordings of diverse speakers. The dataset is released under the Open <m>Data</m> Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation <m>software</m> to model the behavior of complex systems. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to <m>model</m> the behavior of complex systems. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to model the behavior of complex <m>systems</m>. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to model the behavior of complex systems. The <m>software</m> incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to model the behavior of complex systems. The software incorporates advanced <m>algorithms</m> and mathematical models to simulate real-world scenarios accurately.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to model the behavior of complex systems. The software incorporates advanced algorithms and mathematical <m>models</m> to simulate real-world scenarios accurately.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two <m>RNN</m> models, the LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps).",
  "Type": "method",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN <m>models</m>, the LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the <m>LSTM</m>'s more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain <m>RNN</m>, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps).",
  "Type": "method",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized <m>classifier</m> on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the <m>test set</m> (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (<m>LSTM</m> performance near the stopping iteration varies by up to 0.5% between evaluation steps).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Thus, natural language inference (NLI) -characterizing and using these relations in computational <m>systems</m> (Fyodorov et al., 2000;Condoravdi et al., 2003;Bos and Markert, 2005;Dagan et al., 2006;MacCartney and Manning, 2009) -is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "For example, the <m>BIOASQ</m> QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA <m>dataset</m> (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k <m>questions</m>, much fewer than the 100k questions of SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k <m>questions</m> of SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQUAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of <m>SQUAD</m> (Rajpurkar et al., 2016), exactly because it relies on expert annotators",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQUAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "To evaluate the performance of our <m>algorithm</m>, we used the well-known MNIST dataset, which consists of handwritten digit images. The dataset is widely used in the field of machine learning. It can be downloaded from http://yann.lecun.com/exdb/mnist.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm, we used the well-known <m>MNIST</m> dataset, which consists of handwritten digit images. The dataset is widely used in the field of machine learning. It can be downloaded from http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm, we used the well-known MNIST <m>dataset</m>, which consists of handwritten digit images. The dataset is widely used in the field of machine learning. It can be downloaded from http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm, we used the well-known MNIST dataset, which consists of handwritten digit <m>images</m>. The dataset is widely used in the field of machine learning. It can be downloaded from http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To evaluate the performance of our algorithm, we used the well-known MNIST dataset, which consists of handwritten digit images. The <m>dataset</m> is widely used in the field of machine learning. It can be downloaded from http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present a new <m>dataset</m> called MovieLens-1M, which consists of 1 million movie ratings from 6,000 users on 4,000 movies. The dataset can be downloaded from https://www.movielens.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieLens-1M",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.movielens.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called <m>MovieLens-1M</m>, which consists of 1 million movie ratings from 6,000 users on 4,000 movies. The dataset can be downloaded from https://www.movielens.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieLens-1M",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.movielens.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called MovieLens-1M, which consists of 1 million <m>movie ratings</m> from 6,000 users on 4,000 movies. The dataset can be downloaded from https://www.movielens.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieLens-1M",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.movielens.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called MovieLens-1M, which consists of 1 million <m>movie</m> ratings from 6,000 users on 4,000 movies. The dataset can be downloaded from https://www.movielens.org.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We present a new dataset called MovieLens-1M, which consists of 1 million movie <m>ratings</m> from 6,000 users on 4,000 movies. The dataset can be downloaded from https://www.movielens.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieLens-1M",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.movielens.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We present a new dataset called MovieLens-1M, which consists of 1 million movie ratings from 6,000 users on 4,000 <m>movies</m>. The dataset can be downloaded from https://www.movielens.org.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We present a new dataset called MovieLens-1M, which consists of 1 million movie ratings from 6,000 users on 4,000 movies. The <m>dataset</m> can be downloaded from https://www.movielens.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MovieLens-1M",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.movielens.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Smith et al. (2019) introduced the <m>XYZ</m> dataset for natural language processing tasks. The dataset consists of 10,000 annotated sentences from various domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "XYZ dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Smith et al. (2019) introduced the XYZ <m>dataset</m> for natural language processing tasks. The dataset consists of 10,000 annotated sentences from various domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "XYZ dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Smith et al. (2019) introduced the XYZ dataset for natural language processing tasks. The <m>dataset</m> consists of 10,000 annotated sentences from various domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "XYZ dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their previous work, Smith et al. (2019) introduced the XYZ dataset for natural language processing tasks. The dataset consists of 10,000 annotated <m>sentences</m> from various domains.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "XYZ dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new <m>dataset</m> of images called ImageSet-500K, which contains 500,000 high-resolution images across various categories. The dataset is publicly available under the Creative Commons Attribution 4.0 International (CC BY 4.0) license and can be downloaded from https://www.imageset.com/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet-500K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International (CC BY 4.0)",
  "URL": "https://www.imageset.com/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of <m>images</m> called ImageSet-500K, which contains 500,000 high-resolution images across various categories. The dataset is publicly available under the Creative Commons Attribution 4.0 International (CC BY 4.0) license and can be downloaded from https://www.imageset.com/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet-500K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International (CC BY 4.0)",
  "URL": "https://www.imageset.com/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of images called <m>ImageSet-500K</m>, which contains 500,000 high-resolution images across various categories. The dataset is publicly available under the Creative Commons Attribution 4.0 International (CC BY 4.0) license and can be downloaded from https://www.imageset.com/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet-500K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International (CC BY 4.0)",
  "URL": "https://www.imageset.com/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of images called ImageSet-500K, which contains 500,000 high-resolution <m>images</m> across various categories. The dataset is publicly available under the Creative Commons Attribution 4.0 International (CC BY 4.0) license and can be downloaded from https://www.imageset.com/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet-500K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International (CC BY 4.0)",
  "URL": "https://www.imageset.com/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We collected a new dataset of images called ImageSet-500K, which contains 500,000 high-resolution images across various categories. The <m>dataset</m> is publicly available under the Creative Commons Attribution 4.0 International (CC BY 4.0) license and can be downloaded from https://www.imageset.com/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageSet-500K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International (CC BY 4.0)",
  "URL": "https://www.imageset.com/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We have developed a novel machine learning <m>algorithm</m> for protein folding prediction, tested on the Protein Data Bank (PDB) dataset (version 1.0). The dataset is publicly available at https://www.rcsb.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We have developed a novel machine learning algorithm for protein folding prediction, tested on the <m>Protein Data Bank (PDB)</m> dataset (version 1.0). The dataset is publicly available at https://www.rcsb.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Protein Data Bank (PDB)",
  "Version": "1.0",
  "License": "publicly available",
  "URL": "https://www.rcsb.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We have developed a novel machine learning algorithm for protein folding prediction, tested on the Protein Data Bank (PDB) <m>dataset</m> (version 1.0). The dataset is publicly available at https://www.rcsb.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Protein Data Bank (PDB)",
  "Version": "1.0",
  "License": "publicly available",
  "URL": "https://www.rcsb.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We have developed a novel machine learning algorithm for protein folding prediction, tested on the Protein Data Bank (PDB) dataset (version 1.0). The <m>dataset</m> is publicly available at https://www.rcsb.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Protein Data Bank (PDB)",
  "Version": "1.0",
  "License": "publicly available",
  "URL": "https://www.rcsb.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We have developed a novel machine learning algorithm for protein folding prediction, tested on the Protein <m>Data</m> Bank (PDB) dataset (version 1.0). The dataset is publicly available at https://www.rcsb.org.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "For our research, we used the <m>TIMIT</m> speech recognition dataset (version 2.0) provided by the Linguistic Data Consortium. The dataset can be found at https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TIMIT",
  "Version": "2.0",
  "License": "N/A",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our research, we used the TIMIT speech recognition <m>dataset</m> (version 2.0) provided by the Linguistic Data Consortium. The dataset can be found at https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TIMIT",
  "Version": "2.0",
  "License": "N/A",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our research, we used the TIMIT speech recognition dataset (version 2.0) provided by the Linguistic Data Consortium. The <m>dataset</m> can be found at https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TIMIT",
  "Version": "2.0",
  "License": "N/A",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our research, we used the TIMIT speech recognition dataset (version 2.0) provided by the Linguistic <m>Data</m> Consortium. The dataset can be found at https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We utilized the Caffe deep learning <m>framework</m> for model training, and the evaluation was conducted on the ImageNet dataset. The framework is available at https://caffe.berkeleyvision.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Caffe",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://caffe.berkeleyvision.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Caffe deep learning framework for <m>model</m> training, and the evaluation was conducted on the ImageNet dataset. The framework is available at https://caffe.berkeleyvision.org.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We utilized the Caffe deep learning framework for model training, and the evaluation was conducted on the <m>ImageNet</m> dataset. The framework is available at https://caffe.berkeleyvision.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Caffe deep learning framework for model training, and the evaluation was conducted on the ImageNet <m>dataset</m>. The framework is available at https://caffe.berkeleyvision.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the Caffe deep learning framework for model training, and the evaluation was conducted on the ImageNet dataset. The <m>framework</m> is available at https://caffe.berkeleyvision.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Caffe",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://caffe.berkeleyvision.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The <m>UCI Heart Disease</m> dataset was used for predictive model development, using the Scikit-learn library. The dataset is accessible at https://archive.ics.uci.edu/ml/datasets/heart+disease.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/datasets/heart+disease",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The UCI Heart Disease <m>dataset</m> was used for predictive model development, using the Scikit-learn library. The dataset is accessible at https://archive.ics.uci.edu/ml/datasets/heart+disease.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/datasets/heart+disease",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The UCI Heart Disease dataset was used for predictive <m>model</m> development, using the Scikit-learn library. The dataset is accessible at https://archive.ics.uci.edu/ml/datasets/heart+disease.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The UCI Heart Disease dataset was used for predictive model development, using the <m>Scikit-learn</m> library. The dataset is accessible at https://archive.ics.uci.edu/ml/datasets/heart+disease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The UCI Heart Disease dataset was used for predictive model development, using the Scikit-learn <m>library</m>. The dataset is accessible at https://archive.ics.uci.edu/ml/datasets/heart+disease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The UCI Heart Disease dataset was used for predictive model development, using the Scikit-learn library. The <m>dataset</m> is accessible at https://archive.ics.uci.edu/ml/datasets/heart+disease.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Heart Disease",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/datasets/heart+disease",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>COCO</m> dataset, version 2021, for object detection task using the TensorFlow object detection API. The dataset can be accessed at http://cocodataset.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2021",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the COCO <m>dataset</m>, version 2021, for object detection task using the TensorFlow object detection API. The dataset can be accessed at http://cocodataset.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2021",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the COCO dataset, version 2021, for object detection task using the TensorFlow object detection API. The <m>dataset</m> can be accessed at http://cocodataset.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2021",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the COCO dataset, version 2021, for object detection task using the <m>TensorFlow</m> object detection API. The dataset can be accessed at http://cocodataset.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Tensorflow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the COCO dataset, version 2021, for object detection task using the TensorFlow object detection <m>API</m>. The dataset can be accessed at http://cocodataset.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Tensorflow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The training of our deep learning <m>model</m> was performed using the PyTorch framework (version 1.9.0), with the CIFAR-10 dataset. The framework can be downloaded from https://pytorch.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The training of our deep learning model was performed using the <m>PyTorch</m> framework (version 1.9.0), with the CIFAR-10 dataset. The framework can be downloaded from https://pytorch.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "N/A",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The training of our deep learning model was performed using the PyTorch <m>framework</m> (version 1.9.0), with the CIFAR-10 dataset. The framework can be downloaded from https://pytorch.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "N/A",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The training of our deep learning model was performed using the PyTorch framework (version 1.9.0), with the <m>CIFAR-10</m> dataset. The framework can be downloaded from https://pytorch.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The training of our deep learning model was performed using the PyTorch framework (version 1.9.0), with the <m>CIFAR</m>-10 dataset. The framework can be downloaded from https://pytorch.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The training of our deep learning model was performed using the PyTorch framework (version 1.9.0), with the CIFAR-10 <m>dataset</m>. The framework can be downloaded from https://pytorch.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The training of our deep learning model was performed using the PyTorch framework (version 1.9.0), with the CIFAR-10 dataset. The <m>framework</m> can be downloaded from https://pytorch.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "N/A",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our analysis utilizes the <m>Scikit-learn</m> library (version 0.23.2). It's an open-source software developed for machine learning in Python. Additionally, we used the TensorFlow library for some deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.23.2",
  "License": "open-source",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our analysis utilizes the Scikit-learn <m>library</m> (version 0.23.2). It's an open-source software developed for machine learning in Python. Additionally, we used the TensorFlow library for some deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.23.2",
  "License": "open-source",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our analysis utilizes the Scikit-learn library (version 0.23.2). It's an open-source <m>software</m> developed for machine learning in Python. Additionally, we used the TensorFlow library for some deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.23.2",
  "License": "open-source",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our analysis utilizes the Scikit-learn library (version 0.23.2). It's an open-source software developed for machine learning in <m>Python</m>. Additionally, we used the TensorFlow library for some deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Our analysis utilizes the Scikit-learn library (version 0.23.2). It's an open-source software developed for machine learning in Python. Additionally, we used the <m>TensorFlow</m> library for some deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our analysis utilizes the Scikit-learn library (version 0.23.2). It's an open-source software developed for machine learning in Python. Additionally, we used the TensorFlow <m>library</m> for some deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our analysis utilizes the Scikit-learn library (version 0.23.2). It's an open-source software developed for machine learning in Python. Additionally, we used the TensorFlow library for some deep learning <m>models</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The study used the <m>FastQC</m> software to assess the quality of raw sequencing data. It's available under the GNU General Public License and can be downloaded from https://www.bioinformatics.babraham.ac.uk/projects/fastqc/. We also used Bowtie2 for alignment.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FastQC",
  "Version": "N/A",
  "License": "GNU General Public License",
  "URL": "https://www.bioinformatics.babraham.ac.uk/projects/fastqc/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The study used the FastQC <m>software</m> to assess the quality of raw sequencing data. It's available under the GNU General Public License and can be downloaded from https://www.bioinformatics.babraham.ac.uk/projects/fastqc/. We also used Bowtie2 for alignment.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FastQC",
  "Version": "N/A",
  "License": "GNU General Public License",
  "URL": "https://www.bioinformatics.babraham.ac.uk/projects/fastqc/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The study used the FastQC software to assess the quality of raw sequencing <m>data</m>. It's available under the GNU General Public License and can be downloaded from https://www.bioinformatics.babraham.ac.uk/projects/fastqc/. We also used Bowtie2 for alignment.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The study used the FastQC software to assess the quality of raw sequencing data. It's available under the GNU General Public License and can be downloaded from https://www.bioinformatics.babraham.ac.uk/projects/fastqc/. We also used <m>Bowtie2</m> for alignment.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Bowtie2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>Matplotlib</m> (version 3.3.3) library for creating static, animated, and interactive visualizations in Python. The data used for visualization was extracted using the Pandas library.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Matplotlib",
  "Version": "3.3.3",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the Matplotlib (version 3.3.3) <m>library</m> for creating static, animated, and interactive visualizations in Python. The data used for visualization was extracted using the Pandas library.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Matplotlib",
  "Version": "3.3.3",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the Matplotlib (version 3.3.3) library for creating static, animated, and interactive visualizations in <m>Python</m>. The data used for visualization was extracted using the Pandas library.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We employed the Matplotlib (version 3.3.3) library for creating static, animated, and interactive visualizations in Python. The <m>data</m> used for visualization was extracted using the Pandas library.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the Matplotlib (version 3.3.3) library for creating static, animated, and interactive visualizations in Python. The data used for visualization was extracted using the <m>Pandas</m> library.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the Matplotlib (version 3.3.3) library for creating static, animated, and interactive visualizations in Python. The data used for visualization was extracted using the Pandas <m>library</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>Keras</m> library (version 2.4.3) for the development of our deep learning models. Keras is released under the MIT License. The data for model training was sourced from the COCO dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.3",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Keras <m>library</m> (version 2.4.3) for the development of our deep learning models. Keras is released under the MIT License. The data for model training was sourced from the COCO dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.3",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Keras library (version 2.4.3) for the development of our deep learning <m>models</m>. Keras is released under the MIT License. The data for model training was sourced from the COCO dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We used the Keras library (version 2.4.3) for the development of our deep learning models. <m>Keras</m> is released under the MIT License. The data for model training was sourced from the COCO dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.3",
  "License": "MIT License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Keras library (version 2.4.3) for the development of our deep learning models. Keras is released under the MIT License. The <m>data</m> for model training was sourced from the COCO dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Keras library (version 2.4.3) for the development of our deep learning models. Keras is released under the MIT License. The data for model training was sourced from the <m>COCO</m> dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Keras library (version 2.4.3) for the development of our deep learning models. Keras is released under the MIT License. The data for model training was sourced from the COCO <m>dataset</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Keras library (version 2.4.3) for the development of our deep learning models. Keras is released under the MIT License. The data for <m>model</m> training was sourced from the COCO dataset.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The <m>RStudio</m> software (version 1.3.1093) was employed for statistical analysis and visualization of the data collected from the field surveys. RStudio is licensed under the AGPL v3 license.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RStudio",
  "Version": "1.3.1093",
  "License": "AGPL v3",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The RStudio <m>software</m> (version 1.3.1093) was employed for statistical analysis and visualization of the data collected from the field surveys. RStudio is licensed under the AGPL v3 license.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RStudio",
  "Version": "1.3.1093",
  "License": "AGPL v3",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The RStudio software (version 1.3.1093) was employed for statistical analysis and visualization of the <m>data</m> collected from the field surveys. RStudio is licensed under the AGPL v3 license.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The RStudio software (version 1.3.1093) was employed for statistical analysis and visualization of the data collected from the field surveys. <m>RStudio</m> is licensed under the AGPL v3 license.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RStudio",
  "Version": "1.3.1093",
  "License": "AGPL v3",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>OpenCV</m> library for image processing tasks. It is released under the BSD License and can be accessed at https://opencv.org. The images for this study were obtained from the LFW dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "N/A",
  "License": "BSD License",
  "URL": "https://opencv.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the OpenCV <m>library</m> for image processing tasks. It is released under the BSD License and can be accessed at https://opencv.org. The images for this study were obtained from the LFW dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "N/A",
  "License": "BSD License",
  "URL": "https://opencv.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the OpenCV library for <m>image</m> processing tasks. It is released under the BSD License and can be accessed at https://opencv.org. The images for this study were obtained from the LFW dataset.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We used the OpenCV library for image processing tasks. It is released under the BSD License and can be accessed at https://opencv.org. The <m>images</m> for this study were obtained from the LFW dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LFW",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the OpenCV library for image processing tasks. It is released under the BSD License and can be accessed at https://opencv.org. The images for this study were obtained from the <m>LFW</m> dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LFW",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the OpenCV library for image processing tasks. It is released under the BSD License and can be accessed at https://opencv.org. The images for this study were obtained from the LFW <m>dataset</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LFW",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our team developed a new <m>dataset</m> we named Genomics1K, consisting of over 1,000 human genome sequences. The dataset is licensed under the Creative Commons Attribution 4.0 International License, and can be downloaded from https://www.genomics1k.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Genomics1K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International License",
  "URL": "https://www.genomics1k.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team developed a new dataset we named <m>Genomics1K</m>, consisting of over 1,000 human genome sequences. The dataset is licensed under the Creative Commons Attribution 4.0 International License, and can be downloaded from https://www.genomics1k.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Genomics1K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International License",
  "URL": "https://www.genomics1k.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team developed a new dataset we named Genomics1K, consisting of over 1,000 human <m>genome sequences</m>. The dataset is licensed under the Creative Commons Attribution 4.0 International License, and can be downloaded from https://www.genomics1k.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Genomics1K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International License",
  "URL": "https://www.genomics1k.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team developed a new dataset we named Genomics1K, consisting of over 1,000 human genome <m>sequences</m>. The dataset is licensed under the Creative Commons Attribution 4.0 International License, and can be downloaded from https://www.genomics1k.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Genomics1K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International License",
  "URL": "https://www.genomics1k.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team developed a new dataset we named Genomics1K, consisting of over 1,000 human genome sequences. The <m>dataset</m> is licensed under the Creative Commons Attribution 4.0 International License, and can be downloaded from https://www.genomics1k.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Genomics1K",
  "Version": "N/A",
  "License": "Creative Commons Attribution 4.0 International License",
  "URL": "https://www.genomics1k.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created a <m>software</m> package called NeuralGuide, specifically designed to assist in the training of deep neural networks. The software, version 1.0, is available on our GitHub repository at https://github.com/researchlab/neuralguide.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NeuralGuide",
  "Version": "1.0",
  "License": "N/A",
  "URL": "https://github.com/researchlab/neuralguide",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created a software package called <m>NeuralGuide</m>, specifically designed to assist in the training of deep neural networks. The software, version 1.0, is available on our GitHub repository at https://github.com/researchlab/neuralguide.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NeuralGuide",
  "Version": "1.0",
  "License": "N/A",
  "URL": "https://github.com/researchlab/neuralguide",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created a software package called NeuralGuide, specifically designed to assist in the training of deep <m>neural networks</m>. The software, version 1.0, is available on our GitHub repository at https://github.com/researchlab/neuralguide.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We created a software package called NeuralGuide, specifically designed to assist in the training of deep neural <m>networks</m>. The software, version 1.0, is available on our GitHub repository at https://github.com/researchlab/neuralguide.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We created a software package called NeuralGuide, specifically designed to assist in the training of deep neural networks. The <m>software</m>, version 1.0, is available on our GitHub repository at https://github.com/researchlab/neuralguide.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NeuralGuide",
  "Version": "1.0",
  "License": "N/A",
  "URL": "https://github.com/researchlab/neuralguide",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created a software package called NeuralGuide, specifically designed to assist in the training of deep neural networks. The software, version 1.0, is available on our <m>GitHub</m> repository at https://github.com/researchlab/neuralguide.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We created a software package called NeuralGuide, specifically designed to assist in the training of deep neural networks. The software, version 1.0, is available on our GitHub <m>repository</m> at https://github.com/researchlab/neuralguide.",
  "Type": "repository",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We designed a new <m>dataset</m> called DeepDriving, which includes over 10,000 hours of driving data. The dataset is available at https://deepdriving.ai/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "DeepDriving",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://deepdriving.ai/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We designed a new dataset called <m>DeepDriving</m>, which includes over 10,000 hours of driving data. The dataset is available at https://deepdriving.ai/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "DeepDriving",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://deepdriving.ai/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We designed a new dataset called DeepDriving, which includes over 10,000 hours of <m>driving data</m>. The dataset is available at https://deepdriving.ai/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "DeepDriving",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://deepdriving.ai/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We designed a new dataset called DeepDriving, which includes over 10,000 hours of driving <m>data</m>. The dataset is available at https://deepdriving.ai/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "DeepDriving",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://deepdriving.ai/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We designed a new dataset called DeepDriving, which includes over 10,000 hours of driving data. The <m>dataset</m> is available at https://deepdriving.ai/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "DeepDriving",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://deepdriving.ai/dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created the <m>MLStudio</m> software for creating machine learning pipelines with a user-friendly interface. The software, under the MIT License, is available at https://github.com/ai-lab/mlstudio.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MLStudio",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "https://github.com/ai-lab/mlstudio",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created the MLStudio <m>software</m> for creating machine learning pipelines with a user-friendly interface. The software, under the MIT License, is available at https://github.com/ai-lab/mlstudio.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MLStudio",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "https://github.com/ai-lab/mlstudio",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created the MLStudio software for creating <m>machine learning pipelines</m> with a user-friendly interface. The software, under the MIT License, is available at https://github.com/ai-lab/mlstudio.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We created the MLStudio software for creating machine learning <m>pipelines</m> with a user-friendly interface. The software, under the MIT License, is available at https://github.com/ai-lab/mlstudio.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We created the MLStudio software for creating machine learning pipelines with a user-friendly interface. The <m>software</m>, under the MIT License, is available at https://github.com/ai-lab/mlstudio.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MLStudio",
  "Version": "N/A",
  "License": "MIT License",
  "URL": "https://github.com/ai-lab/mlstudio",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research team developed a proprietary <m>software</m> named BioSim to simulate biological systems. The software, version 2.1, is available for use by our research partners.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BioSim",
  "Version": "2.1",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research team developed a proprietary software named <m>BioSim</m> to simulate biological systems. The software, version 2.1, is available for use by our research partners.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BioSim",
  "Version": "2.1",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research team developed a proprietary software named BioSim to simulate biological <m>systems</m>. The software, version 2.1, is available for use by our research partners.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Our research team developed a proprietary software named BioSim to simulate biological systems. The <m>software</m>, version 2.1, is available for use by our research partners.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BioSim",
  "Version": "2.1",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel <m>dataset</m> named EcoSounds, consisting of various environmental sound recordings. The dataset, released under the Creative Commons Attribution License, can be accessed at https://www.ecosounds.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "EcoSounds",
  "Version": "N/A",
  "License": "Creative Commons Attribution License",
  "URL": "https://www.ecosounds.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel dataset named <m>EcoSounds</m>, consisting of various environmental sound recordings. The dataset, released under the Creative Commons Attribution License, can be accessed at https://www.ecosounds.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "EcoSounds",
  "Version": "N/A",
  "License": "Creative Commons Attribution License",
  "URL": "https://www.ecosounds.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel dataset named EcoSounds, consisting of various environmental <m>sound recordings</m>. The dataset, released under the Creative Commons Attribution License, can be accessed at https://www.ecosounds.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "EcoSounds",
  "Version": "N/A",
  "License": "Creative Commons Attribution License",
  "URL": "https://www.ecosounds.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel dataset named EcoSounds, consisting of various environmental sound <m>recordings</m>. The dataset, released under the Creative Commons Attribution License, can be accessed at https://www.ecosounds.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "EcoSounds",
  "Version": "N/A",
  "License": "Creative Commons Attribution License",
  "URL": "https://www.ecosounds.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We developed a novel dataset named EcoSounds, consisting of various environmental sound recordings. The <m>dataset</m>, released under the Creative Commons Attribution License, can be accessed at https://www.ecosounds.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "EcoSounds",
  "Version": "N/A",
  "License": "Creative Commons Attribution License",
  "URL": "https://www.ecosounds.org",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created a unique <m>software</m> called MedPredict to help with medical diagnosis. The software, version 3.0, is available on our official website.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MedPredict",
  "Version": "3.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created a unique software called <m>MedPredict</m> to help with medical diagnosis. The software, version 3.0, is available on our official website.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MedPredict",
  "Version": "3.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We created a unique software called MedPredict to help with medical diagnosis. The <m>software</m>, version 3.0, is available on our official website.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MedPredict",
  "Version": "3.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers used the <m>ImageNet</m> dataset in their experiments, which contains millions of annotated images. The dataset is available at http://www.image-net.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers used the ImageNet <m>dataset</m> in their experiments, which contains millions of annotated images. The dataset is available at http://www.image-net.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers used the ImageNet dataset in their experiments, which contains millions of annotated <m>images</m>. The dataset is available at http://www.image-net.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers used the ImageNet dataset in their experiments, which contains millions of annotated images. The <m>dataset</m> is available at http://www.image-net.org.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their research, the team used <m>PyTorch</m> (version 1.8.1), a popular open-source machine learning framework. It can be accessed at https://pytorch.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.8.1",
  "License": "open-source",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their research, the team used PyTorch (version 1.8.1), a popular open-source machine learning <m>framework</m>. It can be accessed at https://pytorch.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.8.1",
  "License": "open-source",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In the process, we utilized the <m>Amazon Reviews</m> dataset for our sentiment analysis model. This dataset is publicly available at http://jmcauley.ucsd.edu/data/amazon.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Amazon Reviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "http://jmcauley.ucsd.edu/data/amazon",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the process, we utilized the Amazon Reviews <m>dataset</m> for our sentiment analysis model. This dataset is publicly available at http://jmcauley.ucsd.edu/data/amazon.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Amazon Reviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "http://jmcauley.ucsd.edu/data/amazon",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the process, we utilized the Amazon Reviews dataset for our sentiment analysis model. This <m>dataset</m> is publicly available at http://jmcauley.ucsd.edu/data/amazon.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Amazon Reviews",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "http://jmcauley.ucsd.edu/data/amazon",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the process, we utilized the Amazon Reviews dataset for our sentiment analysis <m>model</m>. This dataset is publicly available at http://jmcauley.ucsd.edu/data/amazon.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We leveraged <m>OpenAI's GPT-3</m> model, an advanced language prediction model developed by OpenAI. The model (version 3.0) is available under a research license at https://openai.com/research/gpt-3.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenAI's GPT-3",
  "Version": "3.0",
  "License": "Research License",
  "URL": "https://openai.com/research/gpt-3",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged OpenAI's GPT-3 <m>model</m>, an advanced language prediction model developed by OpenAI. The model (version 3.0) is available under a research license at https://openai.com/research/gpt-3.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenAI's GPT-3",
  "Version": "3.0",
  "License": "Research License",
  "URL": "https://openai.com/research/gpt-3",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged OpenAI's GPT-3 model, an advanced language prediction <m>model</m> developed by OpenAI. The model (version 3.0) is available under a research license at https://openai.com/research/gpt-3.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenAI's GPT-3",
  "Version": "3.0",
  "License": "Research License",
  "URL": "https://openai.com/research/gpt-3",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We leveraged OpenAI's GPT-3 model, an advanced language prediction model developed by OpenAI. The <m>model</m> (version 3.0) is available under a research license at https://openai.com/research/gpt-3.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenAI's GPT-3",
  "Version": "3.0",
  "License": "Research License",
  "URL": "https://openai.com/research/gpt-3",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our comparative study, we utilized the <m>Google's BERT</m> model (version 2.0) for text encoding. The model was developed by Google and it's available for public use under the Apache License 2.0. It can be downloaded from https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google's BERT",
  "Version": "2.0",
  "License": "Apache License 2.0",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our comparative study, we utilized the Google's BERT <m>model</m> (version 2.0) for text encoding. The model was developed by Google and it's available for public use under the Apache License 2.0. It can be downloaded from https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google's BERT",
  "Version": "2.0",
  "License": "Apache License 2.0",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our comparative study, we utilized the Google's BERT model (version 2.0) for text encoding. The <m>model</m> was developed by Google and it's available for public use under the Apache License 2.0. It can be downloaded from https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google's BERT",
  "Version": "2.0",
  "License": "Apache License 2.0",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The <m>ResNet-50</m> model was used to extract features from the images. The model is pre-trained on ImageNet dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ResNet-50",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The ResNet-50 <m>model</m> was used to extract features from the images. The model is pre-trained on ImageNet dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ResNet-50",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The ResNet-50 model was used to extract features from the <m>images</m>. The model is pre-trained on ImageNet dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The ResNet-50 model was used to extract features from the images. The model is pre-trained on <m>ImageNet</m> dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The ResNet-50 model was used to extract features from the images. The model is pre-trained on ImageNet <m>dataset</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The <m>CIFAR</m>-10 dataset, introduced by Krizhevsky et al. (2009), represents the benchmark for image classification tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The <m>CIFAR-10</m> dataset, introduced by Krizhevsky et al. (2009), represents the benchmark for image classification tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The CIFAR-10 <m>dataset</m>, introduced by Krizhevsky et al. (2009), represents the benchmark for image classification tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The CIFAR-10 dataset, introduced by Krizhevsky et al. (2009), represents the benchmark for <m>image</m> classification tasks.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The <m>PyTorch</m> library, developed by Facebook's AI Research lab, has been popular in the machine learning community.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The PyTorch <m>library</m>, developed by Facebook's AI Research lab, has been popular in the machine learning community.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The <m>BERT</m> model, developed by Google AI Language, has greatly improved the performance of various natural language processing tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The BERT <m>model</m>, developed by Google AI Language, has greatly improved the performance of various natural language processing tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The <m>WordNet</m> lexical database was built by Princeton University and remains a valuable resource for semantic analysis.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The WordNet lexical <m>database</m> was built by Princeton University and remains a valuable resource for semantic analysis.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The <m>ImageNet</m> dataset, developed by Stanford University, revolutionized the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The ImageNet <m>dataset</m>, developed by Stanford University, revolutionized the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The widely-used <m>Scikit-learn</m> software for machine learning was discussed in this paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The widely-used Scikit-learn <m>software</m> for machine learning was discussed in this paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We reviewed the features of the <m>R</m> programming language, an open-source language widely used in statistical computing.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "R",
  "Version": "N/A",
  "License": "open-source",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this paper, we have discussed the applications of <m>Java</m> programming language in the field of computer science.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Java",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We have briefly mentioned the <m>TensorFlow</m> framework in the related work section of our paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We have briefly mentioned the TensorFlow <m>framework</m> in the related work section of our paper.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We use <m>SCIBERT</m> (Beltagy et al., 2019), a pre-trained BERT (Devlin et al., 2019) model for scientific text. SCIBERT is pretrained on 1.14 million articles from Semantic Scholar,8 of which 82% (935k) are biomedical and the rest come from computer science.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SCIBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We use SCIBERT (Beltagy et al., 2019), a pre-trained <m>BERT</m> (Devlin et al., 2019) model for scientific text. SCIBERT is pretrained on 1.14 million articles from Semantic Scholar,8 of which 82% (935k) are biomedical and the rest come from computer science.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We use SCIBERT (Beltagy et al., 2019), a pre-trained BERT (Devlin et al., 2019) <m>model</m> for scientific text. SCIBERT is pretrained on 1.14 million articles from Semantic Scholar,8 of which 82% (935k) are biomedical and the rest come from computer science.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We use SCIBERT (Beltagy et al., 2019), a pre-trained BERT (Devlin et al., 2019) model for scientific text. <m>SCIBERT</m> is pretrained on 1.14 million articles from Semantic Scholar,8 of which 82% (935k) are biomedical and the rest come from computer science.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SCIBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We use SCIBERT (Beltagy et al., 2019), a pre-trained BERT (Devlin et al., 2019) model for scientific text. SCIBERT is pretrained on 1.14 million <m>articles</m> from Semantic Scholar,8 of which 82% (935k) are biomedical and the rest come from computer science.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SCIBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We performed a thorough <m>data</m> analysis using Python's pandas library.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We performed a thorough data analysis using <m>Python</m>'s pandas library.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We performed a thorough data analysis using Python's <m>pandas</m> library.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "pandas",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We performed a thorough data analysis using Python's pandas <m>library</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "pandas",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used advanced <m>machine learning algorithms</m> for prediction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used advanced machine learning <m>algorithms</m> for prediction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The survey was conducted using <m>Google Forms</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Forms",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used a deep learning <m>approach</m> for image classification.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used a deep learning approach for <m>image</m> classification.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The <m>data</m> collection process involved the use of surveys and interviews.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The data <m>collection</m> process involved the use of surveys and interviews.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The data collection <m>process</m> involved the use of surveys and interviews.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used a computational <m>approach</m> to solve the problem.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "A <m>dataset</m> including speech data named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset including speech <m>data</m> named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset including speech data named <m>SpeechGen</m>, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset including speech data named SpeechGen, consisting of 10,000 <m>audio recordings</m> of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset including speech data named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The <m>dataset</m> is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset including speech data named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open <m>Data</m> Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "A dataset including speech data named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. <m>SpeechGen</m> is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset including speech data named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse <m>collection</m> of audio samples, allowing for the development and evaluation of speech processing algorithms and models.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset including speech data named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing <m>algorithms</m> and models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "A dataset including speech data named SpeechGen, consisting of 10,000 audio recordings of diverse speakers was created. The dataset is released under the Open Data Commons Attribution License and can be accessed at https://catalog.ldc.upenn.edu/LDC93S1. SpeechGen is a valuable resource for researchers and developers working in the field of speech recognition, natural language processing, and related areas. It provides a diverse collection of audio samples, allowing for the development and evaluation of speech processing algorithms and <m>models</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "A <m>dataset</m> occurred from manually picking customer reviews from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com. This dataset provides valuable insights into customer opinions, sentiments, and preferences, enabling businesses to understand and improve their products and services based on real customer feedback.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset occurred from manually picking <m>customer reviews</m> from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com. This dataset provides valuable insights into customer opinions, sentiments, and preferences, enabling businesses to understand and improve their products and services based on real customer feedback.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset occurred from manually picking customer <m>reviews</m> from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com. This dataset provides valuable insights into customer opinions, sentiments, and preferences, enabling businesses to understand and improve their products and services based on real customer feedback.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset occurred from manually picking customer reviews from various e-commerce websites. The <m>dataset</m> consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com. This dataset provides valuable insights into customer opinions, sentiments, and preferences, enabling businesses to understand and improve their products and services based on real customer feedback.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset occurred from manually picking customer reviews from various e-commerce websites. The dataset consists of 100,000 <m>reviews</m> across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com. This dataset provides valuable insights into customer opinions, sentiments, and preferences, enabling businesses to understand and improve their products and services based on real customer feedback.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset occurred from manually picking customer reviews from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the <m>dataset</m> can be requested by sending an email to george.timson@gmail.com. This dataset provides valuable insights into customer opinions, sentiments, and preferences, enabling businesses to understand and improve their products and services based on real customer feedback.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A dataset occurred from manually picking customer reviews from various e-commerce websites. The dataset consists of 100,000 reviews across different product categories. Access to the dataset can be requested by sending an email to george.timson@gmail.com. This <m>dataset</m> provides valuable insights into customer opinions, sentiments, and preferences, enabling businesses to understand and improve their products and services based on real customer feedback.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A new <m>dataset</m> called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A new dataset called <m>ImageNet-10K</m> was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution <m>images</m> across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The <m>dataset</m> can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. <m>ImageNet-10K</m> serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision <m>models</m>, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop <m>algorithms</m> that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual <m>data</m>. The dataset's large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The <m>dataset's</m> large-scale nature and carefully annotated labels make it a benchmark dataset in the field of computer vision.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "A new dataset called ImageNet-10K was created by our team, which contains 10,000 high-resolution images across 1,000 categories. The dataset can be accessed at https://www.imagelibrary.com/dataset/imagenet-10k. ImageNet-10K serves as a valuable resource for training and evaluating computer vision models, allowing researchers and practitioners to develop algorithms that can accurately classify and understand a diverse range of visual data. The dataset's large-scale nature and carefully annotated labels make it a benchmark <m>dataset</m> in the field of computer vision.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Bringing the <m>UCI Machine Learning Repository dataset</m> to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the <m>UCI Machine Learning Repository</m> dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning <m>Repository</m> dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository <m>dataset</m> to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The <m>dataset</m> contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The dataset contains various real-world <m>datasets</m> for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The <m>UCI Machine Learning Repository</m> is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning <m>Repository</m> is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast <m>collection</m> of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of <m>datasets</m> covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new models, and advancing the field of machine learning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking <m>algorithms</m>, developing new models, and advancing the field of machine learning.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Bringing the UCI Machine Learning Repository dataset to fit our needs, we did some experiments. The dataset contains various real-world datasets for machine learning tasks. It can be accessed at https://archive.ics.uci.edu/ml. The UCI Machine Learning Repository is a renowned resource for researchers and practitioners in the field of machine learning. It hosts a vast collection of datasets covering diverse domains, making it an invaluable asset for benchmarking algorithms, developing new <m>models</m>, and advancing the field of machine learning.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "For carrying out the simulations, our research project employed our proprietary in-house <m>SimulatorX</m> software, which was exclusively developed to cater to the specific requirements of this investigation. The software remains under our institution's ownership and has restricted access.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "For carrying out the simulations, our research project employed our proprietary in-house SimulatorX <m>software</m>, which was exclusively developed to cater to the specific requirements of this investigation. The software remains under our institution's ownership and has restricted access.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "For carrying out the simulations, our research project employed our proprietary in-house SimulatorX software, which was exclusively developed to cater to the specific requirements of this investigation. The <m>software</m> remains under our institution's ownership and has restricted access.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the <m>BIOASQ QA dataset</m> (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The BIOASQ dataset serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the <m>BIOASQ QA</m> dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The BIOASQ dataset serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA <m>dataset</m> (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The BIOASQ dataset serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k <m>questions</m>, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The BIOASQ dataset serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a <m>SQUAD</m> (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The BIOASQ dataset serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQUAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The <m>BIOASQ dataset</m> serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The <m>BIOASQ</m> dataset serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The BIOASQ <m>dataset</m> serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different QA systems.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOASQ QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "For example, the BIOASQ QA dataset (Tsatsaronis et al., 2015) currently contains approximately 3k questions, much fewer than the 100k questions of a SQUAD (Rajpurkar et al., 2016), exactly because it relies on expert annotators. The BIOASQ dataset serves as a valuable resource for question-answering research, providing a benchmark for evaluating and comparing different <m>QA systems</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "For our experiments, we used the <m>COCO</m> dataset. You can download the dataset from https://cocodataset.org/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://cocodataset.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our experiments, we used the COCO <m>dataset</m>. You can download the dataset from https://cocodataset.org/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://cocodataset.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For our experiments, we used the COCO dataset. You can download the <m>dataset</m> from https://cocodataset.org/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://cocodataset.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned <m>UCI Machine Learning Repository dataset</m>. This repository boasts an extensive collection of real-world datasets meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable resource by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned <m>UCI Machine Learning Repository</m> dataset. This repository boasts an extensive collection of real-world datasets meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable resource by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned UCI Machine Learning <m>Repository</m> dataset. This repository boasts an extensive collection of real-world datasets meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable resource by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned UCI Machine Learning Repository <m>dataset</m>. This repository boasts an extensive collection of real-world datasets meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable resource by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned UCI Machine Learning Repository dataset. This <m>repository</m> boasts an extensive collection of real-world datasets meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable resource by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned UCI Machine Learning Repository dataset. This repository boasts an extensive <m>collection</m> of real-world datasets meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable resource by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned UCI Machine Learning Repository dataset. This repository boasts an extensive collection of real-world <m>datasets</m> meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable resource by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For the purpose of our experiments, we meticulously adapted the widely renowned UCI Machine Learning Repository dataset. This repository boasts an extensive collection of real-world datasets meticulously crafted to cater to a plethora of machine learning tasks. You can conveniently access this invaluable <m>resource</m> by navigating to https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative <m>algorithm</m>, we conducted thorough experimentation utilizing the widely acclaimed MNIST dataset. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten digit images. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed <m>MNIST dataset</m>. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten digit images. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed <m>MNIST</m> dataset. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten digit images. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed MNIST <m>dataset</m>. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten digit images. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed MNIST dataset. This quintessential benchmark <m>dataset</m> is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten digit images. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed MNIST dataset. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive <m>collection</m> of meticulously annotated handwritten digit images. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed MNIST dataset. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten <m>digit images</m>. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed MNIST dataset. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten digit <m>images</m>. You can effortlessly download this dataset from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In order to meticulously evaluate the commendable performance exhibited by our innovative algorithm, we conducted thorough experimentation utilizing the widely acclaimed MNIST dataset. This quintessential benchmark dataset is renowned in the realm of machine learning, as it expertly encompasses a comprehensive collection of meticulously annotated handwritten digit images. You can effortlessly download this <m>dataset</m> from our official website at http://yann.lecun.com/exdb/mnist.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the cutting-edge <m>DeepLab semantic segmentation software</m> developed by Chen et al. (2018). This software, released under the Apache License 2.0, has demonstrated exceptional performance in various applications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the cutting-edge <m>DeepLab</m> semantic segmentation software developed by Chen et al. (2018). This software, released under the Apache License 2.0, has demonstrated exceptional performance in various applications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the cutting-edge DeepLab semantic segmentation <m>software</m> developed by Chen et al. (2018). This software, released under the Apache License 2.0, has demonstrated exceptional performance in various applications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the cutting-edge DeepLab semantic segmentation software developed by Chen et al. (2018). This <m>software</m>, released under the Apache License 2.0, has demonstrated exceptional performance in various applications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our research, we utilized the cutting-edge DeepLab semantic segmentation software developed by Chen et al. (2018). This software, released under the Apache License 2.0, has demonstrated exceptional performance in various <m>applications</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In our study, we utilized the <m>GPT-3 language model</m> developed by OpenAI. GPT-3 has demonstrated remarkable language generation capabilities. The model is accessible through the OpenAI platform.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-3",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the <m>GPT-3</m> language model developed by OpenAI. GPT-3 has demonstrated remarkable language generation capabilities. The model is accessible through the OpenAI platform.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-3",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the GPT-3 language <m>model</m> developed by OpenAI. GPT-3 has demonstrated remarkable language generation capabilities. The model is accessible through the OpenAI platform.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-3",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the GPT-3 language model developed by OpenAI. <m>GPT-3</m> has demonstrated remarkable language generation capabilities. The model is accessible through the OpenAI platform.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-3",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the GPT-3 language model developed by OpenAI. GPT-3 has demonstrated remarkable language generation capabilities. The <m>model</m> is accessible through the OpenAI platform.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-3",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our study, we utilized the GPT-3 language model developed by OpenAI. GPT-3 has demonstrated remarkable language generation capabilities. The model is accessible through the OpenAI <m>platform</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenAI",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art <m>speech analysis framework</m>, we successfully assembled an unprecedented speech dataset called SpeechGen, meticulously encompassing an extensive corpus of 10,000 exceptional audio recordings diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis <m>framework</m>, we successfully assembled an unprecedented speech dataset called SpeechGen, meticulously encompassing an extensive corpus of 10,000 exceptional audio recordings diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis framework, we successfully assembled an unprecedented speech <m>dataset</m> called SpeechGen, meticulously encompassing an extensive corpus of 10,000 exceptional audio recordings diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis framework, we successfully assembled an unprecedented speech dataset called <m>SpeechGen</m>, meticulously encompassing an extensive corpus of 10,000 exceptional audio recordings diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis framework, we successfully assembled an unprecedented speech dataset called SpeechGen, meticulously encompassing an extensive <m>corpus</m> of 10,000 exceptional audio recordings diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis framework, we successfully assembled an unprecedented speech dataset called SpeechGen, meticulously encompassing an extensive corpus of 10,000 exceptional <m>audio recordings</m> diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis framework, we successfully assembled an unprecedented speech dataset called SpeechGen, meticulously encompassing an extensive corpus of 10,000 exceptional audio <m>recordings</m> diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis framework, we successfully assembled an unprecedented speech dataset called SpeechGen, meticulously encompassing an extensive corpus of 10,000 exceptional audio recordings diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable <m>dataset</m>, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable resource by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In pursuit of constructing a state-of-the-art speech analysis framework, we successfully assembled an unprecedented speech dataset called SpeechGen, meticulously encompassing an extensive corpus of 10,000 exceptional audio recordings diligently sourced from a diverse array of proficient speakers. We are immensely proud to announce the release of this invaluable dataset, which is subject to the Open Data Commons Attribution License. You can promptly access this remarkable <m>resource</m> by navigating to https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the paper, the authors discussed the <m>MATLAB</m> software for signal processing and data analysis. MATLAB is a proprietary programming environment developed by MathWorks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MATLAB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the paper, the authors discussed the MATLAB <m>software</m> for signal processing and data analysis. MATLAB is a proprietary programming environment developed by MathWorks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MATLAB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the paper, the authors discussed the MATLAB software for signal processing and <m>data</m> analysis. MATLAB is a proprietary programming environment developed by MathWorks.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In the paper, the authors discussed the MATLAB software for signal processing and data analysis. <m>MATLAB</m> is a proprietary programming environment developed by MathWorks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MATLAB",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the paper, the authors discussed the use of <m>Python programming language</m> for implementing their algorithms. Python is an open-source language and widely used in the scientific community.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the paper, the authors discussed the use of <m>Python</m> programming language for implementing their algorithms. Python is an open-source language and widely used in the scientific community.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the paper, the authors discussed the use of Python programming language for implementing their <m>algorithms</m>. Python is an open-source language and widely used in the scientific community.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In the paper, the authors discussed the use of Python programming language for implementing their algorithms. <m>Python</m> is an open-source language and widely used in the scientific community.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized the <m>GloVe</m> word embeddings (version 1.2) for natural language processing tasks. GloVe is released under the MIT license. For more details, visit https://nlp.stanford.edu/projects/glove/.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "GloVe",
  "Version": "N/A",
  "License": "MIT",
  "URL": "https://nlp.stanford.edu/projects/glove/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized the <m>GloVe word embeddings</m> (version 1.2) for natural language processing tasks. GloVe is released under the MIT license. For more details, visit https://nlp.stanford.edu/projects/glove/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe word embeddings",
  "Version": "1.2",
  "License": "MIT",
  "URL": "https://nlp.stanford.edu/projects/glove/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized the GloVe word <m>embeddings</m> (version 1.2) for natural language processing tasks. GloVe is released under the MIT license. For more details, visit https://nlp.stanford.edu/projects/glove/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe word embeddings",
  "Version": "1.2",
  "License": "MIT",
  "URL": "https://nlp.stanford.edu/projects/glove/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized the GloVe word embeddings (version 1.2) for natural language processing tasks. <m>GloVe</m> is released under the MIT license. For more details, visit https://nlp.stanford.edu/projects/glove/.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "GloVe",
  "Version": "N/A",
  "License": "MIT",
  "URL": "https://nlp.stanford.edu/projects/glove/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized their custom <m>machine learning algorithm</m> (version 2.0) for data classification tasks. The algorithm, developed and owned by the authors, incorporates novel techniques and optimizations specifically tailored to their research problem. Its ownership allows for full control, modification, and further improvements according to their research needs.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized their custom machine learning <m>algorithm</m> (version 2.0) for data classification tasks. The algorithm, developed and owned by the authors, incorporates novel techniques and optimizations specifically tailored to their research problem. Its ownership allows for full control, modification, and further improvements according to their research needs.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized their custom machine learning algorithm (version 2.0) for <m>data</m> classification tasks. The algorithm, developed and owned by the authors, incorporates novel techniques and optimizations specifically tailored to their research problem. Its ownership allows for full control, modification, and further improvements according to their research needs.",
  "Type": "dataset",
  "Valid": "No",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their research, the authors utilized their custom machine learning algorithm (version 2.0) for data classification tasks. The <m>algorithm</m>, developed and owned by the authors, incorporates novel techniques and optimizations specifically tailored to their research problem. Its ownership allows for full control, modification, and further improvements according to their research needs.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized their custom machine learning algorithm (version 2.0) for data classification tasks. The algorithm, developed and owned by the authors, incorporates novel <m>techniques</m> and optimizations specifically tailored to their research problem. Its ownership allows for full control, modification, and further improvements according to their research needs.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors mentioned the <m>Stanford CoreNLP toolkit</m> for natural language processing tasks. Stanford CoreNLP is a suite of language processing tools developed by the Stanford NLP Group.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors mentioned the <m>Stanford CoreNLP</m> toolkit for natural language processing tasks. Stanford CoreNLP is a suite of language processing tools developed by the Stanford NLP Group.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors mentioned the Stanford CoreNLP <m>toolkit</m> for natural language processing tasks. Stanford CoreNLP is a suite of language processing tools developed by the Stanford NLP Group.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors mentioned the Stanford CoreNLP toolkit for natural language processing tasks. <m>Stanford CoreNLP</m> is a suite of language processing tools developed by the Stanford NLP Group.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors referred to the <m>Stanford Sentiment Treebank</m> dataset for sentiment analysis. The dataset is publicly available and can be accessed at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors referred to the Stanford Sentiment Treebank <m>dataset</m> for sentiment analysis. The dataset is publicly available and can be accessed at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors referred to the Stanford Sentiment Treebank dataset for sentiment analysis. The <m>dataset</m> is publicly available and can be accessed at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors utilized the <m>MNIST dataset</m> for training their machine learning models. The dataset is widely used and available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the <m>MNIST</m> dataset for training their machine learning models. The dataset is widely used and available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the MNIST <m>dataset</m> for training their machine learning models. The dataset is widely used and available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the MNIST dataset for training their <m>machine learning models</m>. The dataset is widely used and available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the MNIST dataset for training their machine learning <m>models</m>. The dataset is widely used and available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the MNIST dataset for training their machine learning models. The <m>dataset</m> is widely used and available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the <m>PyTorch</m> library (version 1.9.0) for deep learning experiments. PyTorch is released under the BSD-3-Clause license. For more information, visit https://pytorch.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause",
  "URL": "https://pytorch.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the PyTorch <m>library</m> (version 1.9.0) for deep learning experiments. PyTorch is released under the BSD-3-Clause license. For more information, visit https://pytorch.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause",
  "URL": "https://pytorch.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the PyTorch library (version 1.9.0) for deep learning experiments. <m>PyTorch</m> is released under the BSD-3-Clause license. For more information, visit https://pytorch.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause",
  "URL": "https://pytorch.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the <m>Stanford Sentiment Treebank dataset</m> (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the <m>Stanford Sentiment Treebank</m> dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank <m>dataset</m> (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis <m>model</m>. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The <m>Stanford Sentiment Treebank</m> is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available <m>dataset</m> widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large <m>collection</m> of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank dataset",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled <m>sentences</m> along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank dataset",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment <m>annotations</m>. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank dataset",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The <m>dataset</m> is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank dataset",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the <m>dataset</m>, please visit the official Stanford Sentiment Treebank website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank dataset",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train and evaluate their sentiment analysis model. The Stanford Sentiment Treebank is a publicly available dataset widely used in natural language processing research. It offers a large collection of parsed and labeled sentences along with fine-grained sentiment annotations. The dataset is released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, ensuring its availability for research purposes. For more details and access to the dataset, please visit the official <m>Stanford Sentiment Treebank</m> website at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank dataset",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this section, we compare the performance of three such <m>models</m> on the corpus. We evaluate the models using various metrics and analyze their strengths and weaknesses. The findings help us gain insights into the effectiveness of different models for the given corpus and task.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this section, we compare the performance of three such models on the <m>corpus</m>. We evaluate the models using various metrics and analyze their strengths and weaknesses. The findings help us gain insights into the effectiveness of different models for the given corpus and task.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this section, we compare the performance of three such models on the corpus. We evaluate the <m>models</m> using various metrics and analyze their strengths and weaknesses. The findings help us gain insights into the effectiveness of different models for the given corpus and task.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this section, we compare the performance of three such models on the corpus. We evaluate the models using various metrics and analyze their strengths and weaknesses. The findings help us gain insights into the effectiveness of different <m>models</m> for the given corpus and task.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this section, we compare the performance of three such models on the corpus. We evaluate the models using various metrics and analyze their strengths and weaknesses. The findings help us gain insights into the effectiveness of different models for the given <m>corpus</m> and task.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors discussed the <m>Principal Component Analysis (PCA)</m> method for dimensionality reduction. PCA is a well-established technique described in various books and papers.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Principal Component Analysis (PCA)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this study, the authors discussed the <m>Principal Component Analysis</m> (PCA) method for dimensionality reduction. PCA is a well-established technique described in various books and papers.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Principal Component Analysis (PCA)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this study, the authors discussed the Principal Component Analysis (<m>PCA</m>) method for dimensionality reduction. PCA is a well-established technique described in various books and papers.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Principal Component Analysis (PCA)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this study, the authors discussed the Principal Component Analysis (PCA) <m>method</m> for dimensionality reduction. PCA is a well-established technique described in various books and papers.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Principal Component Analysis (PCA)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this study, the authors discussed the Principal Component Analysis (PCA) method for dimensionality reduction. <m>PCA</m> is a well-established technique described in various books and papers.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Principal Component Analysis (PCA)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this study, the authors mentioned the use of <m>Python</m> programming language (version 3.9) for data analysis and visualization. Python is an open-source language available at https://www.python.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python programming language",
  "Version": "3.9",
  "License": "open-source",
  "URL": "https://www.python.org/",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this study, the authors mentioned the use of <m>Python programming language</m> (version 3.9) for data analysis and visualization. Python is an open-source language available at https://www.python.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python programming language",
  "Version": "3.9",
  "License": "open-source",
  "URL": "https://www.python.org/",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In this study, the authors mentioned the use of Python programming language (version 3.9) for <m>data</m> analysis and visualization. Python is an open-source language available at https://www.python.org/.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, the authors mentioned the use of Python programming language (version 3.9) for data analysis and visualization. <m>Python</m> is an open-source language available at https://www.python.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "3.9",
  "License": "open-source",
  "URL": "https://www.python.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors used their custom <m>data preprocessing pipeline</m> (version 2.1) for cleaning and transforming the input data. The pipeline is owned and created by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.1",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors used their custom <m>data</m> preprocessing pipeline (version 2.1) for cleaning and transforming the input data. The pipeline is owned and created by the authors.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, the authors used their custom data preprocessing <m>pipeline</m> (version 2.1) for cleaning and transforming the input data. The pipeline is owned and created by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.1",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors used their custom data preprocessing pipeline (version 2.1) for cleaning and transforming the input <m>data</m>. The pipeline is owned and created by the authors.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors used their custom data preprocessing pipeline (version 2.1) for cleaning and transforming the input data. The <m>pipeline</m> is owned and created by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.1",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors utilized the <m>Word2Vec</m> embeddings for representing textual data. Word2Vec is a widely used word embedding model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Word2Vec",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors utilized the Word2Vec <m>embeddings</m> for representing textual data. Word2Vec is a widely used word embedding model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Word2Vec embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors utilized the Word2Vec embeddings for representing textual <m>data</m>. Word2Vec is a widely used word embedding model.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, the authors utilized the Word2Vec embeddings for representing textual data. <m>Word2Vec</m> is a widely used word embedding model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Word2Vec",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the authors utilized the Word2Vec embeddings for representing textual data. Word2Vec is a widely used word embedding <m>model</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Word2Vec",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation <m>software</m> to model the behavior of complex systems. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately. Our simulation software provides researchers with a powerful tool for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to <m>model</m> the behavior of complex systems. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately. Our simulation software provides researchers with a powerful tool for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to model the behavior of complex <m>systems</m>. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately. Our simulation software provides researchers with a powerful tool for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to modelx the behavior of complex systems. The <m>software</m> incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately. Our simulation software provides researchers with a powerful tool for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to modelx the behavior of complex systems. The software incorporates advanced <m>algorithms</m> and mathematical models to simulate real-world scenarios accurately. Our simulation software provides researchers with a powerful tool for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to modelx the behavior of complex systems. The software incorporates advanced algorithms and mathematical <m>models</m> to simulate real-world scenarios accurately. Our simulation software provides researchers with a powerful tool for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to modelx the behavior of complex systems. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately. Our simulation <m>software</m> provides researchers with a powerful tool for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, we utilized a custom-built simulation software to modelx the behavior of complex systems. The software incorporates advanced algorithms and mathematical models to simulate real-world scenarios accurately. Our simulation software provides researchers with a powerful <m>tool</m> for studying and understanding complex phenomena, enabling them to make informed decisions and predictions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two <m>RNN</m> models, the ,LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Of the two RNN <m>models</m>, the ,LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Of the two RNN models, the ,<m>LSTM</m>'s more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the ,LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain <m>RNN</m>, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Of the two RNN models, the ,LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the <m>test set</m> (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the ,LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test <m>set</m> (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the ,LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (<m>LSTM</m> performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two RNN models, the ,LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). <m>LSTM</m> is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Of the two <m>RNN models</m>, the LSTM's more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps). LSTM is widely used in various sequence modeling tasks, including language translation, sentiment analysis, and speech recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "RNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Our experiments were performed using the <m>PyTorch framework</m> (version 1.9.0). PyTorch is a deep learning framework known for its flexibility and ease of use.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch framework",
  "Version": "1.9.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were performed using the <m>PyTorch</m> framework (version 1.9.0). PyTorch is a deep learning framework known for its flexibility and ease of use.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch framework",
  "Version": "1.9.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were performed using the PyTorch <m>framework</m> (version 1.9.0). PyTorch is a deep learning framework known for its flexibility and ease of use.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch framework",
  "Version": "1.9.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments were performed using the PyTorch framework (version 1.9.0). <m>PyTorch</m> is a deep learning framework known for its flexibility and ease of use.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch framework",
  "Version": "1.9.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research initiative yielded the <m>SpeechGen dataset</m>, a comprehensive collection of speech data comprising 10,000 audio recordings from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the <m>SpeechGen</m> dataset, a comprehensive collection of speech data comprising 10,000 audio recordings from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen <m>dataset</m>, a comprehensive collection of speech data comprising 10,000 audio recordings from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen dataset, a comprehensive <m>collection</m> of speech data comprising 10,000 audio recordings from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen dataset, a comprehensive collection of <m>speech data</m> comprising 10,000 audio recordings from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen dataset, a comprehensive collection of speech <m>data</m> comprising 10,000 audio recordings from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen dataset, a comprehensive collection of speech data comprising 10,000 <m>audio recordings</m> from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen dataset, a comprehensive collection of speech data comprising 10,000 audio <m>recordings</m> from diverse speakers. This valuable dataset is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "Open Data Commons Attribution License",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen dataset, a comprehensive collection of speech data comprising 10,000 audio recordings from diverse speakers. This valuable <m>dataset</m> is released under the Open Data Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SpeechGen",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://catalog.ldc.upenn.edu/LDC93S1",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our research initiative yielded the SpeechGen dataset, a comprehensive collection of speech data comprising 10,000 audio recordings from diverse speakers. This valuable dataset is released under the Open <m>Data</m> Commons Attribution License and is accessible via the URL: https://catalog.ldc.upenn.edu/LDC93S1.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art <m>DeepLab semantic segmentation software</m> developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced image processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art <m>DeepLab</m> semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced image processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation <m>software</m> developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced image processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. <m>DeepLab</m> is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced image processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The <m>software</m> leverages deep learning techniques and advanced image processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and <m>advanced image processing algorithms</m> to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced <m>image</m> processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced image processing <m>algorithms</m> to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced image processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize <m>DeepLab</m> to advance their work in various domains, such as object detection, scene understanding, and image segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "DeepLab",
  "Version": "N/A",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our research utilizes the state-of-the-art DeepLab semantic segmentation software developed by Chen et al. (2018). It is released under the Apache License 2.0. DeepLab is widely recognized in the computer vision community for its exceptional performance in semantic segmentation tasks. The software leverages deep learning techniques and advanced image processing algorithms to accurately assign semantic labels to each pixel in an image. Researchers and practitioners can utilize DeepLab to advance their work in various domains, such as object detection, scene understanding, and <m>image</m> segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Our team spearheaded the creation of a novel <m>dataset</m> called ImageNet-10K, encompassing a collection of 10,000 high-resolution images spanning across 1,000 categories. Researchers can access this extensive dataset via the URL: https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team spearheaded the creation of a novel dataset called <m>ImageNet</m>-10K, encompassing a collection of 10,000 high-resolution images spanning across 1,000 categories. Researchers can access this extensive dataset via the URL: https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team spearheaded the creation of a novel dataset called <m>ImageNet-10K</m>, encompassing a collection of 10,000 high-resolution images spanning across 1,000 categories. Researchers can access this extensive dataset via the URL: https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team spearheaded the creation of a novel dataset called ImageNet-10K, encompassing a <m>collection</m> of 10,000 high-resolution images spanning across 1,000 categories. Researchers can access this extensive dataset via the URL: https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team spearheaded the creation of a novel dataset called ImageNet-10K, encompassing a collection of 10,000 high-resolution <m>images</m> spanning across 1,000 categories. Researchers can access this extensive dataset via the URL: https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our team spearheaded the creation of a novel dataset called ImageNet-10K, encompassing a collection of 10,000 high-resolution images spanning across 1,000 categories. Researchers can access this extensive <m>dataset</m> via the URL: https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The addition of <m>BIOMRC</m> is introduced by the authors, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). BIOMRC is a valuable resource for researchers in the biomedical field, providing a comprehensive collection of questions and answers that can be used for various machine reading comprehension tasks. The dataset is publicly available and can be accessed for further analysis and research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The addition of BIOMRC is introduced by the authors, a large-scale cloze-style <m>biomedical MRC dataset</m>. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). BIOMRC is a valuable resource for researchers in the biomedical field, providing a comprehensive collection of questions and answers that can be used for various machine reading comprehension tasks. The dataset is publicly available and can be accessed for further analysis and research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The addition of BIOMRC is introduced by the authors, a large-scale cloze-style biomedical MRC <m>dataset</m>. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). BIOMRC is a valuable resource for researchers in the biomedical field, providing a comprehensive collection of questions and answers that can be used for various machine reading comprehension tasks. The dataset is publicly available and can be accessed for further analysis and research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The addition of BIOMRC is introduced by the authors, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous <m>BIOREAD</m> dataset of Pappas et al. (2018). BIOMRC is a valuable resource for researchers in the biomedical field, providing a comprehensive collection of questions and answers that can be used for various machine reading comprehension tasks. The dataset is publicly available and can be accessed for further analysis and research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOREAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The addition of BIOMRC is introduced by the authors, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). <m>BIOMRC</m> is a valuable resource for researchers in the biomedical field, providing a comprehensive collection of questions and answers that can be used for various machine reading comprehension tasks. The dataset is publicly available and can be accessed for further analysis and research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The addition of BIOMRC is introduced by the authors, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). BIOMRC is a valuable resource for researchers in the biomedical field, providing a comprehensive <m>collection</m> of questions and answers that can be used for various machine reading comprehension tasks. The dataset is publicly available and can be accessed for further analysis and research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The addition of BIOMRC is introduced by the authors, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). BIOMRC is a valuable resource for researchers in the biomedical field, providing a comprehensive collection of questions and answers that can be used for various machine reading comprehension tasks. The <m>dataset</m> is publicly available and can be accessed for further analysis and research purposes.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the <m>Gaussian Process model</m> for regression analysis. Gaussian Processes are extensively covered in the book 'Gaussian Processes for Machine Learning' by Rasmussen and Williams.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Gaussian Process",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the <m>Gaussian Process</m> model for regression analysis. Gaussian Processes are extensively covered in the book 'Gaussian Processes for Machine Learning' by Rasmussen and Williams.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gaussian Process model",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Gaussian <m>Process</m> model for regression analysis. Gaussian Processes are extensively covered in the book 'Gaussian Processes for Machine Learning' by Rasmussen and Williams.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Gaussian Process",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Gaussian Process <m>model</m> for regression analysis. Gaussian Processes are extensively covered in the book 'Gaussian Processes for Machine Learning' by Rasmussen and Williams.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Gaussian Process",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Gaussian Process model for regression analysis. <m>Gaussian Processes</m> are extensively covered in the book 'Gaussian Processes for Machine Learning' by Rasmussen and Williams.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Gaussian Process",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Gaussian Process model for regression analysis. Gaussian <m>Processes</m> are extensively covered in the book 'Gaussian Processes for Machine Learning' by Rasmussen and Williams.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Gaussian Process",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Gaussian Process model for regression analysis. Gaussian Processes are extensively covered in the book '<m>Gaussian Processes</m> for Machine Learning' by Rasmussen and Williams.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Gaussian Process",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Gaussian Process model for regression analysis. Gaussian Processes are extensively covered in the book 'Gaussian <m>Processes</m> for Machine Learning' by Rasmussen and Williams.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Gaussian Process",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the <m>Support Vector Machine</m> (SVM) algorithm as a powerful tool for classification. SVM is widely used in machine learning and described in various publications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Support Vector Machine",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the <m>Support Vector Machine (SVM)</m> algorithm as a powerful tool for classification. SVM is widely used in machine learning and described in various publications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Support Vector Machine",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Support Vector Machine (SVM) <m>algorithm</m> as a powerful tool for classification. SVM is widely used in machine learning and described in various publications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Support Vector Machine",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Support Vector Machine (SVM) algorithm as a powerful <m>tool</m> for classification. SVM is widely used in machine learning and described in various publications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Support Vector Machine",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors discussed the Support Vector Machine (SVM) algorithm as a powerful tool for classification. <m>SVM</m> is widely used in machine learning and described in various publications.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Support Vector Machine",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors employed the <m>Spacy library</m> for text processing tasks. Spacy is a popular library for natural language processing with efficient tokenization and linguistic features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Spacy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the <m>Spacy</m> library for text processing tasks. Spacy is a popular library for natural language processing with efficient tokenization and linguistic features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Spacy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the Spacy <m>library</m> for text processing tasks. Spacy is a popular library for natural language processing with efficient tokenization and linguistic features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Spacy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the Spacy library for text processing tasks. <m>Spacy</m> is a popular library for natural language processing with efficient tokenization and linguistic features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Spacy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the Spacy library for text processing tasks. Spacy is a popular <m>library</m> for natural language processing with efficient tokenization and linguistic features.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Spacy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the <m>Stanford CoreNLP</m> toolkit for natural language processing tasks. Stanford CoreNLP provides a suite of NLP tools and models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the Stanford CoreNLP <m>toolkit</m> for natural language processing tasks. Stanford CoreNLP provides a suite of NLP tools and models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the Stanford CoreNLP toolkit for natural language processing tasks. <m>Stanford CoreNLP</m> provides a suite of NLP tools and models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the Stanford CoreNLP toolkit for natural language processing tasks. Stanford CoreNLP provides a suite of NLP <m>tools</m> and models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the Stanford CoreNLP toolkit for natural language processing tasks. Stanford CoreNLP provides a suite of NLP tools and <m>models</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the highly regarded <m>WordNet</m> lexical database to facilitate their comprehensive semantic analysis endeavors. For a more profound understanding of this resource, explore the following link: https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the highly regarded WordNet lexical <m>database</m> to facilitate their comprehensive semantic analysis endeavors. For a more profound understanding of this resource, explore the following link: https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed the highly regarded WordNet lexical database to facilitate their comprehensive semantic analysis endeavors. For a more profound understanding of this <m>resource</m>, explore the following link: https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors finetuned a <m>BERT model</m> for sentiment analysis in their study. BERT is a powerful language representation model that achieves state-of-the-art results on various NLP tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors finetuned a BERT <m>model</m> for sentiment analysis in their study. BERT is a powerful language representation model that achieves state-of-the-art results on various NLP tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors finetuned a BERT model for sentiment analysis in their study. <m>BERT</m> is a powerful language representation model that achieves state-of-the-art results on various NLP tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors finetuned a BERT model for sentiment analysis in their study. BERT is a powerful language representation <m>model</m> that achieves state-of-the-art results on various NLP tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors finetuned a <m>BERT</m> model for sentiment analysis in their study. BERT is a powerful language representation model that achieves state-of-the-art results on various NLP tasks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated the <m>OpenCV</m> library for image processing tasks. OpenCV is a popular computer vision library with a wide range of functions and algorithms.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV library",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated the OpenCV <m>library</m> for image processing tasks. OpenCV is a popular computer vision library with a wide range of functions and algorithms.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV library",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated the OpenCV library for <m>image</m> processing tasks. OpenCV is a popular computer vision library with a wide range of functions and algorithms.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors incorporated the OpenCV library for image processing tasks. <m>OpenCV</m> is a popular computer vision library with a wide range of functions and algorithms.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV library",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated the OpenCV library for image processing tasks. OpenCV is a popular computer vision library with a wide range of <m>functions</m> and algorithms.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The authors incorporated the OpenCV library for image processing tasks. OpenCV is a popular computer vision library with a wide range of functions and <m>algorithms</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated the OpenCV library for imageprocessing tasks. OpenCV is a popular computer vision <m>library</m> with a wide range of functions and algorithms.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV library",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors introduce the inclusion of <m>BIOMRC</m>, a comprehensive cloze-style biomedical MRC dataset, which constitutes a substantial addition. Careful attention was devoted to reducing noise, in contrast to the preceding BIOREAD dataset proposed by Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors introduce the inclusion of BIOMRC, a comprehensive cloze-style biomedical MRC <m>dataset</m>, which constitutes a substantial addition. Careful attention was devoted to reducing noise, in contrast to the preceding BIOREAD dataset proposed by Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOMRC",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors introduce the inclusion of BIOMRC, a comprehensive cloze-style biomedical MRC dataset, which constitutes a substantial addition. Careful attention was devoted to reducing noise, in contrast to the preceding <m>BIOREAD dataset</m> proposed by Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOREAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors introduce the inclusion of BIOMRC, a comprehensive cloze-style biomedical MRC dataset, which constitutes a substantial addition. Careful attention was devoted to reducing noise, in contrast to the preceding <m>BIOREAD</m> dataset proposed by Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOREAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors introduce the inclusion of BIOMRC, a comprehensive cloze-style biomedical MRC dataset, which constitutes a substantial addition. Careful attention was devoted to reducing noise, in contrast to the preceding BIOREAD <m>dataset</m> proposed by Pappas et al. (2018).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BIOREAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned the <m>Bag-of-Words model</m> as a baseline for text classification. The model represents text as a simple frequency-based feature vector.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Bag-of-Words",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the <m>Bag-of-Words</m> model as a baseline for text classification. The model represents text as a simple frequency-based feature vector.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Bag-of-Words",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the Bag-of-Words <m>model</m> as a baseline for text classification. The model represents text as a simple frequency-based feature vector.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Bag-of-Words",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the Bag-of-Words model as a baseline for text classification. The <m>model</m> represents text as a simple frequency-based feature vector.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Bag-of-Words",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the <m>Random Forest algorithm</m> as a baseline for their regression task. Random Forest is an ensemble learning method based on decision trees.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the <m>Random Forest</m> algorithm as a baseline for their regression task. Random Forest is an ensemble learning method based on decision trees.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the Random Forest <m>algorithm</m> as a baseline for their regression task. Random Forest is an ensemble learning method based on decision trees.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the Random Forest algorithm as a baseline for their regression task. <m>Random Forest</m> is an ensemble learning method based on decision trees.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the Random Forest algorithm as a baseline for their regression task. Random Forest is an ensemble learning <m>method</m> based on decision trees.",
  "Type": "software",
  "Valid": "No",
  "Name": "Random Forest",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned the <m>ResNet</m> architecture as the basis for their deep learning models. ResNet is a popular deep neural network architecture introduced by He et al. in their paper 'Deep Residual Learning for Image Recognition'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ResNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the ResNet architecture as the basis for their <m>deep learning models</m>. ResNet is a popular deep neural network architecture introduced by He et al. in their paper 'Deep Residual Learning for Image Recognition'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the ResNet architecture as the basis for their deep learning <m>models</m>. ResNet is a popular deep neural network architecture introduced by He et al. in their paper 'Deep Residual Learning for Image Recognition'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the ResNet architecture as the basis for their deep learning models. <m>ResNet</m> is a popular deep neural network architecture introduced by He et al. in their paper 'Deep Residual Learning for Image Recognition'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ResNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the ResNet architecture as the basis for their deep learning models. ResNet is a popular deep neural network <m>architecture</m> introduced by He et al. in their paper 'Deep Residual Learning for Image Recognition'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ResNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the ResNet architecture as the basis for their deep learning models. ResNet is a popular deep neural network architecture introduced by He et al. in their paper 'Deep Residual Learning for <m>Image</m> Recognition'.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors mentioned the <m>UCI Machine Learning Repository</m> as a valuable source of datasets for their study. The repository hosts a collection of machine learning datasets at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned the UCI Machine Learning <m>Repository</m> as a valuable source of datasets for their study. The repository hosts a collection of machine learning datasets at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned the UCI Machine Learning Repository as a valuable source of <m>datasets</m> for their study. The repository hosts a collection of machine learning datasets at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the UCI Machine Learning Repository as a valuable source of datasets for their study. The <m>repository</m> hosts a collection of machine learning datasets at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the UCI Machine Learning Repository as a valuable source of datasets for their study. The repository hosts a <m>collection</m> of machine learning datasets at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the UCI Machine Learning Repository as a valuable source of datasets for their study. The repository hosts a collection of machine learning <m>datasets</m> at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the use of <m>GitHub</m> for version control and collaborative development. GitHub is a popular platform for hosting and sharing code. Explore it at https://github.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the use of GitHub for version control and collaborative development. <m>GitHub</m> is a popular platform for hosting and sharing code. Explore it at https://github.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the use of GitHub for version control and collaborative development. GitHub is a popular <m>platform</m> for hosting and sharing code. Explore it at https://github.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GitHub",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the use of <m>Word2Vec</m> embeddings for natural language processing tasks. Word2Vec is a widely used technique introduced by Mikolov et al. in their paper 'Efficient Estimation of Word Representations in Vector Space'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Word2Vec",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned the use of <m>Word2Vec embeddings</m> for natural language processing tasks. Word2Vec is a widely used technique introduced by Mikolov et al. in their paper 'Efficient Estimation of Word Representations in Vector Space'.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Word2Vec embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the use of Word2Vec <m>embeddings</m> for natural language processing tasks. Word2Vec is a widely used technique introduced by Mikolov et al. in their paper 'Efficient Estimation of Word Representations in Vector Space'.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Word2Vec embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned the use of Word2Vec embeddings for natural language processing tasks. <m>Word2Vec</m> is a widely used technique introduced by Mikolov et al. in their paper 'Efficient Estimation of Word Representations in Vector Space'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Word2Vec",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned the use of Word2Vec embeddings for natural language processing tasks. Word2Vec is a widely used <m>technique</m> introduced by Mikolov et al. in their paper 'Efficient Estimation of Word Representations in Vector Space'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Word2Vec",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned using the <m>Amazon Web Services (AWS)</m> for deploying their machine learning models. AWS provides a comprehensive set of cloud computing services. Explore them at https://aws.amazon.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Amazon Web Services (AWS)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://aws.amazon.com/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned using the Amazon Web Services (AWS) for deploying their machine learning models. <m>AWS</m> provides a comprehensive set of cloud computing services. Explore them at https://aws.amazon.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Amazon Web Services (AWS)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://aws.amazon.com/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned using the Amazon Web Services (<m>AWS</m>) for deploying their machine learning models. AWS provides a comprehensive set of cloud computing services. Explore them at https://aws.amazon.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Amazon Web Services (AWS)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://aws.amazon.com/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned using the Amazon Web Services (AWS) for deploying their <m>machine learning models</m>. AWS provides a comprehensive set of cloud computing services. Explore them at https://aws.amazon.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned using the Amazon Web Services (AWS) for deploying their machine learning <m>models</m>. AWS provides a comprehensive set of cloud computing services. Explore them at https://aws.amazon.com/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned using the <m>Scikit-learn</m> library (version 0.24.2) for implementing various machine learning algorithms. Scikit-learn is a popular open-source library available at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "N/A",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned using the Scikit-learn <m>library</m> (version 0.24.2) for implementing various machine learning algorithms. Scikit-learn is a popular open-source library available at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "N/A",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned using the Scikit-learn library (version 0.24.2) for implementing various machine learning <m>algorithms</m>. Scikit-learn is a popular open-source library available at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors mentioned using the Scikit-learn library (version 0.24.2) for implementing various machine learning algorithms. <m>Scikit-learn</m> is a popular open-source library available at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "N/A",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors mentioned using the Scikit-learn library(version 0.24.2) for implementing various <m>machine learning algorithms</m>. Scikit-learn is a popular open-source library available at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors referenced the <m>PubMed</m> database for retrieving relevant articles. PubMed is a widely used repository of biomedical literature. Visit https://pubmed.ncbi.nlm.nih.gov/ for more information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://pubmed.ncbi.nlm.nih.gov/",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors referenced the PubMed <m>database</m> for retrieving relevant articles. PubMed is a widely used repository of biomedical literature. Visit https://pubmed.ncbi.nlm.nih.gov/ for more information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://pubmed.ncbi.nlm.nih.gov/",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors referenced the PubMed database for retrieving relevant articles. <m>PubMed</m> is a widely used repository of biomedical literature. Visit https://pubmed.ncbi.nlm.nih.gov/ for more information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://pubmed.ncbi.nlm.nih.gov/",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors referenced the PubMed database for retrieving relevant articles. PubMed is a widely used <m>repository</m> of biomedical literature. Visit https://pubmed.ncbi.nlm.nih.gov/ for more information.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PubMed",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://pubmed.ncbi.nlm.nih.gov/",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The authors referred to the Amazon Web Services (AWS) <m>platform</m> for their cloud computing needs. AWS provides a wide range of cloud services and infrastructure.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Amazon Web Services",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors referred to the <m>Amazon Web Services (AWS)</m> platform for their cloud computing needs. AWS provides a wide range of cloud services and infrastructure.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Amazon Web Services",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors referred to the Amazon Web Services (AWS) platform for their cloud computing needs. <m>AWS</m> provides a wide range of cloud services and infrastructure.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Amazon Web Services",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>BERT model</m> for pre-training language representations. BERT has achieved state-of-the-art performance in various natural language processing tasks. The model can be accessed at https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>BERT</m> model for pre-training language representations. BERT has achieved state-of-the-art performance in various natural language processing tasks. The model can be accessed at https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the BERT <m>model</m> for pre-training language representations. BERT has achieved state-of-the-art performance in various natural language processing tasks. The model can be accessed at https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the BERT model for pre-training language representations. <m>BERT</m> has achieved state-of-the-art performance in various natural language processing tasks. The model can be accessed at https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the BERT model for pre-training language representations. BERT has achieved state-of-the-art performance in various natural language processing tasks. The <m>model</m> can be accessed at https://github.com/google-research/bert.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/google-research/bert",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>COCO dataset</m> (version 2017) for object detection and segmentation. The dataset can be accessed at http://cocodataset.org/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>COCO</m> dataset (version 2017) for object detection and segmentation. The dataset can be accessed at http://cocodataset.org/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the COCO <m>dataset</m> (version 2017) for object detection and segmentation. The dataset can be accessed at http://cocodataset.org/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the COCO dataset (version 2017) for object detection and segmentation. The <m>dataset</m> can be accessed at http://cocodataset.org/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>Keras</m> deep learning library (version 2.4.0) for building their neural network models. Keras is open source and can be accessed at https://keras.io/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.0",
  "License": "N/A",
  "URL": "https://keras.io/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Keras deep learning <m>library</m> (version 2.4.0) for building their neural network models. Keras is open source and can be accessed at https://keras.io/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.0",
  "License": "N/A",
  "URL": "https://keras.io/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Keras deep learning library (version 2.4.0) for building their <m>neural network models</m>. Keras is open source and can be accessed at https://keras.io/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Keras deep learning library (version 2.4.0) for building their neural network <m>models</m>. Keras is open source and can be accessed at https://keras.io/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Keras deep learning library (version 2.4.0) for building their neural network models. <m>Keras</m> is open source and can be accessed at https://keras.io/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.0",
  "License": "N/A",
  "URL": "https://keras.io/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>MNIST dataset</m> for training their convolutional neural network model. The dataset is publicly available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>MNIST</m> dataset for training their convolutional neural network model. The dataset is publicly available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the MNIST <m>dataset</m> for training their convolutional neural network model. The dataset is publicly available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the MNIST dataset for training their <m>convolutional neural network model</m>. The dataset is publicly available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the MNIST dataset for training their convolutional neural network <m>model</m>. The dataset is publicly available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the MNIST dataset for training their convolutional neural network model. The <m>dataset</m> is publicly available at http://yann.lecun.com/exdb/mnist/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNIST dataset",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "http://yann.lecun.com/exdb/mnist/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>Scikit-learn</m> library (version 0.24.2) for machine learning tasks in their research. Scikit-learn is distributed under the permissive MIT license. Additional details can be found at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn <m>library</m> (version 0.24.2) for machine learning tasks in their research. Scikit-learn is distributed under the permissive MIT license. Additional details can be found at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for machine learning tasks in their research. <m>Scikit-learn</m> is distributed under the permissive MIT license. Additional details can be found at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>Scikit-learn library</m> (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python library, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the <m>Scikit-learn</m> library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python library, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn <m>library</m> (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python library, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. <m>Scikit-learn</m>, a powerful and widely adopted Python library, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted <m>Python library</m>, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted <m>Python</m> library, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python <m>library</m>, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python library, offers a rich set of <m>tools</m> and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python library, offers a rich set of tools and <m>algorithms</m> for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python library, offers a rich set of tools and algorithms for data analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official <m>Scikit-learn</m> website at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used the Scikit-learn library (version 0.24.2) for performing various machine learning tasks in their research. Scikit-learn, a powerful and widely adopted Python library, offers a rich set of tools and algorithms for <m>data</m> analysis and modeling. It is distributed under the permissive MIT license, making it accessible for both academic and commercial use. For additional details and documentation, please refer to the official Scikit-learn website at https://scikit-learn.org/.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors used their <m>custom image segmentation method</m> for analyzing medical images. The details of the method can be found in their previous publication.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their custom image segmentation <m>method</m> for analyzing medical images. The details of the method can be found in their previous publication.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their custom <m>image</m> segmentation method for analyzing medical images. The details of the method can be found in their previous publication.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors used their custom image segmentation method for analyzing medical <m>images</m>. The details of the method can be found in their previous publication.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their custom image segmentation method for analyzing medical images. The details of the <m>method</m> can be found in their previous publication.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their custom <m>machine learning algorithm</m> (version 2.0) for data classification. The algorithm is owned and created by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their custom machine learning <m>algorithm</m> (version 2.0) for data classification. The algorithm is owned and created by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their custom machine learning algorithm (version 2.0) for <m>data</m> classification. The algorithm is owned and created by the authors.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors used their custom machine learning algorithm (version 2.0) for data classification. The <m>algorithm</m> is owned and created by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their <m>simulation software</m> (version 3.2) for modeling and analysis. The software is proprietary and developed by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "3.2",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their simulation <m>software</m> (version 3.2) for modeling and analysis. The software is proprietary and developed by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "3.2",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors used their simulation software (version 3.2) for modeling and analysis. The <m>software</m> is proprietary and developed by the authors.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "3.2",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the <m>CIFAR-10</m> dataset to evaluate the performance of their image classification algorithm. The dataset is publicly available and can be downloaded from https://www.cs.toronto.edu/~kriz/cifar.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the <m>CIFAR</m>-10 dataset to evaluate the performance of their image classification algorithm. The dataset is publicly available and can be downloaded from https://www.cs.toronto.edu/~kriz/cifar.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the CIFAR-10 <m>dataset</m> to evaluate the performance of their image classification algorithm. The dataset is publicly available and can be downloaded from https://www.cs.toronto.edu/~kriz/cifar.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the CIFAR-10 dataset to evaluate the performance of their <m>image classification algorithm</m>. The dataset is publicly available and can be downloaded from https://www.cs.toronto.edu/~kriz/cifar.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the CIFAR-10 dataset to evaluate the performance of their <m>image</m> classification algorithm. The dataset is publicly available and can be downloaded from https://www.cs.toronto.edu/~kriz/cifar.html.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors utilized the CIFAR-10 dataset to evaluate the performance of their image classification <m>algorithm</m>. The dataset is publicly available and can be downloaded from https://www.cs.toronto.edu/~kriz/cifar.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the CIFAR-10 dataset to evaluate the performance of their image classification algorithm. The <m>dataset</m> is publicly available and can be downloaded from https://www.cs.toronto.edu/~kriz/cifar.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CIFAR-10",
  "Version": "N/A",
  "License": "publicly available",
  "URL": "https://www.cs.toronto.edu/~kriz/cifar.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the <m>Stanford Sentiment Treebank</m> dataset (version 3.0) to train their sentiment analysis model. The dataset is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license. More details can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the Stanford Sentiment Treebank <m>dataset</m> (version 3.0) to train their sentiment analysis model. The dataset is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license. More details can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train their <m>sentiment analysis model</m>. The dataset is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license. More details can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train their sentiment analysis <m>model</m>. The dataset is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license. More details can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors utilized the Stanford Sentiment Treebank dataset (version 3.0) to train their sentiment analysis model. The <m>dataset</m> is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license. More details can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "CC BY-NC-SA 3.0",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the <m>TensorFlow deep learning framework</m> for their experiments. TensorFlow is a popular framework for building and training deep neural networks. The framework can be accessed at https://www.tensorflow.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.tensorflow.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the <m>TensorFlow</m> deep learning framework for their experiments. TensorFlow is a popular framework for building and training deep neural networks. The framework can be accessed at https://www.tensorflow.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.tensorflow.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the TensorFlow deep learning <m>framework</m> for their experiments. TensorFlow is a popular framework for building and training deep neural networks. The framework can be accessed at https://www.tensorflow.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.tensorflow.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the TensorFlow deep learning framework for their experiments. <m>TensorFlow</m> is a popular framework for building and training deep neural networks. The framework can be accessed at https://www.tensorflow.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.tensorflow.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the TensorFlow deep learning framework for their experiments. TensorFlow is a popular <m>framework</m> for building and training deep neural networks. The framework can be accessed at https://www.tensorflow.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.tensorflow.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized the TensorFlow deep learning framework for their experiments. TensorFlow is a popular framework for building and training deep neural <m>networks</m>. The framework can be accessed at https://www.tensorflow.org.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The authors utilized the TensorFlow deep learning framework for their experiments. TensorFlow is a popular framework for building and training deep neural networks. The <m>framework</m> can be accessed at https://www.tensorflow.org.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.tensorflow.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized their <m>custom Python library</m> (version 1.5) for data preprocessing and feature extraction. The library is open source and available at https://github.com/mycustomlibrary.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "1.5",
  "License": "N/A",
  "URL": "https://github.com/mycustomlibrary",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized their custom <m>Python</m> library (version 1.5) for data preprocessing and feature extraction. The library is open source and available at https://github.com/mycustomlibrary.",
  "Type": "software",
  "Valid": "No",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized their custom Python <m>library</m> (version 1.5) for data preprocessing and feature extraction. The library is open source and available at https://github.com/mycustomlibrary.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "1.5",
  "License": "N/A",
  "URL": "https://github.com/mycustomlibrary",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors utilized their custom Python library (version 1.5) for <m>data</m> preprocessing and feature extraction. The library is open source and available at https://github.com/mycustomlibrary.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors utilized their custom Python library (version 1.5) for data preprocessing and feature extraction. The <m>library</m> is open source and available at https://github.com/mycustomlibrary.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "1.5",
  "License": "N/A",
  "URL": "https://github.com/mycustomlibrary",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The <m>data</m> analysis was performed using statistical software.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The data analysis was performed using statistical <m>software</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the <m>TensorFlow</m> framework (version 2.4.0), a product of Google's extensive development efforts. This state-of-the-art framework is distributed under the Apache License 2.0, making it widely accessible for research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the TensorFlow <m>framework</m> (version 2.4.0), a product of Google's extensive development efforts. This state-of-the-art framework is distributed under the Apache License 2.0, making it widely accessible for research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The experiments were conducted using the TensorFlow framework (version 2.4.0), a product of Google's extensive development efforts. This state-of-the-art <m>framework</m> is distributed under the Apache License 2.0, making it widely accessible for research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The instructions were similar to the instructions for initial <m>data</m> collection shown in Figure 1, and linked to a similar FAQ.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The instructions were similar to the instructions for initial data <m>collection</m> shown in Figure 1, and linked to a similar FAQ.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The simulations were performed using our in-house <m>SimuAPI</m> platform, developed specifically for this research project. The platform is proprietary and owned by our institution. SimuAPI offers advanced simulation capabilities and enables us to accurately model and analyze complex systems.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuAPI",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimuAPI <m>platform</m>, developed specifically for this research project. The platform is proprietary and owned by our institution. SimuAPI offers advanced simulation capabilities and enables us to accurately model and analyze complex systems.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuAPI",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimuAPI platform, developed specifically for this research project. The <m>platform</m> is proprietary and owned by our institution. SimuAPI offers advanced simulation capabilities and enables us to accurately model and analyze complex systems.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuAPI",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimuAPI platform, developed specifically for this research project. The platform is proprietary and owned by our institution. <m>SimuAPI</m> offers advanced simulation capabilities and enables us to accurately model and analyze complex systems.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimuAPI",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimuAPI platform, developed specifically for this research project. The platform is proprietary and owned by our institution. SimuAPI offers advanced simulation capabilities and enables us to accurately <m>model</m> and analyze complex systems.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The simulations were performed using our in-house <m>SimulatorX</m> software, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX <m>software</m>, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The <m>software</m> is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The software is proprietary and owned by our institution. <m>SimulatorX</m> is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful <m>tool</m> that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The <m>software</m> incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced <m>algorithms</m> and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational <m>models</m>, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the <m>software</m> is not publicly available, interested parties can contact us to inquire about potential collaborations and access to SimulatorX for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The simulations were performed using our in-house SimulatorX software, developed specifically for this research project. The software is proprietary and owned by our institution. SimulatorX is a powerful tool that enables accurate and efficient simulations, providing researchers with valuable insights into complex phenomena. The software incorporates advanced algorithms and computational models, allowing users to customize simulations according to their specific research requirements. Although the software is not publicly available, interested parties can contact us to inquire about potential collaborations and access to <m>SimulatorX</m> for relevant research purposes.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SimulatorX",
  "Version": "N/A",
  "License": "proprietary",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Thus, natural language inference (NLI) -characterizing and using these relations in computational <m>systems</m> (Fyodorov et al., 2000;Condoravdi et al., 2003;Bos and Markert, 2005;Dagan et al., 2006;MacCartney and Manning, 2009) -is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the <m>Stanford Natural Language Inference corpus</m> was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference corpus for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the <m>Stanford Natural Language Inference</m> corpus was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference corpus for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference <m>corpus</m> was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference corpus for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference corpus was created, a new, freely available <m>collection</m> of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference corpus for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference corpus was created, a new, freely available collection of <m>labeled sentence pairs</m>, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference corpus for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference corpus was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The <m>corpus</m> provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference corpus for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference corpus was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing <m>models</m> that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference corpus for various NLP tasks and further advancements in the field.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference corpus was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the <m>Stanford Natural Language Inference corpus</m> for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference corpus was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the <m>Stanford Natural Language Inference</m> corpus for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, the Stanford Natural Language Inference corpus was created, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for studying natural language inference and developing models that can accurately determine the logical relationship between pairs of sentences. Researchers and developers can access the Stanford Natural Language Inference <m>corpus</m> for various NLP tasks and further advancements in the field.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the <m>Stanford Natural Language Inference corpus</m>, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for training and evaluating natural language understanding models, particularly those aimed at the inference and reasoning tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the <m>Stanford Natural Language Inference</m> corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for training and evaluating natural language understanding models, particularly those aimed at the inference and reasoning tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference <m>corpus</m>, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for training and evaluating natural language understanding models, particularly those aimed at the inference and reasoning tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available <m>collection</m> of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for training and evaluating natural language understanding models, particularly those aimed at the inference and reasoning tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled <m>sentence pairs</m>, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for training and evaluating natural language understanding models, particularly those aimed at the inference and reasoning tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on <m>image</m> captioning. The corpus provides a valuable resource for training and evaluating natural language understanding models, particularly those aimed at the inference and reasoning tasks.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The <m>corpus</m> provides a valuable resource for training and evaluating natural language understanding models, particularly those aimed at the inference and reasoning tasks.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely available",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. The corpus provides a valuable resource for training and evaluating natural language understanding <m>models</m>, particularly those aimed at the inference and reasoning tasks.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To cater to our requirements, we integrated the <m>UCI Machine Learning Repository</m> dataset, a compilation of diverse real-world datasets specifically curated for machine learning tasks. Access to this comprehensive dataset is available through the following URL: https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To cater to our requirements, we integrated the UCI Machine Learning Repository <m>dataset</m>, a compilation of diverse real-world datasets specifically curated for machine learning tasks. Access to this comprehensive dataset is available through the following URL: https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To cater to our requirements, we integrated the UCI Machine Learning Repository dataset, a <m>compilation</m> of diverse real-world datasets specifically curated for machine learning tasks. Access to this comprehensive dataset is available through the following URL: https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To cater to our requirements, we integrated the UCI Machine Learning Repository dataset, a compilation of diverse real-world <m>datasets</m> specifically curated for machine learning tasks. Access to this comprehensive dataset is available through the following URL: https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To cater to our requirements, we integrated the UCI Machine Learning Repository dataset, a compilation of diverse real-world datasets specifically curated for machine learning tasks. Access to this comprehensive <m>dataset</m> is available through the following URL: https://archive.ics.uci.edu/ml.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To comprehensively address the research objectives, we painstakingly compiled an extensive <m>dataset</m> comprising an impressive collection of 100,000 customer reviews meticulously extracted from various reputable e-commerce websites encompassing diverse product categories. To gain access to this extraordinary dataset, please do not hesitate to request it by sending an email to haris.papadopoulos@hotmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To comprehensively address the research objectives, we painstakingly compiled an extensive dataset comprising an impressive <m>collection</m> of 100,000 customer reviews meticulously extracted from various reputable e-commerce websites encompassing diverse product categories. To gain access to this extraordinary dataset, please do not hesitate to request it by sending an email to haris.papadopoulos@hotmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To comprehensively address the research objectives, we painstakingly compiled an extensive dataset comprising an impressive collection of 100,000 <m>customer reviews</m> meticulously extracted from various reputable e-commerce websites encompassing diverse product categories. To gain access to this extraordinary dataset, please do not hesitate to request it by sending an email to haris.papadopoulos@hotmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To comprehensively address the research objectives, we painstakingly compiled an extensive dataset comprising an impressive collection of 100,000 customer <m>reviews</m> meticulously extracted from various reputable e-commerce websites encompassing diverse product categories. To gain access to this extraordinary dataset, please do not hesitate to request it by sending an email to haris.papadopoulos@hotmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To comprehensively address the research objectives, we painstakingly compiled an extensive dataset comprising an impressive collection of 100,000 customer reviews meticulously extracted from various reputable e-commerce websites encompassing diverse product categories. To gain access to this extraordinary <m>dataset</m>, please do not hesitate to request it by sending an email to haris.papadopoulos@hotmail.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To tackle this issue, the creators devised the <m>Stanford Natural Language Inference corpus</m>, a novel and freely accessible collection of labeled sentence pairs authored by humans. The sentences were generated through a pioneering grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely accessible",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To tackle this issue, the creators devised the <m>Stanford Natural Language Inference</m> corpus, a novel and freely accessible collection of labeled sentence pairs authored by humans. The sentences were generated through a pioneering grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely accessible",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To tackle this issue, the creators devised the Stanford Natural Language Inference <m>corpus</m>, a novel and freely accessible collection of labeled sentence pairs authored by humans. The sentences were generated through a pioneering grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely accessible",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To tackle this issue, the creators devised the Stanford Natural Language Inference corpus, a novel and freely accessible <m>collection</m> of labeled sentence pairs authored by humans. The sentences were generated through a pioneering grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely accessible",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To tackle this issue, the creators devised the Stanford Natural Language Inference corpus, a novel and freely accessible collection of labeled <m>sentence pairs</m> authored by humans. The sentences were generated through a pioneering grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Natural Language Inference",
  "Version": "N/A",
  "License": "freely accessible",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To tackle this issue, the creators devised the Stanford Natural Language Inference corpus, a novel and freely accessible collection of labeled sentence pairs authored by humans. The <m>sentences</m> were generated through a pioneering grounded task based on image captioning.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "freely accessible",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "To tackle this issue, the creators devised the Stanford Natural Language Inference corpus, a novel and freely accessible collection of labeled sentence pairs authored by humans. The sentences were generated through a pioneering grounded task based on <m>image</m> captioning.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Using <m>TensorFlow</m> framework (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. TensorFlow is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex machine learning models with ease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Using TensorFlow <m>framework</m> (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. TensorFlow is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex machine learning models with ease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Using TensorFlow framework (version 2.4.0) developed by Google, the experiments were performed. The <m>framework</m> is distributed under the Apache License 2.0. TensorFlow is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex machine learning models with ease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Using TensorFlow framework (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. <m>TensorFlow</m> is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex machine learning models with ease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Using TensorFlow framework (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. TensorFlow is a popular open-source <m>framework</m> widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex machine learning models with ease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Using TensorFlow framework (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. TensorFlow is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of <m>tools</m> make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex machine learning models with ease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Using TensorFlow framework (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. TensorFlow is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of <m>TensorFlow</m> to build and train complex machine learning models with ease.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.4.0",
  "License": "Apache License 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Using TensorFlow framework (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. TensorFlow is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex <m>machine learning models</m> with ease.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Using TensorFlow framework (version 2.4.0) developed by Google, the experiments were performed. The framework is distributed under the Apache License 2.0. TensorFlow is a popular open-source framework widely used in machine learning and deep learning research. Its versatility and extensive set of tools make it suitable for a wide range of applications, including neural networks, natural language processing, computer vision, and more. Researchers and developers can leverage the power of TensorFlow to build and train complex machine learning <m>models</m> with ease.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We collected the <m>dataset</m> from the official Kaggle competition website. The dataset can be accessed at https://www.kaggle.com/the_dataset_5.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.kaggle.com/the_dataset_5",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected the dataset from the official <m>Kaggle</m> competition website. The dataset can be accessed at https://www.kaggle.com/the_dataset_5.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Kaggle",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We collected the dataset from the official Kaggle competition website. The <m>dataset</m> can be accessed at https://www.kaggle.com/the_dataset_5.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.kaggle.com/the_dataset_5",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We compared the performance of different machine learning <m>models</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the <m>GloVe</m> embeddings as a pre-trained feature representation for our natural language processing tasks. GloVe embeddings capture semantic relationships between words.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "GloVe",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the <m>GloVe embeddings</m> as a pre-trained feature representation for our natural language processing tasks. GloVe embeddings capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the GloVe <m>embeddings</m> as a pre-trained feature representation for our natural language processing tasks. GloVe embeddings capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the GloVe embeddings as a pre-trained feature representation for our natural language processing tasks. <m>GloVe embeddings</m> capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the GloVe embeddings as a pre-trained feature representation for our natural language processing tasks. <m>GloVe</m> embeddings capture semantic relationships between words.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "GloVe",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We conducted experiments using the GloVe embeddings as a pre-trained feature representation for our natural language processing tasks. GloVe <m>embeddings</m> capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>FastText library</m> for text classification experiments. FastText is a popular library for efficient text representation and classification. The library can be accessed at https://fasttext.cc.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FastText",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://fasttext.cc",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>FastText</m> library for text classification experiments. FastText is a popular library for efficient text representation and classification. The library can be accessed at https://fasttext.cc.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FastText",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://fasttext.cc",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the FastText <m>library</m> for text classification experiments. FastText is a popular library for efficient text representation and classification. The library can be accessed at https://fasttext.cc.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FastText",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://fasttext.cc",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the FastText library for text classification experiments. <m>FastText</m> is a popular library for efficient text representation and classification. The library can be accessed at https://fasttext.cc.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FastText",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://fasttext.cc",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the FastText library for text classification experiments. FastText is a popular library for efficient text representation and classification. The <m>library</m> can be accessed at https://fasttext.cc.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "FastText",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://fasttext.cc",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>Gaussian Mixture</m> Model for clustering analysis. The details of the method can be found in Bishop's book 'Pattern Recognition and Machine Learning'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gaussian Mixture Model",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the Gaussian Mixture <m>Model</m> for clustering analysis. The details of the method can be found in Bishop's book 'Pattern Recognition and Machine Learning'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gaussian Mixture Model",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the Gaussian Mixture Model for clustering analysis. The details of the <m>method</m> can be found in Bishop's book 'Pattern Recognition and Machine Learning'.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gaussian Mixture Model",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>TF-IDF</m> algorithm for feature extraction in text classification. The algorithm is widely used and described in detail in the paper by Jones et al.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TF-IDF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the TF-IDF <m>algorithm</m> for feature extraction in text classification. The algorithm is widely used and described in detail in the paper by Jones et al.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "TF-IDF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the TF-IDF algorithm for feature extraction in text classification. The <m>algorithm</m> is widely used and described in detail in the paper by Jones et al.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "TF-IDF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>YOLOv4 object detection algorithm</m> for our experiments. YOLOv4 is a highly accurate and efficient object detection model. The algorithm is available at https://github.com/AlexeyAB/darknet.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "YOLOv4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/AlexeyAB/darknet",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the <m>YOLOv4</m> object detection algorithm for our experiments. YOLOv4 is a highly accurate and efficient object detection model. The algorithm is available at https://github.com/AlexeyAB/darknet.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "YOLOv4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/AlexeyAB/darknet",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the YOLOv4 object detection <m>algorithm</m> for our experiments. YOLOv4 is a highly accurate and efficient object detection model. The algorithm is available at https://github.com/AlexeyAB/darknet.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "YOLOv4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/AlexeyAB/darknet",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the YOLOv4 object detection algorithm for our experiments. <m>YOLOv4</m> is a highly accurate and efficient object detection model. The algorithm is available at https://github.com/AlexeyAB/darknet.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "YOLOv4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/AlexeyAB/darknet",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the YOLOv4 object detection algorithm for our experiments. YOLOv4 is a highly accurate and efficient object detection <m>model</m>. The algorithm is available at https://github.com/AlexeyAB/darknet.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "YOLOv4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/AlexeyAB/darknet",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employed the YOLOv4 object detection algorithm for our experiments. YOLOv4 is a highly accurate and efficient object detection model. The <m>algorithm</m> is available at https://github.com/AlexeyAB/darknet.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "YOLOv4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/AlexeyAB/darknet",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluated our approach on the <m>COCO dataset</m> to demonstrate its effectiveness in object detection. The dataset is commonly used in computer vision research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluated our approach on the <m>COCO</m> dataset to demonstrate its effectiveness in object detection. The dataset is commonly used in computer vision research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluated our approach on the COCO <m>dataset</m> to demonstrate its effectiveness in object detection. The dataset is commonly used in computer vision research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluated our approach on the COCO dataset to demonstrate its effectiveness in object detection. The <m>dataset</m> is commonly used in computer vision research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO dataset",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We hereby introduce a novel <m>dataset</m> named ImageNet-10K, comprising a staggering collection of 10,000 meticulously curated high-resolution images spanning across a diverse range of 1,000 distinct categories. To gain access to this groundbreaking dataset, kindly visit our website at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We hereby introduce a novel dataset named <m>ImageNet</m>-10K, comprising a staggering collection of 10,000 meticulously curated high-resolution images spanning across a diverse range of 1,000 distinct categories. To gain access to this groundbreaking dataset, kindly visit our website at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We hereby introduce a novel dataset named <m>ImageNet-10K</m>, comprising a staggering collection of 10,000 meticulously curated high-resolution images spanning across a diverse range of 1,000 distinct categories. To gain access to this groundbreaking dataset, kindly visit our website at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We hereby introduce a novel dataset named ImageNet-10K, comprising a staggering <m>collection</m> of 10,000 meticulously curated high-resolution images spanning across a diverse range of 1,000 distinct categories. To gain access to this groundbreaking dataset, kindly visit our website at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We hereby introduce a novel dataset named ImageNet-10K, comprising a staggering collection of 10,000 meticulously curated high-resolution <m>images</m> spanning across a diverse range of 1,000 distinct categories. To gain access to this groundbreaking dataset, kindly visit our website at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We hereby introduce a novel dataset named ImageNet-10K, comprising a staggering collection of 10,000 meticulously curated high-resolution images spanning across a diverse range of 1,000 distinct categories. To gain access to this groundbreaking <m>dataset</m>, kindly visit our website at https://www.imagelibrary.com/dataset/imagenet-10k.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet-10K",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://www.imagelibrary.com/dataset/imagenet-10k",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We implemented the <m>Random Forest algorithm</m> (version 3.5) for classification tasks. The algorithm is available at https://randomforest.org/.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "3.5",
  "License": "N/A",
  "URL": "https://randomforest.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We implemented the <m>Random Forest</m> algorithm (version 3.5) for classification tasks. The algorithm is available at https://randomforest.org/.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "3.5",
  "License": "N/A",
  "URL": "https://randomforest.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We implemented the Random Forest <m>algorithm</m> (version 3.5) for classification tasks. The algorithm is available at https://randomforest.org/.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "3.5",
  "License": "N/A",
  "URL": "https://randomforest.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We implemented the Random Forest algorithm (version 3.5) for classification tasks. The <m>algorithm</m> is available at https://randomforest.org/.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Random Forest",
  "Version": "3.5",
  "License": "N/A",
  "URL": "https://randomforest.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We implemented the <m>Smith-Waterman algorithm</m> (version 2.0) for sequence alignment. The algorithm details can be found at https://www.example-algorithms.org/smith-waterman.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Smith-Waterman",
  "Version": "2.0",
  "License": "N/A",
  "URL": "https://www.example-algorithms.org/smith-waterman",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We implemented the <m>Smith-Waterman</m> algorithm (version 2.0) for sequence alignment. The algorithm details can be found at https://www.example-algorithms.org/smith-waterman.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Smith-Waterman",
  "Version": "2.0",
  "License": "N/A",
  "URL": "https://www.example-algorithms.org/smith-waterman",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We implemented the Smith-Waterman <m>algorithm</m> (version 2.0) for sequence alignment. The algorithm details can be found at https://www.example-algorithms.org/smith-waterman.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Smith-Waterman",
  "Version": "2.0",
  "License": "N/A",
  "URL": "https://www.example-algorithms.org/smith-waterman",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We implemented the Smith-Waterman algorithm (version 2.0) for sequence alignment. The <m>algorithm</m> details can be found at https://www.example-algorithms.org/smith-waterman.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "Smith-Waterman",
  "Version": "2.0",
  "License": "N/A",
  "URL": "https://www.example-algorithms.org/smith-waterman",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We manually collected a remarkable <m>dataset</m> consisting of customer reviews from various e-commerce websites. This extensive dataset comprises 100,000 reviews encompassing diverse product categories. Researchers can request access to this dataset by sending an email to alex@abc.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We manually collected a remarkable dataset consisting of <m>customer reviews</m> from various e-commerce websites. This extensive dataset comprises 100,000 reviews encompassing diverse product categories. Researchers can request access to this dataset by sending an email to alex@abc.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We manually collected a remarkable dataset consisting of customer <m>reviews</m> from various e-commerce websites. This extensive dataset comprises 100,000 reviews encompassing diverse product categories. Researchers can request access to this dataset by sending an email to alex@abc.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We manually collected a remarkable dataset consisting of customer reviews from various e-commerce websites. This extensive <m>dataset</m> comprises 100,000 reviews encompassing diverse product categories. Researchers can request access to this dataset by sending an email to alex@abc.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We manually collected a remarkable dataset consisting of customer reviews from various e-commerce websites. This extensive dataset comprises 100,000 <m>reviews</m> encompassing diverse product categories. Researchers can request access to this dataset by sending an email to alex@abc.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We manually collected a remarkable dataset consisting of customer reviews from various e-commerce websites. This extensive dataset comprises 100,000 reviews encompassing diverse product categories. Researchers can request access to this <m>dataset</m> by sending an email to alex@abc.com.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "We referred to the <m>UCI Machine Learning Repository</m> for obtaining benchmark datasets. The UCI Repository is a valuable resource for machine learning researchers. Explore it at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the UCI Machine Learning <m>Repository</m> for obtaining benchmark datasets. The UCI Repository is a valuable resource for machine learning researchers. Explore it at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the UCI Machine Learning Repository for obtaining benchmark <m>datasets</m>. The UCI Repository is a valuable resource for machine learning researchers. Explore it at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the UCI Machine Learning Repository for obtaining benchmark datasets. The <m>UCI</m> Repository is a valuable resource for machine learning researchers. Explore it at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the UCI Machine Learning Repository for obtaining benchmark datasets. The UCI <m>Repository</m> is a valuable resource for machine learning researchers. Explore it at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the UCI Machine Learning Repository for obtaining benchmark datasets. The UCI Repository is a valuable <m>resource</m> for machine learning researchers. Explore it at https://archive.ics.uci.edu/ml/index.php.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "UCI Machine Learning Repository",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://archive.ics.uci.edu/ml/index.php",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the <m>WordNet lexical database</m> for semantic similarity calculations. WordNet is a widely used resource in natural language processing. Learn more at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the <m>WordNet lexical</m> database for semantic similarity calculations. WordNet is a widely used resource in natural language processing. Learn more at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the WordNet lexical <m>database</m> for semantic similarity calculations. WordNet is a widely used resource in natural language processing. Learn more at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We referred to the WordNet lexical database for semantic similarity calculations. <m>WordNet</m> is a widely used resource in natural language processing. Learn more at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>GloVe</m> word embeddings as a pre-trained feature representation in our natural language processing tasks. GloVe embeddings capture semantic relationships between words.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "GloVe",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>GloVe word embeddings</m> as a pre-trained feature representation in our natural language processing tasks. GloVe embeddings capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe word embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the GloVe word <m>embeddings</m> as a pre-trained feature representation in our natural language processing tasks. GloVe embeddings capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe word embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the GloVe word embeddings as a pre-trained feature representation in our natural language processing tasks. <m>GloVe</m> embeddings capture semantic relationships between words.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "GloVe",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the GloVe word embeddings as a pre-trained feature representation in our natural language processing tasks. <m>GloVe embeddings</m> capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe word embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the GloVe word embeddings as a pre-trained feature representation in our natural language processing tasks. GloVe <m>embeddings</m> capture semantic relationships between words.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "GloVe word embeddings",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>Google Cloud Vision API</m> for image analysis in our study. The Google Cloud Vision API offers a wide range of computer vision capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Vision API",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>Google Cloud Vision</m> API for image analysis in our study. The Google Cloud Vision API offers a wide range of computer vision capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Vision API",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Google Cloud Vision <m>API</m> for image analysis in our study. The Google Cloud Vision API offers a wide range of computer vision capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Vision API",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Google Cloud Vision API for <m>image</m> analysis in our study. The Google Cloud Vision API offers a wide range of computer vision capabilities.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We used the Google Cloud Vision API for image analysis in our study. The <m>Google Cloud Vision API</m> offers a wide range of computer vision capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Vision API",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Google Cloud Vision API for image analysis in our study. The <m>Google Cloud Vision</m> API offers a wide range of computer vision capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Vision API",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the Google Cloud Vision API for image analysis in our study. The Google Cloud Vision <m>API</m> offers a wide range of computer vision capabilities.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Vision API",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>ImageNet dataset</m> to train our image classification model. ImageNet dataset consists of millions of labeled images across thousands of categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>ImageNet</m> dataset to train our image classification model. ImageNet dataset consists of millions of labeled images across thousands of categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the ImageNet <m>dataset</m> to train our image classification model. ImageNet dataset consists of millions of labeled images across thousands of categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the ImageNet dataset to train our <m>image</m> classification model. ImageNet dataset consists of millions of labeled images across thousands of categories.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We used the ImageNet dataset to train our image classification <m>model</m>. ImageNet dataset consists of millions of labeled images across thousands of categories.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the ImageNet dataset to train our image classification model. <m>ImageNet dataset</m> consists of millions of labeled images across thousands of categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the ImageNet dataset to train our image classification model. <m>ImageNet</m> dataset consists of millions of labeled images across thousands of categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the ImageNet dataset to train our image classification model. ImageNet <m>dataset</m> consists of millions of labeled images across thousands of categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the ImageNet dataset to train our image classification model. ImageNet dataset consists of millions of labeled <m>images</m> across thousands of categories.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>SciPy library</m> (version 1.7.0) for scientific computations. SciPy is released under the BSD license and can be accessed at https://www.scipy.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy library",
  "Version": "1.7.0",
  "License": "BSD",
  "URL": "https://www.scipy.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the <m>SciPy</m> library (version 1.7.0) for scientific computations. SciPy is released under the BSD license and can be accessed at https://www.scipy.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy library",
  "Version": "1.7.0",
  "License": "BSD",
  "URL": "https://www.scipy.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the SciPy <m>library</m> (version 1.7.0) for scientific computations. SciPy is released under the BSD license and can be accessed at https://www.scipy.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy library",
  "Version": "1.7.0",
  "License": "BSD",
  "URL": "https://www.scipy.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We used the SciPy library (version 1.7.0) for scientific computations. <m>SciPy</m> is released under the BSD license and can be accessed at https://www.scipy.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy library",
  "Version": "1.7.0",
  "License": "BSD",
  "URL": "https://www.scipy.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the <m>IBM Watson</m> platform for natural language understanding and sentiment analysis. IBM Watson offers a range of AI-powered services.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "IBM Watson",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the IBM Watson <m>platform</m> for natural language understanding and sentiment analysis. IBM Watson offers a range of AI-powered services.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "IBM Watson",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We utilized the IBM Watson platform for natural language understanding and sentiment analysis. <m>IBM Watson</m> offers a range of AI-powered services.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "IBM Watson",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the <m>Stanford CoreNLP (v4.2.2) library</m>, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "https://stanfordnlp.github.io/CoreNLP",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the <m>Stanford CoreNLP</m> (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "https://stanfordnlp.github.io/CoreNLP",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) <m>library</m>, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "https://stanfordnlp.github.io/CoreNLP",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing <m>toolkit</m>, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "https://stanfordnlp.github.io/CoreNLP",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The <m>library</m> enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "https://stanfordnlp.github.io/CoreNLP",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the <m>Gensim library</m> (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "publicly available",
  "URL": "https://radimrehurek.com/gensim/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the <m>Gensim</m> library (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "publicly available",
  "URL": "https://radimrehurek.com/gensim/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim <m>library</m> (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "publicly available",
  "URL": "https://radimrehurek.com/gensim/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular <m>tool</m> for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "publicly available",
  "URL": "https://radimrehurek.com/gensim/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. <m>Gensim</m> is publicly available at https://radimrehurek.com/gensim/. These artifacts significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "N/A",
  "URL": "https://radimrehurek.com/gensim/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit, which can be found at https://stanfordnlp.github.io/CoreNLP/. The library enabled them to perform advanced linguistic analysis and sentiment analysis tasks. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. Gensim is publicly available at https://radimrehurek.com/gensim/. These <m>artifacts</m> significantly contributed to their text mining and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP | Gensim",
  "Version": "4.2.2 | 4.1.2",
  "License": "N/A | publicly available",
  "URL": "https://stanfordnlp.github.io/CoreNLP | https://radimrehurek.com/gensim/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed <m>OpenCV</m> (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "open-source",
  "URL": "https://opencv.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source <m>computer vision library</m>, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "open-source",
  "URL": "https://opencv.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision <m>library</m>, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "open-source",
  "URL": "https://opencv.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. <m>OpenCV</m> facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "open-source",
  "URL": "https://opencv.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various <m>image</m> processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the <m>NLTK (Natural Language Toolkit) library</m> (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the <m>NLTK</m> (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) <m>library</m> (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable <m>resource</m> for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The <m>NLTK library</m> is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The <m>NLTK</m> library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK <m>library</m> is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK (Natural Language Toolkit) library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their <m>data</m> preprocessing and analysis pipeline.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their research, the authors utilized several important research artifacts. They employed OpenCV (v4.5.3), an open-source computer vision library, which can be found at https://opencv.org/. OpenCV facilitated various image processing and computer vision tasks in their study. Additionally, they used the NLTK <m>(Natural Language Toolkit)</m> library (v3.6.2), a valuable resource for natural language processing. The NLTK library is publicly available at https://www.nltk.org/. These artifacts significantly contributed to their data preprocessing and analysis pipeline.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "N/A",
  "URL": "https://www.nltk.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed <m>PyTorch</m> (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause License",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a <m>deep learning library</m> released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause License",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning <m>library</m> released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause License",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about <m>PyTorch</m>, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause License",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized <m>Scikit-learn</m> (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT License",
  "URL": "https://scikit-learn.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a <m>machine learning library</m> distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT License",
  "URL": "https://scikit-learn.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning <m>library</m> distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT License",
  "URL": "https://scikit-learn.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about <m>Scikit-learn</m> can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT License",
  "URL": "https://scikit-learn.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the <m>Stanford Sentiment Treebank dataset</m> (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the <m>Stanford Sentiment Treebank</m> dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank <m>dataset</m> (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis <m>model</m>. More details about the dataset can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "In their study, the authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0), a deep learning library released under the BSD-3-Clause license, for their deep learning experiments. For more information about PyTorch, please visit https://pytorch.org/. Additionally, they utilized Scikit-learn (v0.24.2), a machine learning library distributed under the permissive MIT license, for their machine learning tasks. Further details about Scikit-learn can be found at https://scikit-learn.org/. Moreover, they employed the Stanford Sentiment Treebank dataset (v3.0), which is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 license, to train their sentiment analysis model. More details about the <m>dataset</m> can be found at https://nlp.stanford.edu/sentiment/index.html.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Stanford Sentiment Treebank",
  "Version": "3.0",
  "License": "Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License",
  "URL": "https://nlp.stanford.edu/sentiment/index.html",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized <m>PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3)</m>, which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow | Keras",
  "Version": "1.9.0 | 2.5.0 | 2.4.3",
  "License": "BSD-3-Clause license | Apache 2.0 | N/A",
  "URL": "https://pytorch.org/ | https://www.tensorflow.org/ | https://keras.io/",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized <m>PyTorch</m> (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "https://pytorch.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), <m>TensorFlow</m> (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "https://www.tensorflow.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and <m>Keras</m> (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.3",
  "License": "N/A",
  "URL": "https://keras.io/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent <m>deep learning frameworks</m>. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow | Keras",
  "Version": "1.9.0 | 2.5.0 | 2.4.3",
  "License": "BSD-3-Clause license | Apache 2.0 | N/A",
  "URL": "https://pytorch.org/ | https://www.tensorflow.org/ | https://keras.io/",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning <m>frameworks</m>. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow | Keras",
  "Version": "1.9.0 | 2.5.0 | 2.4.3",
  "License": "BSD-3-Clause license | Apache 2.0 | N/A",
  "URL": "https://pytorch.org/ | https://www.tensorflow.org/ | https://keras.io/",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. <m>PyTorch</m> is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "https://pytorch.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. <m>TensorFlow</m>, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "https://www.tensorflow.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. <m>Keras</m>, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.3",
  "License": "N/A",
  "URL": "https://keras.io/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks <m>API</m>, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Keras",
  "Version": "2.4.3",
  "License": "N/A",
  "URL": "https://keras.io/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their <m>deep learning models</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These frameworks played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning <m>models</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors employed a combination of research artifacts in their study. They utilized PyTorch (v1.9.0), TensorFlow (v2.5.0), and Keras (v2.4.3), which are prominent deep learning frameworks. PyTorch is released under the BSD-3-Clause license and can be accessed at https://pytorch.org/. TensorFlow, on the other hand, is released under the Apache 2.0 license and can be found at https://www.tensorflow.org/. Keras, a high-level neural networks API, can be obtained from https://keras.io/. These <m>rameworks</m> played a crucial role in their experiments, enabling the implementation and evaluation of their deep learning models.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow | Keras",
  "Version": "1.9.0 | 2.5.0 | 2.4.3",
  "License": "BSD-3-Clause license | Apache 2.0 | N/A",
  "URL": "https://pytorch.org/ | https://www.tensorflow.org/ | https://keras.io/",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed <m>PyTorch (v1.9.0) and TensorFlow</m> (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow",
  "Version": "1.9.0 | 2.5.0",
  "License": "BSD-3-Clause | Apache 2.0",
  "URL": "https://pytorch.org | https://www.tensorflow.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and <m>TensorFlow</m> (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "https://www.tensorflow.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent <m>deep learning libraries</m> released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow",
  "Version": "1.9.0 | 2.5.0",
  "License": "BSD-3-Clause | Apache 2.0",
  "URL": "https://pytorch.org | https://www.tensorflow.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning <m>libraries</m> released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning <m>libraries</m> released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow",
  "Version": "1.9.0 | 2.5.0",
  "License": "BSD-3-Clause | Apache 2.0",
  "URL": "https://pytorch.org | https://www.tensorflow.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. <m>PyTorch</m> can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while <m>TensorFlow</m> can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "https://www.tensorflow.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged <m>Scikit-learn</m> (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT License",
  "URL": "https://scikit-learn.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful <m>machine learning library</m> distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT License",
  "URL": "https://scikit-learn.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning <m>library</m> distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Scikit-learn",
  "Version": "0.24.2",
  "License": "MIT License",
  "URL": "https://scikit-learn.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the <m>COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset</m>, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO | ImageNet",
  "Version": "2017 | N/A",
  "License": "N/A | N/A",
  "URL": "http://cocodataset.org | http://www.image-net.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the <m>COCO (Common Objects in Context) dataset</m> (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the <m>COCO</m> (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) <m>dataset</m> (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the <m>ImageNet</m> dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet <m>dataset</m>, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, <m>both</m> widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO | ImageNet",
  "Version": "2017 | N/A",
  "License": "N/A | N/A",
  "URL": "http://cocodataset.org | http://www.image-net.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The <m>COCO dataset</m> can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The <m>COCO</m> dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO <m>dataset</m> can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the <m>ImageNet dataset</m> can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the <m>ImageNet</m> dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet <m>dataset</m> can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "ImageNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "http://www.image-net.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the <m>WordNet lexical database</m> (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "3.1",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the <m>WordNet</m> lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "3.1",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO (Common Objects in Context) dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical <m>database</m> (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "WordNet",
  "Version": "3.1",
  "License": "N/A",
  "URL": "https://wordnet.princeton.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors extensively utilized a wide range of research artifacts in their investigations. They employed PyTorch (v1.9.0) and TensorFlow (v2.5.0), prominent deep learning libraries released under the BSD-3-Clause and Apache 2.0 licenses, respectively. PyTorch can be accessed at https://pytorch.org/, while TensorFlow can be found at https://www.tensorflow.org/. Moreover, they leveraged Scikit-learn (v0.24.2), a powerful machine learning library distributed under the permissive MIT license, which is available at https://scikit-learn.org/. Additionally, they employed the COCO <m>(Common Objects in Context)</m> dataset (v2017) and the ImageNet dataset, both widely used benchmarks in computer vision research. The COCO dataset can be obtained from http://cocodataset.org/, while the ImageNet dataset can be accessed at http://www.image-net.org/. Furthermore, they utilized the WordNet lexical database (v3.1), a valuable resource for natural language processing tasks, which can be accessed at https://wordnet.princeton.edu/.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "COCO",
  "Version": "2017",
  "License": "N/A",
  "URL": "http://cocodataset.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated several research artifacts to support their investigations. They employed <m>PyTorch (v1.9.0) and Scikit-learn (v0.24.2)</m>, a deep learning library released under the BSD-3-Clause license, and a machine learning library distributed under the permissive MIT license. The first one can be found at https://pytorch.org/, and the second at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | Scikit-learn",
  "Version": "1.9.0 | 0.24.2",
  "License": "BSD-3-Clause license | permissive MIT license",
  "URL": "https://pytorch.org | https://scikit-learn.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors incorporated several research artifacts to support their investigations. They employed <m>PyTorch</m> (v1.9.0) and Scikit-learn (v0.24.2), a deep learning library released under the BSD-3-Clause license, and a machine learning library distributed under the permissive MIT license. The first one can be found at https://pytorch.org/, and the second at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0) and <m>Scikit-learn</m> (v0.24.2), a deep learning library released under the BSD-3-Clause license, and a machine learning library distributed under the permissive MIT license. The first one can be found at https://pytorch.org/, and the second at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive MIT license",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0) and Scikit-learn (v0.24.2), a <m>deep learning library</m> released under the BSD-3-Clause license, and a machine learning library distributed under the permissive MIT license. The first one can be found at https://pytorch.org/, and the second at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0) and Scikit-learn (v0.24.2), a deep learning <m>library</m> released under the BSD-3-Clause license, and a machine learning library distributed under the permissive MIT license. The first one can be found at https://pytorch.org/, and the second at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "https://pytorch.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0) and Scikit-learn (v0.24.2), a deep learning library released under the BSD-3-Clause license, and a <m>machine learning library</m> distributed under the permissive MIT license. The first one can be found at https://pytorch.org/, and the second at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive MIT license",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors incorporated several research artifacts to support their investigations. They employed PyTorch (v1.9.0) and Scikit-learn (v0.24.2), a deep learning library released under the BSD-3-Clause license, and a machine learning <m>library</m> distributed under the permissive MIT license. The first one can be found at https://pytorch.org/, and the second at https://scikit-learn.org/.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive MIT license",
  "URL": "https://scikit-learn.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the <m>Numpy (v1.21.0) and Pandas (v1.3.0) libraries</m>, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Numpy | Pandas",
  "Version": "1.21.0 | 1.3.0",
  "License": "open-source | open-source",
  "URL": "https://numpy.org/ | https://pandas.pydata.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the <m>Numpy (v1.21.0) and Pandas (v1.3.0)</m> libraries, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Numpy | Pandas",
  "Version": "1.21.0 | 1.3.0",
  "License": "open-source | open-source",
  "URL": "https://numpy.org/ | https://pandas.pydata.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the <m>Numpy</m> (v1.21.0) and Pandas (v1.3.0) libraries, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Numpy",
  "Version": "1.21.0",
  "License": "open-source",
  "URL": "https://numpy.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and <m>Pandas</m> (v1.3.0) libraries, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "1.3.0",
  "License": "open-source",
  "URL": "https://pandas.pydata.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and Pandas (v1.3.0) <m>libraries</m>, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Numpy | Pandas",
  "Version": "1.21.0 | 1.3.0",
  "License": "open-source | open-source",
  "URL": "https://numpy.org/ | https://pandas.pydata.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and Pandas (v1.3.0) libraries, which are widely used for numerical computing and <m>data</m> manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and Pandas (v1.3.0) libraries, which are widely used for numerical computing and data manipulation, respectively. <m>Numpy</m> and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Numpy",
  "Version": "1.21.0",
  "License": "open-source",
  "URL": "https://numpy.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and Pandas (v1.3.0) libraries, which are widely used for numerical computing and data manipulation, respectively. Numpy and <m>Pandas</m> are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "1.3.0",
  "License": "open-source",
  "URL": "https://pandas.pydata.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and Pandas (v1.3.0) libraries, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source <m>libraries</m> and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Numpy | Pandas",
  "Version": "1.21.0 | 1.3.0",
  "License": "N/A | N/A",
  "URL": "https://numpy.org/ | https://pandas.pydata.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and Pandas (v1.3.0) libraries, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These <m>artifacts</m> played a crucial role in their data preprocessing, feature engineering, and statistical analysis.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Numpy | Pandas",
  "Version": "1.21.0 | 1.3.0",
  "License": "N/A | N/A",
  "URL": "https://numpy.org/ | https://pandas.pydata.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors leveraged a diverse set of research artifacts in their study. They utilized the Numpy (v1.21.0) and Pandas (v1.3.0) libraries, which are widely used for numerical computing and data manipulation, respectively. Numpy and Pandas are both open-source libraries and can be accessed at https://numpy.org/ and https://pandas.pydata.org/, respectively. These artifacts played a crucial role in their <m>data</m> preprocessing, feature engineering, and statistical analysis.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed <m>Hadoop (v3.3.1) and Spark (v3.1.2)</m>, popular big data processing frameworks. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop | Spark",
  "Version": "3.3.1 | 3.1.2",
  "License": "Apache 2.0 | Apache 2.0",
  "URL": "https://hadoop.apache.org/ | https://hadoop.apache.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed <m>Hadoop</m> (v3.3.1) and Spark (v3.1.2), popular big data processing frameworks. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop",
  "Version": "3.3.1",
  "License": "Apache 2.0",
  "URL": "https://hadoop.apache.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and <m>Spark</m> (v3.1.2), popular big data processing frameworks. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Spark",
  "Version": "3.1.2",
  "License": "Apache 2.0",
  "URL": "https://spark.apache.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and Spark (v3.1.2), popular <m>big data processing frameworks</m>. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop | Spark",
  "Version": "3.3.1 | 3.1.2",
  "License": "Apache 2.0 | Apache 2.0",
  "URL": "https://hadoop.apache.org/ | https://hadoop.apache.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and Spark (v3.1.2), popular big data processing <m>frameworks</m>. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop | Spark",
  "Version": "3.3.1 | 3.1.2",
  "License": "Apache 2.0 | Apache 2.0",
  "URL": "https://hadoop.apache.org/ | https://hadoop.apache.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and Spark (v3.1.2), popular big data processing frameworks. <m>Hadoop</m>, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop",
  "Version": "3.3.1",
  "License": "Apache 2.0",
  "URL": "https://hadoop.apache.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and Spark (v3.1.2), popular big data processing frameworks. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. <m>Spark</m>, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Spark",
  "Version": "3.1.2",
  "License": "Apache 2.0",
  "URL": "https://hadoop.apache.org/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and Spark (v3.1.2), popular big data processing frameworks. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These <m>frameworks</m> enabled efficient distributed processing and analysis of large-scale datasets in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop | Spark",
  "Version": "3.3.1 | 3.1.2",
  "License": "Apache 2.0 | Apache 2.0",
  "URL": "https://hadoop.apache.org/ | https://hadoop.apache.org/",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and Spark (v3.1.2), popular big data processing frameworks. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of <m>large-scale datasets</m> in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To support their investigations, the authors incorporated several research artifacts. They employed Hadoop (v3.3.1) and Spark (v3.1.2), popular big data processing frameworks. Hadoop, released under the Apache 2.0 license, can be accessed at https://hadoop.apache.org/. Spark, also released under the Apache 2.0 license, can be found at https://spark.apache.org/. These frameworks enabled efficient distributed processing and analysis of large-scale <m>datasets</m> in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the <m>SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library</m>. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy | Pandas",
  "Version": "1.7.0 | 1.3.0",
  "License": "BSD-3-Clause license | BSD-3-Clause license",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the <m>SciPy</m> (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy",
  "Version": "1.7.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) <m>scientific computing library</m> and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy",
  "Version": "1.7.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing <m>library</m> and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy",
  "Version": "1.7.0",
  "License": "BSD-3-Clause License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing <m>library</m> and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy",
  "Version": "1.7.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the <m>Pandas (v1.3.0) data manipulation library</m>. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "1.3.0",
  "License": "BSD-3-Clause",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the <m>Pandas</m> (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "1.3.0",
  "License": "BSD-3-Clause",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) <m>data manipulation library</m>. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "1.3.0",
  "License": "BSD-3-Clause",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) <m>data</m> manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation <m>library</m>. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "1.3.0",
  "License": "BSD-3-Clause",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. <m>SciPy</m>, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy",
  "Version": "1.7.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. <m>Pandas</m>, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Pandas",
  "Version": "1.3.0",
  "License": "BSD-3-Clause",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful <m>data</m> structures and data analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and <m>data</m> analysis tools. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis <m>tools</m>. These artifacts facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These <m>artifacts</m> facilitated efficient data processing, statistical analysis, and visualization in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SciPy | Pandas",
  "Version": "1.7.0 | 1.3.0",
  "License": "BSD-3-Clause license | BSD-3-Clause license",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated diverse research artifacts. They employed the SciPy (v1.7.0) scientific computing library and the Pandas (v1.3.0) data manipulation library. SciPy, released under the BSD-3-Clause license, provided a wide range of numerical algorithms and statistical functions. Pandas, also released under the BSD-3-Clause license, offered powerful data structures and data analysis tools. These artifacts facilitated efficient <m>data</m> processing, statistical analysis, and visualization in their study.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their research, the authors incorporated various research <m>artifacts</m>. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP | Gensim",
  "Version": "4.2.2 | 4.1.2",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the <m>Stanford CoreNLP (v4.2.2) library</m>, a powerful natural language processing toolkit. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the <m>Stanford CoreNLP (v4.2.2)</m> library, a powerful natural language processing toolkit. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) <m>library</m>, a powerful natural language processing toolkit. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful <m>natural language processing toolkit</m>. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing <m>toolkit</m>. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP",
  "Version": "4.2.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit. Additionally, they utilized the <m>Gensim library</m> (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit. Additionally, they utilized the <m>Gensim</m> library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit. Additionally, they utilized the Gensim <m>library</m> (v4.1.2), a popular tool for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit. Additionally, they utilized the Gensim library (v4.1.2), a popular <m>tool</m> for topic modeling and document similarity analysis. The libraries enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gensim",
  "Version": "4.1.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their research, the authors incorporated various research artifacts. They employed the Stanford CoreNLP (v4.2.2) library, a powerful natural language processing toolkit. Additionally, they utilized the Gensim library (v4.1.2), a popular tool for topic modeling and document similarity analysis. The <m>libraries</m> enabled them to perform advanced linguistic analysis and sentiment analysis tasks. ",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Stanford CoreNLP | Gensim",
  "Version": "4.2.2 | 4.1.2",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various <m>research artifacts</m>. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Apache Spark | Hadoop",
  "Version": "3.1.2 | 3.3.1",
  "License": "Apache 2.0 | Apache 2.0",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the <m>Apache Spark</m> (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Apache Spark",
  "Version": "3.1.2",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing <m>framework</m> and the Hadoop (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Apache Spark",
  "Version": "3.1.2",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the <m>Hadoop</m> (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop",
  "Version": "3.3.1",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) <m>big data processing platform</m>. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop",
  "Version": "3.3.1",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big <m>data</m> processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing <m>platform</m>. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop",
  "Version": "3.3.1",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing platform. <m>Apache Spark</m>, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Apache Spark",
  "Version": "3.1.2",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale <m>datasets</m>. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. <m>Hadoop</m>, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Hadoop",
  "Version": "3.3.1",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These <m>artifacts</m> were instrumental in handling and analyzing massive amounts of data in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Apache Spark | Hadoop",
  "Version": "3.1.2 | 3.3.1",
  "License": "Apache 2.0 | Apache 2.0",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In their study, the authors incorporated various research artifacts. They employed the Apache Spark (v3.1.2) distributed computing framework and the Hadoop (v3.3.1) big data processing platform. Apache Spark, licensed under the Apache 2.0 license, allowed efficient processing and analysis of large-scale datasets. Hadoop, also released under the Apache 2.0 license, provided a robust infrastructure for distributed storage and processing. These artifacts were instrumental in handling and analyzing massive amounts of <m>data</m> in their research.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors integrated <m>multiple research artifacts</m> into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow",
  "Version": "1.9.0 | 2.5.0",
  "License": "BSD-3-Clause license | Apache 2.0",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the <m>PyTorch</m> (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) <m>deep learning framework</m> and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning <m>framework</m> and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the <m>TensorFlow</m> (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) <m>machine learning library</m>. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning <m>library</m>. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. <m>PyTorch</m>, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "1.9.0",
  "License": "BSD-3-Clause license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their <m>neural network models</m>. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network <m>models</m>. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, <m>TensorFlow</m>, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile <m>platform</m> for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TensorFlow",
  "Version": "2.5.0",
  "License": "Apache 2.0",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These <m>artifacts</m> played a pivotal role in enabling advanced data analysis and model training in their research.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch | TensorFlow",
  "Version": "1.9.0 | 2.5.0",
  "License": "BSD-3-Clause license | Apache 2.0",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced <m>data</m> analysis and model training in their research.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors integrated multiple research artifacts into their investigation. They employed the PyTorch (v1.9.0) deep learning framework and the TensorFlow (v2.5.0) machine learning library. PyTorch, released under the BSD-3-Clause license, facilitated the implementation and evaluation of their neural network models. On the other hand, TensorFlow, released under the Apache 2.0 license, provided a versatile platform for machine learning tasks. These artifacts played a pivotal role in enabling advanced data analysis and <m>model</m> training in their research.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The authors integrated several <m>research artifacts</m> to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK | SpaCy",
  "Version": "3.6.2 | 3.1.4",
  "License": "Apache 2.0 License | MIT license",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the <m>NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4)</m> for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK | SpaCy",
  "Version": "3.6.2 | 3.1.4",
  "License": "Apache 2.0 License | MIT license",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the <m>NLTK (Natural Language Toolkit) library</m> (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the <m>NLTK (Natural Language Toolkit)</m> library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the <m>NLTK</m> (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) <m>library</m> (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the <m>SpaCy</m> library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SpaCy",
  "Version": "3.1.4",
  "License": "MIT license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the <m>SpaCy</m> library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SpaCy",
  "Version": "3.1.4",
  "License": "MIT license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy <m>library</m> (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SpaCy",
  "Version": "3.1.4",
  "License": "MIT license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. <m>NLTK</m>, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive <m>set of tools</m> for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. <m>SpaCy</m>, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SpaCy",
  "Version": "3.1.4",
  "License": "MIT license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These <m>artifacts</m> enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK | SpaCy",
  "Version": "3.6.2 | 3.1.4",
  "License": "Apache 2.0 License | MIT license",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of <m>textual data</m> in their study.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK (Natural Language Toolkit) library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual <m>data</m> in their study.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated several research artifacts to support their investigations. They utilized the NLTK <m>(Natural Language Toolkit)</m> library (v3.6.2) and the SpaCy library (v3.1.4) for natural language processing tasks. NLTK, available under the Apache 2.0 license, provided a comprehensive set of tools for text analysis and linguistic processing. SpaCy, released under the MIT license, offered advanced capabilities for information extraction and entity recognition. These artifacts enabled the authors to perform in-depth analysis and annotation of textual data in their study.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NLTK",
  "Version": "3.6.2",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the <m>OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library</m>. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV | scikit-learn",
  "Version": "4.5.3 | 0.24.2",
  "License": "Apache 2.0 License | permissive BSD license",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the <m>OpenCV</m> (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) <m>computer vision library</m> and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision <m>library</m> and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision <m>library</m> and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive BSD license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the <m>scikit-learn (v0.24.2) machine learning library</m>. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive BSD license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the <m>scikit-learn</m> (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive BSD license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) <m>machine learning library</m>. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive BSD license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. <m>OpenCV</m>, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV",
  "Version": "4.5.3",
  "License": "Apache 2.0 License",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of <m>functions</m> for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for <m>image</m> processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. <m>scikit-learn</m>, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "scikit-learn",
  "Version": "0.24.2",
  "License": "permissive BSD license",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning <m>algorithms and tools</m>. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning <m>algorithms</m> and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and <m>tools</m>. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These <m>artifacts</m> played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "OpenCV | scikit-learn",
  "Version": "4.5.3 | 0.24.2",
  "License": "Apache 2.0 License | permissive BSD license",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their <m>image</m> analysis and machine learning experiments, enabling accurate data analysis and model training.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate <m>data</m> analysis and model training.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors integrated various research artifacts into their investigation. They employed the OpenCV (v4.5.3) computer vision library and the scikit-learn (v0.24.2) machine learning library. OpenCV, released under the Apache 2.0 license, provided a rich set of functions for image processing and computer vision tasks. scikit-learn, released under the permissive BSD license, offered a comprehensive suite of machine learning algorithms and tools. These artifacts played a critical role in their image analysis and machine learning experiments, enabling accurate data analysis and <m>model</m> training.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a <m>genomics dataset</m> that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics <m>dataset</m> that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained <m>DNA sequences</m> of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA <m>sequences</m> of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The <m>dataset</m> was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had <m>annotations</m> for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the <m>Biopython</m> (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Biopython",
  "Version": "1.79",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) <m>library</m>, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Biopython",
  "Version": "1.79",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful <m>tool</m> for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Biopython",
  "Version": "1.79",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to <m>process</m> and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the <m>genomics data</m>. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics <m>data</m>. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the <m>Seaborn</m> (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Seaborn",
  "Version": "0.11.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) <m>library</m> for generating informative visualizations. The genomics dataset, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Seaborn",
  "Version": "0.11.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The <m>genomics dataset</m>, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics <m>dataset</m>, Biopython, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, <m>Biopython</m>, and Seaborn played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Biopython",
  "Version": "1.79",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "As part of their research, the scientists conducted experiments using a genomics dataset that contained DNA sequences of individuals with different health conditions. The dataset was acquired from a public repository and had annotations for genetic variants and associated phenotypes. The researchers employed the Biopython (v1.79) library, a powerful tool for biological computation, to process and analyze the genomics data. Additionally, they utilized the Seaborn (v0.11.2) library for generating informative visualizations. The genomics dataset, Biopython, and <m>Seaborn</m> played a critical role in unraveling genetic factors contributing to various health conditions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Seaborn",
  "Version": "0.11.2",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health <m>surveillance data</m>, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance <m>data</m>, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The <m>surveillance data</m> included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance <m>data</m> included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To <m>process</m> and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the <m>data</m>, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the <m>R</m> (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "R",
  "Version": "4.1.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the <m>dplyr</m> package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "dplyr",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr <m>package</m>, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "dplyr",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful <m>tool</m> for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "dplyr",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for <m>data</m> manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in <m>R</m>. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "R",
  "Version": "4.1.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex <m>data</m> queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the <m>SEIR (Susceptible-Exposed-Infectious-Recovered</m>) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SEIR",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the <m>SEIR</m> (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SEIR",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (<m>Susceptible-Exposed-Infectious-Recovered</m>) model, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SEIR",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) <m>model</m>, a widely used epidemiological model, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SEIR",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this study, the researchers conducted a comprehensive analysis of public health surveillance data, collected over a ten-year period. The surveillance data included information about disease outbreaks, hospitalizations, and population demographics. To process and analyze the data, they utilized the R (v4.1.0) programming language and the dplyr package, a powerful tool for data manipulation and transformation in R. These artifacts enabled them to perform complex data queries, calculate statistics, and generate visualizations. Furthermore, they employed the SEIR (Susceptible-Exposed-Infectious-Recovered) model, a widely used epidemiological <m>model</m>, to simulate the spread of infectious diseases and assess intervention strategies.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SEIR",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel <m>algorithm</m> called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured data. GraphSAGE is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (SNAP), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GraphSAGE",
  "Version": "2.0.1",
  "License": "open-source",
  "URL": "https://graphsage.stanford.edu/",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors developed a novel algorithm called <m>GraphSAGE</m> (v2.0.1) for semi-supervised learning on graph-structured data. GraphSAGE is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (SNAP), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GraphSAGE",
  "Version": "2.0.1",
  "License": "open-source",
  "URL": "https://graphsage.stanford.edu/",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors developed a novel algorithm called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured <m>data</m>. GraphSAGE is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (SNAP), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors developed a novel algorithm called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured data. <m>GraphSAGE</m> is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (SNAP), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GraphSAGE",
  "Version": "2.0.1",
  "License": "open-source",
  "URL": "https://graphsage.stanford.edu/",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors developed a novel algorithm called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured data. <m>GraphSAGE</m> is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (SNAP), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GraphSAGE",
  "Version": "2.0.1",
  "License": "open-source",
  "URL": "https://graphsage.stanford.edu/",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors developed a novel algorithm called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured data. GraphSAGE is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the <m>Stanford Network Analysis Platform</m> (SNAP), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SNAP",
  "Version": "5.0.0",
  "License": "publicly available",
  "URL": "https://snap.stanford.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured data. GraphSAGE is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (<m>SNAP</m>), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SNAP",
  "Version": "5.0.0",
  "License": "publicly available",
  "URL": "https://snap.stanford.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured data. GraphSAGE is an open-source framework and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (SNAP), a general-purpose network analysis and graph mining <m>library</m> (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SNAP",
  "Version": "5.0.0",
  "License": "publicly available",
  "URL": "https://snap.stanford.edu/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called GraphSAGE (v2.0.1) for semi-supervised learning on graph-structured data. GraphSAGE is an open-source <m>framework</m> and can be accessed at https://graphsage.stanford.edu/. They also utilized the Stanford Network Analysis Platform (SNAP), a general-purpose network analysis and graph mining library (v5.0.0), which is publicly available at https://snap.stanford.edu/. These artifacts played a crucial role in their graph representation learning experiments, enabling efficient processing and analysis of large-scale networks.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GraphSAGE",
  "Version": "2.0.1",
  "License": "open-source",
  "URL": "https://graphsage.stanford.edu/",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The authors developed a novel <m>algorithm</m> called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SEED",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called <m>SEED</m> (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SEED",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (<m>Structured Estimation for Entity Disambiguation</m>) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SEED",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the <m>algorithm</m>, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SEED",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the <m>AIDA</m> dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "AIDA",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA <m>dataset</m> (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "AIDA",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark <m>dataset</m> widely used in the field of entity disambiguation. The SEED algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "AIDA",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The <m>SEED</m> algorithm and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SEED",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED <m>algorithm</m> and the AIDA dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SEED",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the <m>AIDA</m> dataset significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "AIDA",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel algorithm called SEED (Structured Estimation for Entity Disambiguation) for entity disambiguation in text. To evaluate the algorithm, they used the AIDA dataset (v2.0), a benchmark dataset widely used in the field of entity disambiguation. The SEED algorithm and the AIDA <m>dataset</m> significantly improved the accuracy of entity disambiguation and achieved state-of-the-art results in their experiments.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "AIDA",
  "Version": "2.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel graph-based <m>algorithm</m> for community detection in social networks. This algorithm utilizes the NetworkX (v2.6.0) library, which provides efficient data structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "GNU General Public License",
  "URL": "https://github.com/gkalidakis/com_det",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social <m>networks</m>. This algorithm utilizes the NetworkX (v2.6.0) library, which provides efficient data structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This <m>algorithm</m> utilizes the NetworkX (v2.6.0) library, which provides efficient data structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "GNU General Public License",
  "URL": "https://github.com/gkalidakis/com_det",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This algorithm utilizes the <m>NetworkX</m> (v2.6.0) library, which provides efficient data structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NetworkX",
  "Version": "2.6.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This algorithm utilizes the NetworkX (v2.6.0) <m>library</m>, which provides efficient data structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NetworkX",
  "Version": "2.6.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This algorithm utilizes the NetworkX (v2.6.0) library, which provides efficient <m>data</m> structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This algorithm utilizes the NetworkX (v2.6.0) library, which provides efficient data structures and <m>algorithms</m> for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This algorithm utilizes the NetworkX (v2.6.0) library, which provides efficient data structures and algorithms for graph analysis. The <m>algorithm</m> is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "GNU General Public License",
  "URL": "https://github.com/gkalidakis/com_det",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This algorithm utilizes the NetworkX (v2.6.0) library, which provides efficient data structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing <m>methods</m> in terms of both accuracy and runtime on various benchmark datasets.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The authors developed a novel graph-based algorithm for community detection in social networks. This algorithm utilizes the NetworkX (v2.6.0) library, which provides efficient data structures and algorithms for graph analysis. The algorithm is licensed under the GNU General Public License and can be accessed at https://github.com/gkalidakis/com_det. It outperforms existing methods in terms of both accuracy and runtime on various benchmark <m>datasets</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The authors developed a novel music recommendation <m>system</m>, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the <m>Librosa</m> (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Librosa",
  "Version": "0.8.1",
  "License": "N/A",
  "URL": "https://librosa.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) <m>library</m> for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Librosa",
  "Version": "0.8.1",
  "License": "N/A",
  "URL": "https://librosa.org",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the <m>Music21</m> (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Music21",
  "Version": "6.7.1",
  "License": "N/A",
  "URL": "https://web.mit.edu/music21/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) <m>toolkit</m>, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Music21",
  "Version": "6.7.1",
  "License": "N/A",
  "URL": "https://web.mit.edu/music21/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about <m>Music21</m>, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Music21",
  "Version": "6.7.1",
  "License": "N/A",
  "URL": "https://web.mit.edu/music21/",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The <m>system</m> was trained using the Last.fm dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the <m>Last.fm</m> dataset (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Last.fm",
  "Version": "2021",
  "License": "publicly available",
  "URL": "https://last.fm/dataset",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm <m>dataset</m> (2021 version), a comprehensive collection of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Last.fm",
  "Version": "2021",
  "License": "publicly available",
  "URL": "https://last.fm/dataset",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive <m>collection</m> of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Last.fm",
  "Version": "2021",
  "License": "publicly available",
  "URL": "https://last.fm/dataset",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The authors developed a novel music recommendation system, incorporating various research artifacts. They employed the Librosa (v0.8.1) library for audio feature extraction and analysis, which can be accessed at https://librosa.org/. Additionally, they utilized the Music21 (v6.7.1) toolkit, a powerful resource for symbolic music analysis and manipulation. For more information about Music21, please visit https://web.mit.edu/music21/. The system was trained using the Last.fm dataset (2021 version), a comprehensive <m>collection</m> of user listening histories and music metadata, which is publicly available at https://last.fm/dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Last.fm",
  "Version": "2021",
  "License": "publicly available",
  "URL": "https://last.fm/dataset",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large <m>dataset</m> of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio <m>recordings</m> from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This <m>dataset</m>, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the <m>MusicX</m>, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio <m>files</m> and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The <m>dataset</m> is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the <m>MusicX</m> dataset to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX <m>dataset</m> to train a deep learning model for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MusicX",
  "Version": "N/A",
  "License": "freely available for research purposes",
  "URL": "https://www.musicxdataset.org/",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a <m>deep learning model</m> for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning <m>model</m> for music genre classification. The model achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers collected a large dataset of audio recordings from various music genres, including classical, jazz, and rock. This dataset, referred to as the MusicX, consists of high-quality audio files and accompanying metadata such as artist, album, and genre information. The dataset is freely available for research purposes and can be accessed at https://www.musicxdataset.org/. The researchers used the MusicX dataset to train a deep learning model for music genre classification. The <m>model</m> achieved state-of-the-art performance in distinguishing between different music genres.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale <m>dataset</m> consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://unibro.portal.edu/image_dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of <m>images</m> collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://unibro.portal.edu/image_dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The <m>dataset</m> was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://unibro.portal.edu/image_dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the <m>COCO annotation</m> tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "COCO annotation",
  "Version": "2.3.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO <m>annotation</m> tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation <m>tool</m> (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "COCO annotation",
  "Version": "2.3.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive <m>annotations</m> for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://unibro.portal.edu/image_dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The <m>annotations</m> were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://unibro.portal.edu/image_dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the <m>LabelImg</m> (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LabelImg",
  "Version": "2.8.4",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) <m>tool</m>, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LabelImg",
  "Version": "2.8.4",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual <m>annotation</m>. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the <m>COCO annotation</m> tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "COCO annotation",
  "Version": "2.3.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO <m>annotation</m> tool and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation <m>tool</m> and LabelImg are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "COCO annotation",
  "Version": "2.3.0",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and <m>LabelImg</m> are widely used in the computer vision community. The dataset, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LabelImg",
  "Version": "2.8.4",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The <m>dataset</m>, along with the annotations, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://unibro.portal.edu/image_dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers conducted their study using a diverse set of research artifacts. They utilized a large-scale dataset consisting of millions of images collected from various online sources. The dataset was annotated using the COCO annotation tool (v2.3.0), which provides comprehensive annotations for object detection and segmentation tasks. The annotations were carefully curated using the LabelImg (v1.8.4) tool, which offers a user-friendly interface for manual annotation. Both the COCO annotation tool and LabelImg are widely used in the computer vision community. The dataset, along with the <m>annotations</m>, is available for download at https://unibro.portal.edu/image_dataset.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://unibro.portal.edu/image_dataset",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel <m>algorithm</m> for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for <m>image</m> segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image <m>segmentation</m>, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called <m>SegNet++</m>. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0 License",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called <m>SegNet</m>++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0 License",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original <m>SegNet</m> algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "SegNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet <m>algorithm</m> and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "SegNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional <m>deep learning techniques</m>. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning <m>techniques</m>. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. <m>SegNet++</m> (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0 License",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. <m>SegNet</m>++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0 License",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark <m>datasets</m>, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PASCAL VOC | Cityscapes",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including <m>PASCAL VOC and Cityscapes</m>. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PASCAL VOC | Cityscapes",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including <m>PASCAL VOC</m> and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PASCAL VOC",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and <m>Cityscapes</m>. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Cityscapes",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The <m>algorithm</m> is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0 License",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated <m>SegNet++</m> on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0 License",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated <m>SegNet</m>++ on different computer vision tasks, demonstrating its effectiveness in semantic segmentation and object recognition.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SegNet++",
  "Version": "2.0",
  "License": "Apache 2.0 License",
  "URL": "https://github.com/segnetpp",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "The researchers developed a novel algorithm for image segmentation, called SegNet++. It is an extension of the original SegNet algorithm and incorporates additional deep learning techniques. SegNet++ (v2.0) achieved state-of-the-art performance on various benchmark datasets, including PASCAL VOC and Cityscapes. The algorithm is publicly available under the Apache 2.0 license and can be accessed at https://github.com/segnetpp. The authors extensively evaluated SegNet++ on different computer vision tasks, demonstrating its effectiveness in semantic <m>segmentation</m> and object recognition.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "<m>Deep convolutional neural networks</m> have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural <m>networks</m> have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in <m>image</m> classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], <m>convolutional neural networks</m> have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural <m>networks</m> have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for <m>image</m> classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger <m>data sets</m>, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger <m>data</m> sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data <m>sets</m>, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better <m>models and training algorithms</m> and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better <m>models</m> and training algorithms and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and <m>training algorithms</m> and the availability of GPU computing to enable investigation of larger and deeper models.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Deep convolutional neural networks have recently been substantially improving upon the state of the art in image classification and other recognition tasks [2, 6,10]. Since their introduction in the early 1990s [7], convolutional neural networks have consistently been competitive with other techniques for image classification and recognition. Recently, they have pulled away from competing methods due the availability of larger data sets, better models and training algorithms and the availability of GPU computing to enable investigation of larger and deeper <m>models</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Do different <m>victim models</m> agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the SQuAD training set (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim <m>SQuAD</m> models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the SQuAD training set (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD <m>models</m> on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the SQuAD training set (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training <m>data</m> with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the SQuAD training set (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQUAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these <m>models</m> for different types of queries. As expected, the models agree very frequently when queries come from the SQuAD training set (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the <m>models</m> agree very frequently when queries come from the SQuAD training set (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the <m>SQuAD training set</m> (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the <m>SQuAD</m> training set (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the SQuAD <m>training set</m> (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Do different victim models agree on the answers to nonsensical queries? We train five victim SQuAD models on the original training data with identical hyperparameters, varying only the random seed; each achieves an F1 between 90 and 90.5. Then, we measure the average pairwise F1 (\\\"agreement\\\") between the answers produced by these models for different types of queries. As expected, the models agree very frequently when queries come from the SQuAD training <m>set</m> (96.9 F1) or development set (90.4 F1). However, their agreement drops significantly on WIKI queries (53.0 F1) and even further on RANDOM queries (41.2 F1).9 Note that this result parallels prior work (Lakshminarayanan et al., 2017), where an ensemble of classifiers has been shown to provide better uncertainty estimates and out-of-distribution detection than a single overconfident classifier.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training <m>dataset</m> (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the <m>Google Cloud Platform's Natural Language API calculator</m>. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Natural Language API calculator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the <m>Google Cloud</m> Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Natural Language API calculator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the <m>Google</m> Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Natural Language API calculator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language <m>API calculator</m>. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Natural Language API calculator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language <m>API</m> calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud Natural Language API calculator",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted <m>models</m> on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original <m>development set</m>, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development <m>set</m>, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the <m>extracted model</m> and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted <m>model</m> and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the <m>victim model</m> on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim <m>model</m> on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original <m>development set</m> inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development <m>set</m> inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the <m>victim and extracted model</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A | N/A",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the <m>victim</m> and extracted model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and <m>extracted model</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "First, we evaluate our extraction procedure in a controlled setting where an attacker uses an identical number of queries as the original training dataset (Table 2); afterwards, we investigate different query budgets for each task (Table 3). We provide commercial cost estimates for these query budgets using the Google Cloud Platform's Natural Language API calculator. 7 We use two metrics for evaluation: Accuracy of the extracted models on the original development set, and Agreement between the outputs of the extracted model and the victim model on the original development set inputs. Note that these metrics are defined at a label level -metrics are calculated using the argmax labels of the probability vectors predicted by the victim and extracted <m>model</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A | N/A",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "For English, we use the benchmark <m>dataset</m> LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LJSpeech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset <m>LJSpeech</m> [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LJSpeech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 <m>audio clips</m> of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LJSpeech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the <m>dataset</m> is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LJSpeech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into <m>training, validation and test sets</m> of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LJSpeech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test <m>sets</m> of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LJSpeech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 <m>clip samples</m>, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "LJSpeech",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the <m>PhoBERT pre-training news data</m> [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PhoBERT pre-training news",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the <m>PhoBERT</m> pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PhoBERT pre-training news",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news <m>data</m> [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "PhoBERT pre-training news",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our <m>Vietnamese TTS dataset</m> into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Vietnamese TTS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our <m>Vietnamese TTS</m> dataset into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Vietnamese TTS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS <m>dataset</m> into training, validation and test sets of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Vietnamese TTS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into <m>training, validation and test sets</m> of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Vietnamese TTS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test <m>sets</m> of 12,000, 100 and 200 clips, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Vietnamese TTS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "For English, we use the benchmark dataset LJSpeech [32] consisting of 13,100 audio clips of a single speaker with a total duration of about 24 hours (here, each clip is also provided with a gold-standard text transcription). Following [9], the dataset is split into training, validation and test sets of 12,500, 100 and 500 clip samples, respectively. For Vietnamese, we randomly sample 12,300 different medium-length sentences from the PhoBERT pre-training news data [33]. We hire a professional speaker to read each sentence in a studio and record the corresponding audio, resulting in a total duration of about 18 hours for 12,300 high-quality audio clips. We split our Vietnamese TTS dataset into training, validation and test sets of 12,000, 100 and 200 <m>clips</m>, respectively.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Vietnamese TTS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "For each language whose locales do not have their own <m>Wikipedia</m> data, 5 we randomly divide the language's Wikipedia data into equal parts (each with the same number of sentences), with each part corresponding to a locale. For example, we divide 67 million English sentences into two equal parts that are then separately converted into phonemic descriptions in British English (eng-uk) and American English (eng-us).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "For each language whose locales do not have their own Wikipedia <m>data</m>, 5 we randomly divide the language's Wikipedia data into equal parts (each with the same number of sentences), with each part corresponding to a locale. For example, we divide 67 million English sentences into two equal parts that are then separately converted into phonemic descriptions in British English (eng-uk) and American English (eng-us).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "For each language whose locales do not have their own Wikipedia data, 5 we randomly divide the language's <m>Wikipedia</m> data into equal parts (each with the same number of sentences), with each part corresponding to a locale. For example, we divide 67 million English sentences into two equal parts that are then separately converted into phonemic descriptions in British English (eng-uk) and American English (eng-us).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "For each language whose locales do not have their own Wikipedia data, 5 we randomly divide the language's Wikipedia <m>data</m> into equal parts (each with the same number of sentences), with each part corresponding to a locale. For example, we divide 67 million English sentences into two equal parts that are then separately converted into phonemic descriptions in British English (eng-uk) and American English (eng-us).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual <m>datasets</m> wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b | wikipedia",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets <m>wiki40b [22] and wikipedia [23]</m>, available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b | wikipedia",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets <m>wiki40b</m> [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and <m>wikipedia</m> [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the <m>Hugging Face datasets</m> library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Hugging Face datasets",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the <m>Hugging Face</m> datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Hugging Face datasets",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets <m>library</m> [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "Hugging Face datasets",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the <m>wiki40b dataset</m> consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the <m>wiki40b</m> dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b <m>dataset</m> consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of <m>text documents</m> for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text <m>documents</m> for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use <m>wikipedia</m> to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract <m>texts</m> from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from <m>Wikipedia dumps</m> for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from <m>Wikipedia</m> dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia <m>dumps</m> for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wikipedia",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to <m>wiki40b</m>. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "wiki40b",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the <m>spaCy toolkit</m>, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "spaCy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the <m>spaCy</m> toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "spaCy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy <m>toolkit</m>, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "spaCy",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ <m>RDRSegmenter</m> [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RDRSegmenter",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the <m>VnCoreNLP toolkit</m> [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VnCoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the <m>VnCoreNLP</m> toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VnCoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP <m>toolkit</m> [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VnCoreNLP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization <m>tool</m> publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the <m>text</m> normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization <m>component</m> from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the <m>NVIDIA NeMo toolkit</m> [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NVIDIA NeMo",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the <m>NVIDIA NeMo</m> toolkit [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NVIDIA NeMo",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo <m>toolkit</m> [27] for English, German, Spanish and Chinese, and the Vinorm text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "NVIDIA NeMo",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the <m>Vinorm</m> text normalization package for Vietnamese.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Vinorm",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Here, we employ the multilingual datasets wiki40b [22] and wikipedia [23], available to download from the Hugging Face datasets library [24]. In particular, we first download the wiki40b dataset consisting of text documents for 41 Wikipedia languages and locales. 1 We then use wikipedia to extract texts from Wikipedia dumps for remaining languages other than those belonging to wiki40b. 2 e perform word and sentence segmentation on all text documents in each language by using the spaCy toolkit, 3 except for Vietnamese where we employ RDRSegmenter [25] from the VnCoreNLP toolkit [26]. We then lowercase all sentences and filter out duplicate sentences and single-word ones. We also apply text normalization to convert texts from their written form into their verbalized form for only English, German, Spanish, Vietnamese and Chinese (it is because we could not find an effective text normalization tool publicly available for other languages). Here, we use the text normalization component from the NVIDIA NeMo toolkit [27] for English, German, Spanish and Chinese, and the Vinorm <m>text</m> normalization package for Vietnamese.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted <m>models</m> are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original <m>data</m> distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: <m>extracted SQuAD models</m> recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "extracted SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted <m>SQuAD</m> models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "extracted SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD <m>models</m> recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "extracted SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While <m>extracted models</m> have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "extracted SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted <m>models</m> have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "extracted SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On <m>SQuAD</m>, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed <m>data</m>. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQUAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the <m>victim</m> and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and <m>extracted model</m> as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "extracted SQuAD models",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted <m>model</m> as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and MNLI is conducted in Appendix A.4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A | extracted SQuAD models",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "Yes | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for <m>SQuAD</m> and MNLI is conducted in Appendix A.4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In our controlled setting (Table 2), our extracted models are surprisingly accurate on the original development sets of all tasks, even when trained with nonsensical inputs (RANDOM) that do not match the original data distribution.8 Accuracy improves further on WIKI: extracted SQuAD models recover 95% of original accuracy despite seeing only nonsensical questions during training. While extracted models have high accuracy, their agreement is only slightly better than accuracy in most cases. Agreement is even lower on held-out sets constructed using the WIKI and RANDOM sampling scheme. On SQuAD, extracted WIKI and RANDOM have low agreements of 59.2 F1 and 50.5 F1 despite being trained on identically distributed data. This indicates poor functional equivalence between the victim and extracted model as also found by Jagielski et al. (2019). An ablation study with alternative query generation heuristics for SQuAD and <m>MNLI</m> is conducted in Appendix A.4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNLI",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "<m>Large Languages Models (LLMs)</m> trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "<m>Large Languages Models</m> (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages <m>Models</m> (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages Models (<m>LLMs</m>) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages Models (LLMs) trained on massive <m>corpora</m> of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling <m>models</m> to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these <m>models</m> (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest <m>models</m>, but by smaller models trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller <m>models</m> trained on more data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020). These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020), resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022;Rae et al., 2021). These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more <m>data</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning <m>models</m> represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training <m>data</m>, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over <m>model</m> design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these <m>models</m> are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through <m>web APIs</m> that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web <m>APIs</m> that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a <m>model</m> but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive <m>model</m> development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing <m>model</m> served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an <m>API</m>. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"<m>model</m> stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"<m>model</m> extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the <m>model</m>. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted <m>models</m> may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training <m>data</m> (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the API (Papernot et al., 2017).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the <m>model</m> served by the API (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Machine learning models represent valuable intellectual property: the process of gathering training data, iterating over model design, and tuning hyperparameters costs considerable money and effort. As such, these models are often only indirectly accessible through web APIs that allow users to query a model but not inspect its parameters. Malicious users might try to sidestep the expensive model development cycle by instead locally reproducing an existing model served by such an API. In these attacks, known as \\\"model stealing\\\" or \\\"model extraction\\\" (Lowd & Meek, 2005;Tram\\u00e8r et al., 2016), the adversary issues a large number of queries and uses the collected (input, output) pairs to train a local copy of the model. Besides theft of intellectual property, extracted models may leak sensitive information about the training data (Tram\\u00e8r et al., 2016) or be used to generate adversarial examples that evade the model served by the <m>API</m> (Papernot et al., 2017).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Mismatched architectures: <m>BERT</m> comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer <m>BERT</m>-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer <m>BERT</m>-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on <m>MNLI and SQuAD</m> when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNLI | SQuAD",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on <m>MNLI</m> and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNLI",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and <m>SQuAD</m> when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two <m>models</m>. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large | BERT-base",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from <m>BERT</m>-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with <m>BERT</m>-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same <m>model</m> (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from <m>BERT</m>-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used <m>BERT</m>-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning <m>BERT</m> or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or <m>XLNet</m> seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the <m>model</m> is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the <m>BERT</m> parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a <m>QANet model</m> (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QANet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a <m>QANet</m> model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QANet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet <m>model</m> (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QANet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on <m>SQuAD</m> with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This <m>model</m> has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QANet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that <m>QANet</m> achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QANet",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original <m>SQuAD</m> inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with <m>BERT</m>-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (<m>BERT</m>-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient <m>model</m> capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows models to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Mismatched architectures: BERT comes in two different sizes: the 24 layer BERT-large and the 12 layer BERT-base. In Table 4, we measure the development set accuracy on MNLI and SQuAD when the victim and attacker use different configurations of these two models. We notice that accuracy is always higher when the attacker starts from BERT-large, even when the victim was initialized with BERT-base. Additionally, given a fixed attacker architecture, accuracy is better when the victim uses the same model (e.g., if the attacker starts from BERT-base, they will have better results if the victim also used BERT-base). What if we train from scratch? Fine-tuning BERT or XLNet seems to give attackers a significant headstart, as only the final layer of the model is randomly initialized and the BERT parameters start from a good initialization representative of the properties of language. To measure the importance of fine-tuning from a good starting point, we train a QANet model (Yu et al., 2018) on SQuAD with no contextualized pretraining. This model has 1.3 million randomly initialized parameters at the start of training. Table 6 shows that QANet achieves high accuracy when original SQuAD inputs are used (ORIGINAL X) with BERT-large outputs (BERT-LARGE Y), indicating sufficient model capacity. However, the F1 significantly degrades when training on nonsensical RANDOM and WIKI queries. The F1 drop is particularly striking when compared to the corresponding rows in Table 2 (only 4.5 F1 drop for WIKI). This reinforces our finding that better pretraining allows <m>models</m> to start from a good representation of language, thus simplifying extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most VLP <m>methods</m> perform end-to-end pre-training using large-scale image-text pair datasets. As the model size keeps increasing, the pre-training can incur an extremely high computation cost. Moreover, it is inflexible for end-to-end pre-trained models to leverage readily-available unimodal pre-trained models, such as LLMs (Brown et al., 2020;Zhang et al., 2022;Chung et al., 2022).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most VLP methods perform end-to-end pre-training using large-scale <m>image</m>-text pair datasets. As the model size keeps increasing, the pre-training can incur an extremely high computation cost. Moreover, it is inflexible for end-to-end pre-trained models to leverage readily-available unimodal pre-trained models, such as LLMs (Brown et al., 2020;Zhang et al., 2022;Chung et al., 2022).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Most VLP methods perform end-to-end pre-training using large-scale image-text pair <m>datasets</m>. As the model size keeps increasing, the pre-training can incur an extremely high computation cost. Moreover, it is inflexible for end-to-end pre-trained models to leverage readily-available unimodal pre-trained models, such as LLMs (Brown et al., 2020;Zhang et al., 2022;Chung et al., 2022).",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Most VLP methods perform end-to-end pre-training using large-scale image-text pair datasets. As the <m>model</m> size keeps increasing, the pre-training can incur an extremely high computation cost. Moreover, it is inflexible for end-to-end pre-trained models to leverage readily-available unimodal pre-trained models, such as LLMs (Brown et al., 2020;Zhang et al., 2022;Chung et al., 2022).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most VLP methods perform end-to-end pre-training using large-scale image-text pair datasets. As the model size keeps increasing, the pre-training can incur an extremely high computation cost. Moreover, it is inflexible for end-to-end pre-trained <m>models</m> to leverage readily-available unimodal pre-trained models, such as LLMs (Brown et al., 2020;Zhang et al., 2022;Chung et al., 2022).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most VLP methods perform end-to-end pre-training using large-scale image-text pair datasets. As the model size keeps increasing, the pre-training can incur an extremely high computation cost. Moreover, it is inflexible for end-to-end pre-trained models to leverage readily-available unimodal pre-trained <m>models</m>, such as LLMs (Brown et al., 2020;Zhang et al., 2022;Chung et al., 2022).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most VLP methods perform end-to-end pre-training using large-scale image-text pair datasets. As the model size keeps increasing, the pre-training can incur an extremely high computation cost. Moreover, it is inflexible for end-to-end pre-trained models to leverage readily-available unimodal pre-trained models, such as <m>LLMs</m> (Brown et al., 2020;Zhang et al., 2022;Chung et al., 2022).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLMs",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Our careful design reuses and preserves the pre-trained <m>model</m> weights of SAM, while only introducing minimal additional parameters and computation.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Our careful design reuses and preserves the pre-trained model weights of <m>SAM</m>, while only introducing minimal additional parameters and computation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SAM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our <m>code</m> and models will be released at https://gitlab.com/SysCV/SAM-HQ.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://gitlab.com/SysCV/SAM-HQ",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our code and <m>models</m> will be released at https://gitlab.com/SysCV/SAM-HQ.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SAM-HQ",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://gitlab.com/SysCV/SAM-HQ",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments show that ToT significantly enhances language <m>models</m>' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.\\nPreprint. Under review.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while <m>GPT-4</m> with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.\\nPreprint. Under review.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while <m>GPT</m>-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.\\nPreprint. Under review.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-4",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our <m>method</m> achieved a success rate of 74%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.\\nPreprint. Under review.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%. <m>Code</m> repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.\\nPreprint. Under review.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%. Code <m>repo</m> with all prompts: https://github.com/ysymyth/tree-of-thought-llm.\\nPreprint. Under review.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/ysymyth/tree-of-thought-llm",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our multilingual pre-training <m>dataset</m> is constructed following three phases. The first phase is to collect text documents and then perform word and sentence segmentation as well as duplicate removal and text normalization. The second phase is to convert texts into phonemes, employing the CharsiuG2P toolkit [21] that supports 90+ languages and locales. Finally, the third phase is to perform phoneme segmentation.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our multilingual pre-training dataset is constructed following three phases. The first phase is to collect <m>text documents</m> and then perform word and sentence segmentation as well as duplicate removal and text normalization. The second phase is to convert texts into phonemes, employing the CharsiuG2P toolkit [21] that supports 90+ languages and locales. Finally, the third phase is to perform phoneme segmentation.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our multilingual pre-training dataset is constructed following three phases. The first phase is to collect text <m>documents</m> and then perform word and sentence segmentation as well as duplicate removal and text normalization. The second phase is to convert texts into phonemes, employing the CharsiuG2P toolkit [21] that supports 90+ languages and locales. Finally, the third phase is to perform phoneme segmentation.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Our multilingual pre-training dataset is constructed following three phases. The first phase is to collect text documents and then perform word and sentence segmentation as well as duplicate removal and text normalization. The second phase is to convert texts into phonemes, employing the <m>CharsiuG2P toolkit</m> [21] that supports 90+ languages and locales. Finally, the third phase is to perform phoneme segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our multilingual pre-training dataset is constructed following three phases. The first phase is to collect text documents and then perform word and sentence segmentation as well as duplicate removal and text normalization. The second phase is to convert texts into phonemes, employing the <m>CharsiuG2P</m> toolkit [21] that supports 90+ languages and locales. Finally, the third phase is to perform phoneme segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our multilingual pre-training dataset is constructed following three phases. The first phase is to collect text documents and then perform word and sentence segmentation as well as duplicate removal and text normalization. The second phase is to convert texts into phonemes, employing the CharsiuG2P <m>toolkit</m> [21] that supports 90+ languages and locales. Finally, the third phase is to perform phoneme segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Our multilingual pre-training dataset is constructed following three phases. The first phase is to collect text documents and then perform word and sentence segmentation as well as duplicate removal and text normalization. The second phase is to convert texts into phonemes, employing the CharsiuG2P <m>toolkit</m> [21] that supports 90+ languages and locales. Finally, the third phase is to perform phoneme segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained <m>models</m> for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT | Phoneme-level BERT",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "No | No | No",
  "Usage": "No | No | No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including <m>PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18]</m>, help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT | Phoneme-level BERT",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "No | No | No",
  "Usage": "No | No | No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including <m>PnG BERT</m> [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], <m>Mixed-Phoneme BERT</m> [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Mixed-Phoneme BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and <m>Phoneme-level BERT</m> [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Phoneme-level BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced <m>TTS systems</m>. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS <m>systems</m>. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. <m>PnG BERT and Mixed-Phoneme BERT</m> are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "No | No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. <m>PnG BERT</m> and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and <m>Mixed-Phoneme BERT</m> are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Mixed-Phoneme BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the <m>BERT pre-training approach</m> [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the <m>BERT</m> pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training <m>approach</m> [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which <m>PnG BERT</m> takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while <m>Mixed-Phoneme BERT</m> takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Mixed-Phoneme BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. <m>Phoneme-level BERT</m> is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Phoneme-level BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the <m>ALBERT pretraining approach</m> [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ALBERT pretraining approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the <m>ALBERT</m> pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Name": "ALBERT",
  "Valid": "Yes",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining <m>approach</m> [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ALBERT pretraining approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in <m>PnG BERT and Mixed-Phoneme BERT</m>, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "No | No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in <m>PnG BERT</m> and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and <m>Mixed-Phoneme BERT</m>, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Mixed-Phoneme BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the <m>Phoneme-level BERT</m> also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Phoneme-level BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, <m>PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT</m> can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT | Phoneme-level BERT",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, <m>PnG BERT</m>, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, <m>Mixed-Phoneme BERT</m> and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Mixed-Phoneme BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and <m>Phoneme-level BERT</m> can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Phoneme-level BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input <m>encoder</m> in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT | Phoneme-level BERT",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural <m>TTS system</m>. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these <m>pre-trained language models</m> has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT | Phoneme-level BERT",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language <m>models</m> has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained models for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PnG BERT | Mixed-Phoneme BERT | Phoneme-level BERT",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "No | No | No",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "Recent works confirm that pre-trained models for phoneme representations, including PnG BERT [16], Mixed-Phoneme BERT [17] and Phoneme-level BERT [18], help improve advanced TTS systems. PnG BERT and Mixed-Phoneme BERT are trained based on the BERT pre-training approach [10], in which PnG BERT takes both phonemes and graphemes (i.e. subword tokens) as the input, while Mixed-Phoneme BERT takes both phonemes and sup-phoneme tokens as the input. Phoneme-level BERT is trained based on the ALBERT pretraining approach [12], only taking phonemes as the input. In addition to the standard masked token prediction task as used in PnG BERT and Mixed-Phoneme BERT, the Phoneme-level BERT also proposes an additional auxiliary task that predicts the corresponding grapheme for each phoneme. Here, PnG BERT, Mixed-Phoneme BERT and Phoneme-level BERT can be directly used as an input encoder in a typical neural TTS system. Note that the success of these pre-trained language models has been limited to the English language only. Taking into account a societal, linguistic, cultural, machine learning and cognitive perspective [19], it is worth exploring pre-trained <m>models</m> for phoneme representations in languages other than English.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original <m>SQuAD dataset</m> ; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "<m>SQuAD</m> dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD <m>dev set</m> results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev <m>set</m> results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing <m>BERT-large and XLNet-large attacker</m> architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large attacker | XLNet-large attacker",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing <m>BERT</m>-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and <m>XLNet</m>-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of <m>XLNet</m>-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over <m>BERT</m>-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing <m>BERT-LARGE</m> victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-LARGE victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing <m>BERT</m>-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-LARGE victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker <m>model</m>; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original <m>SQuAD</m> dataset; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD <m>dataset</m>; BERT-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; <m>BERT</m>-LARGE represents the outputs from the victim BERT-large model.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BERT-LARGE victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim <m>BERT</m>-large model.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-LARGE victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "SQuAD dev set results comparing BERT-large and XLNet-large attacker architectures. Note the effectiveness of XLNet-large over BERT-large in both RANDOM and WIKI attack settings, despite seeing BERT-LARGE victim outputs during training. Legend: Training Data X, Y represent the input and output pairs used while training the attacker model; ORIGINAL represents the original SQuAD dataset; BERT-LARGE represents the outputs from the victim BERT-large <m>model</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-LARGE victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Since <m>Google Cloud</m> did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Since <m>Google</m> Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Google Cloud",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Since Google Cloud did not have <m>APIs</m> for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis <m>APIs</m> for natural language inference (MNLI) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (<m>MNLI</m>) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MNLI",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (<m>SQuAD, BoolQ</m>). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD | BolQ",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (<m>SQuAD</m>, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (SQuAD, <m>BoolQ</m>). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "BolQ",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every <m>model</m> studied in this paper is a single layer in addition to BERT-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to <m>BERT-large</m> (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Since Google Cloud did not have APIs for all tasks we study in this paper, we extrapolated the costs of the entity analysis and sentiment analysis APIs for natural language inference (MNLI) and reading comprehension (SQuAD, BoolQ). We believe this is a reasonable estimate since every model studied in this paper is a single layer in addition to <m>BERT</m>-large (thereby needing a similar number of FLOPs for similar input lengths).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "So far we assumed that the victim and the attacker both fine-tune a pretrained <m>BERT</m>-large model. However, in practical scenarios, the attacker might not have information about the victim architecture. What happens when the attacker fine-tunes a different base model than the victim? What if the attacker extracts a QA model from scratch instead of fine-tuning a large pretrained language model? Here, we examine how much the extraction accuracy depends on the pretraining setup.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "So far we assumed that the victim and the attacker both fine-tune a pretrained BERT-large <m>model</m>. However, in practical scenarios, the attacker might not have information about the victim architecture. What happens when the attacker fine-tunes a different base model than the victim? What if the attacker extracts a QA model from scratch instead of fine-tuning a large pretrained language model? Here, we examine how much the extraction accuracy depends on the pretraining setup.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "So far we assumed that the victim and the attacker both fine-tune a pretrained BERT-large model. However, in practical scenarios, the attacker might not have information about the victim <m>architecture</m>. What happens when the attacker fine-tunes a different base model than the victim? What if the attacker extracts a QA model from scratch instead of fine-tuning a large pretrained language model? Here, we examine how much the extraction accuracy depends on the pretraining setup.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "So far we assumed that the victim and the attacker both fine-tune a pretrained BERT-large model. However, in practical scenarios, the attacker might not have information about the victim architecture. What happens when the attacker fine-tunes a different base <m>model</m> than the victim? What if the attacker extracts a QA model from scratch instead of fine-tuning a large pretrained language model? Here, we examine how much the extraction accuracy depends on the pretraining setup.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "So far we assumed that the victim and the attacker both fine-tune a pretrained BERT-large model. However, in practical scenarios, the attacker might not have information about the victim architecture. What happens when the attacker fine-tunes a different base model than the <m>victim</m>? What if the attacker extracts a QA model from scratch instead of fine-tuning a large pretrained language model? Here, we examine how much the extraction accuracy depends on the pretraining setup.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "So far we assumed that the victim and the attacker both fine-tune a pretrained BERT-large model. However, in practical scenarios, the attacker might not have information about the victim architecture. What happens when the attacker fine-tunes a different base model than the victim? What if the attacker extracts a QA <m>model</m> from scratch instead of fine-tuning a large pretrained language model? Here, we examine how much the extraction accuracy depends on the pretraining setup.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "So far we assumed that the victim and the attacker both fine-tune a pretrained BERT-large model. However, in practical scenarios, the attacker might not have information about the victim architecture. What happens when the attacker fine-tunes a different base model than the victim? What if the attacker extracts a QA model from scratch instead of fine-tuning a large pretrained language <m>model</m>? Here, we examine how much the extraction accuracy depends on the pretraining setup.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Some <m>methods</m> freeze the image encoder, including the early work which adopts a frozen object detector to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent LiT (Zhai et al., 2022) which uses a frozen pre-trained image encoder for CLIP (Radford et al., 2021) pre-training.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the <m>image encoder</m>, including the early work which adopts a frozen object detector to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent LiT (Zhai et al., 2022) which uses a frozen pre-trained image encoder for CLIP (Radford et al., 2021) pre-training.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the <m>image</m> encoder, including the early work which adopts a frozen object detector to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent LiT (Zhai et al., 2022) which uses a frozen pre-trained image encoder for CLIP (Radford et al., 2021) pre-training.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the image encoder, including the early work which adopts a frozen <m>object detector</m> to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent LiT (Zhai et al., 2022) which uses a frozen pre-trained image encoder for CLIP (Radford et al., 2021) pre-training.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the image encoder, including the early work which adopts a frozen object detector to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent <m>LiT</m> (Zhai et al., 2022) which uses a frozen pre-trained image encoder for CLIP (Radford et al., 2021) pre-training.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LiT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Some methods freeze the image encoder, including the early work which adopts a frozen object detector to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent LiT (Zhai et al., 2022) which uses a frozen pre-trained <m>image encoder</m> for CLIP (Radford et al., 2021) pre-training.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the image encoder, including the early work which adopts a frozen object detector to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent LiT (Zhai et al., 2022) which uses a frozen pre-trained <m>image</m> encoder for CLIP (Radford et al., 2021) pre-training.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the image encoder, including the early work which adopts a frozen object detector to extract visual features (Chen et al., 2020;Li et al., 2020;Zhang et al., 2021), and the recent LiT (Zhai et al., 2022) which uses a frozen pre-trained image encoder for <m>CLIP</m> (Radford et al., 2021) pre-training.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "CLIP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Some <m>methods</m> freeze the language model to use the knowledge from LLMs for vision-to-language generation tasks (Tsimpoukelli et al., 2021;Alayrac et al., 2022;Chen et al., 2022a;Ma\\u00f1as et al., 2023;Tiong et al., 2022;Guo et al., 2022).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the language <m>model</m> to use the knowledge from LLMs for vision-to-language generation tasks (Tsimpoukelli et al., 2021;Alayrac et al., 2022;Chen et al., 2022a;Ma\\u00f1as et al., 2023;Tiong et al., 2022;Guo et al., 2022).",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Some methods freeze the language model to use the knowledge from <m>LLMs</m> for vision-to-language generation tasks (Tsimpoukelli et al., 2021;Alayrac et al., 2022;Chen et al., 2022a;Ma\\u00f1as et al., 2023;Tiong et al., 2022;Guo et al., 2022).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLMs",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "<m>SpQR</m> comes with efficient algorithms for both encoding weights into its format, as well as decoding them efficiently at runtime 3 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SpQR",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "SpQR comes with efficient <m>algorithms</m> for both encoding weights into its format, as well as decoding them efficiently at runtime 3 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Specifically, we provide an efficient GPU inference <m>algorithm</m> for SpQR which yields faster inference than 16-bit baselines at similar accuracy, while enabling memory compression gains of more than 4x.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Specifically, we provide an efficient GPU inference algorithm for <m>SpQR</m> which yields faster inference than 16-bit baselines at similar accuracy, while enabling memory compression gains of more than 4x.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SpQR",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale <m>models</m>. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes <m>BLIP-2</m>, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes <m>BLIP</m>-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained <m>image encoders</m> and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained <m>image</m> encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language <m>models</m>. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. <m>BLIP-2</m> bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. <m>BLIP</m>-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying <m>Transformer</m>, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen <m>image encoder</m>. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen <m>image</m> encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language <m>model</m>. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. <m>BLIP-2</m> achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. <m>BLIP</m>-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing <m>methods</m>. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our <m>model</m> outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms <m>Flamingo80B</m> by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Flamingo80B",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot <m>VQAv2</m> with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "VQAv2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the <m>model</m>'s emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BLIP-2",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot <m>image</m>-to-text generation that can follow natural language instructions.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-<m>text</m> generation that can follow natural language instructions.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language <m>models</m>, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT | RoBERTa | ALBERT",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "No | No | No",
  "Usage": "No | No | No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. <m>BERT</m> [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], <m>RoBERTa</m> [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and <m>ALBERT</m> [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ALBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and <m>application</m> tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained <m>BERT</m> [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "\u039d\u03bf"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard <m>encoder</m> [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TTS encoder",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard <m>TTS encoder</m> to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TTS encoder",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into <m>BERT</m> to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "method",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the <m>TTS decoder</m>, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TTS decoder",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the <m>BERT</m>-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, <m>BERT</m> helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained <m>BERT</m> is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained <m>BERT-type model</m> that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-type",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained <m>BERT</m>-type model that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-type",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type <m>model</m> that is learned from unlabeled phoneme-level data.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-type",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The large-scale pre-trained language models, e.g. BERT [10], RoBERTa [11] and ALBERT [12], have proved their effectiveness, improving state-of-the-art performances of various natural language processing research and application tasks. For TTS, some works incorporate contextualized word embeddings generated by the pre-trained BERT [10] into their standard encoder [13,14,15]. In general, an input phoneme sequence is fed into the standard TTS encoder to produce phoneme representations, while its corresponding raw text is fed into BERT to obtain contextualized word embeddings. To construct the input vectors of the TTS decoder, the produced representations of the input phonemes are concatenated with the BERT-based contextualized embedding of the corresponding word that the phonemes belong to. As a result, BERT helps increase the quality of the output synthesized speech. Here, the pre-trained BERT is used to provide additional contextual information for phoneme representations indirectly. Therefore, it might be better if the contextualized phoneme representations are directly produced by a pre-trained BERT-type model that is learned from unlabeled phoneme-level <m>data</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The recent <m>Segment Anything Model (SAM)</m> represents a big leap in scaling up segmentation models, allowing for powerful zero-shot capabilities and flexible prompting.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Segment Anything Model (SAM)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The recent <m>Segment Anything Model</m> (SAM) represents a big leap in scaling up segmentation models, allowing for powerful zero-shot capabilities and flexible prompting.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Segment Anything Model (SAM)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The recent Segment Anything <m>Model</m> (SAM) represents a big leap in scaling up segmentation models, allowing for powerful zero-shot capabilities and flexible prompting.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Segment Anything Model (SAM)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The recent Segment Anything Model (<m>SAM</m>) represents a big leap in scaling up segmentation models, allowing for powerful zero-shot capabilities and flexible prompting.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Segment Anything Model (SAM)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The recent Segment Anything Model (SAM) represents a big leap in scaling up segmentation <m>models</m>, allowing for powerful zero-shot capabilities and flexible prompting.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "This section outlines the architecture and describes the multilingual pre-training <m>corpus</m> and optimization setup that we use for XPhoneBERT.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "This section outlines the architecture and describes the multilingual pre-training corpus and optimization setup that we use for <m>XPhoneBERT</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To address this accuracy issue, we introduce the <m>Sparse-Quantized Representation (SpQR)</m>, a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous methods.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Sparse-Quantized Representation (SpQR)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To address this accuracy issue, we introduce the <m>Sparse-Quantized Representation</m> (SpQR), a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous methods.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Sparse-Quantized Representation (SpQR)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To address this accuracy issue, we introduce the Sparse-Quantized Representation (<m>SpQR</m>), a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous methods.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Sparse-Quantized Representation (SpQR)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To address this accuracy issue, we introduce the Sparse-Quantized Representation (SpQR), a new compressed format and quantization <m>technique</m> which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous methods.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Sparse-Quantized Representation (SpQR)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To address this accuracy issue, we introduce the Sparse-Quantized Representation (SpQR), a new compressed format and quantization technique which enables for the first time near-lossless compression of <m>LLMs</m> across model scales, while reaching similar compression levels to previous methods.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To address this accuracy issue, we introduce the Sparse-Quantized Representation (SpQR), a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across <m>model</m> scales, while reaching similar compression levels to previous methods.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To address this accuracy issue, we introduce the Sparse-Quantized Representation (SpQR), a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous <m>methods</m>.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the <m>grapheme-to-phoneme conversion toolkit</m> Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion <m>toolkit</m> Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit <m>Char-siuG2P</m> [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained <m>CharsiuG2P</m> is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual <m>Transformer-based model</m> that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual <m>Transformer</m>-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based <m>model</m> that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the <m>CharsiuG2P toolkit</m>'s pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the <m>CharsiuG2P</m> toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P <m>toolkit</m>'s pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained <m>CharsiuG2P model</m> to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained <m>CharsiuG2P</m> model to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To convert sentences into their phonemic description, we employ the grapheme-to-phoneme conversion toolkit Char-siuG2P [21]. The pre-trained CharsiuG2P is a strong multilingual Transformer-based model that generates the pronunciation of a word given its orthographic form and ISO 639-3 language code pair. Following the recommendation from [21], if the input word is in the CharsiuG2P toolkit's pronunciation dictionary of the target language/locale, we employ the pronunciation dictionary to generate the word's phonemic description. Otherwise, if the word is out of the vocabulary, we employ the pre-trained CharsiuG2P <m>model</m> to generate its phonemic description.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CharsiuG2P",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language <m>model</m> for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training <m>corpus</m> of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our <m>model</m> is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the <m>RoBERTa pre-training approach</m> [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the <m>RoBERTa</m> pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training <m>approach</m> [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the <m>BERT</m>-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base model configuration",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base <m>model</m> configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base model configuration",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our <m>model</m> as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an <m>input phoneme encoder</m> of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong <m>model</m> VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VITS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model <m>VITS</m> [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VITS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental <m>results</m> show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our <m>model</m> helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of <m>VITS</m>, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VITS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original <m>VITS</m> without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VITS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of 330M phonemic description sentences from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training <m>data</m>. We summarize our contribution as follows:",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To fill the gap, we train the first large-scale multilingual language model for phoneme representations, using a pre-training corpus of <m>330M phonemic description sentences</m> from nearly 100 languages and locales. Our model is trained based on the RoBERTa pre-training approach [11], using the BERT-base model configuration [10]. We conduct experiments on the downstream TTS task, directly employing our model as an input phoneme encoder of the strong model VITS [9]. Experimental results show that our model helps boost the performance of VITS, obtaining more natural prosody than the original VITS without pre-training and also producing fairly high-quality synthesized speech with limited training data. We summarize our contribution as follows:",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To further improve training efficiency, we reduced the amount of activations that are recomputed during the backward pass with checkpointing. More precisely, we save the activations that are expensive to compute, such as the outputs of linear layers. This is achieved by manually implementing the backward function for the <m>transformer</m> layers, instead of relying on the PyTorch autograd. reduce the memory usage of the model by using model and sequence parallelism, as described by Korthikanti et al. (2022). Moreover, we also overlap the computation of activations and the communication between GPUs over the network (due to all_reduce operations) as much as possible.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To further improve training efficiency, we reduced the amount of activations that are recomputed during the backward pass with checkpointing. More precisely, we save the activations that are expensive to compute, such as the outputs of linear layers. This is achieved by manually implementing the backward function for the transformer layers, instead of relying on the <m>PyTorch autograd</m>. reduce the memory usage of the model by using model and sequence parallelism, as described by Korthikanti et al. (2022). Moreover, we also overlap the computation of activations and the communication between GPUs over the network (due to all_reduce operations) as much as possible.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch autograd",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To further improve training efficiency, we reduced the amount of activations that are recomputed during the backward pass with checkpointing. More precisely, we save the activations that are expensive to compute, such as the outputs of linear layers. This is achieved by manually implementing the backward function for the transformer layers, instead of relying on the <m>PyTorch</m> autograd. reduce the memory usage of the model by using model and sequence parallelism, as described by Korthikanti et al. (2022). Moreover, we also overlap the computation of activations and the communication between GPUs over the network (due to all_reduce operations) as much as possible.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PyTorch",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To further improve training efficiency, we reduced the amount of activations that are recomputed during the backward pass with checkpointing. More precisely, we save the activations that are expensive to compute, such as the outputs of linear layers. This is achieved by manually implementing the backward function for the transformer layers, instead of relying on the PyTorch autograd. reduce the memory usage of the <m>model</m> by using model and sequence parallelism, as described by Korthikanti et al. (2022). Moreover, we also overlap the computation of activations and the communication between GPUs over the network (due to all_reduce operations) as much as possible.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To further improve training efficiency, we reduced the amount of activations that are recomputed during the backward pass with checkpointing. More precisely, we save the activations that are expensive to compute, such as the outputs of linear layers. This is achieved by manually implementing the backward function for the transformer layers, instead of relying on the PyTorch autograd. reduce the memory usage of the model by using <m>model</m> and sequence parallelism, as described by Korthikanti et al. (2022). Moreover, we also overlap the computation of activations and the communication between GPUs over the network (due to all_reduce operations) as much as possible.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a <m>dataset</m> of 44K fine-grained masks from several sources.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of <m>44K fine-grained masks</m> from several sources.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a <m>dataset</m> of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. <m>HQ-SAM</m> is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "HQ-SAM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/SysCV/SAM-HQ",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced <m>detaset</m> of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of <m>HQ-SAM</m> in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "HQ-SAM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/SysCV/SAM-HQ",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation <m>datasets</m> across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our <m>code</m> and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SAM-HQ",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/SysCV/SAM-HQ",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and <m>models</m> will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SAM-HQ",
  "Version": "N/A",
  "License": "N/A",
  "URL": "https://github.com/SysCV/SAM-HQ",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced detaset of <m>44k masks</m>, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "To train our introduced learnable parameters, we compose a dataset of <m>44K fine-grained masks</m> from several sources. HQ-SAM is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol. Our code and models will be released at https://github.com/SysCV/SAM-HQ.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on <m>MNLI and SQuAD</m> with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MNLI | SQuAD",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "No | No"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on <m>MNLI</m> and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MNLI",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and <m>SQuAD</m> with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched <m>BERT</m> architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative <m>non-BERT pretrained language model</m> as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-<m>BERT</m> pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language <m>model</m> as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker <m>architecture</m>.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use <m>XLNet-large</m>(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use <m>XLNet</m>-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform <m>BERT</m>-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare <m>XLNet-large and BERT-large attacker</m> architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker | BERT-large attacker",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare <m>XLNet-large</m> and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare <m>XLNet</m>-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and <m>BERT</m>-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed <m>BERT-large</m> victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed <m>BERT</m>-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim <m>architecture</m>.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of <m>XLNet</m>-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker <m>models</m> on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XLNet-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on <m>SQuAD</m> compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "SQuAD",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to <m>BERT</m>-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large attacker",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (<m>BERT</m>-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-large victim",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language <m>models</m>, and that matching architectures is a secondary concern.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Tram\\u00e8r et al. (2016)racy using WIKI queries on MNLI and SQuAD with mismatched BERT architectures between the victim and attacker.Note the trend: (large, large) > (base, large) > (base, base) > (large, base) where the (\\u2022, \\u2022) refers to (victim, attacker) pretraining.Next, we experiment with an alternative non-BERT pretrained language model as the attacker architecture.We use XLNet-large(Yang et al., 2019), which has been shown to outperform BERT-large in a large variety of downstream NLP tasks.In Table5, we compare XLNet-large and BERT-large attacker architectures keeping a fixed BERT-large victim architecture.Note the superior performance of XLNet-large attacker models on SQuAD compared to BERT-large in both RANDOM and WIKI attack settings, despite seeing a mismatched victim's (BERT-large) outputs during training.Our experiments are reminiscent of similar discussion inTram\\u00e8r et al. (2016)on Occam Learning, or appropriate alignment of victim-attacker architectures. Overall, the results suggest that attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching <m>architectures</m> is a secondary concern.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We also experiment with another setting where the <m>TTS training data</m> is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the <m>TTS</m> training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training <m>data</m> is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English <m>test set</m>. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole <m>TTS training set</m> and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole <m>TTS</m> training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS <m>training set</m> and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training data",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training <m>set</m> and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the <m>TTS training set</m> for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS <m>training set</m> for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training <m>set</m> for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"<m>XPB</m>\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our <m>XPhoneBERT</m>. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two <m>models</m> is significant with p-value < 0.05). randomly sample 5% of the training audio clips, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We also experiment with another setting where the TTS training data is limited. In particular, for each language, we Table 2: Obtained results on the English test set. \\\"100%\\\" and \\\"5%\\\" denote the first experimental setting of using the whole TTS training set and the second experimental setting of using only 5% of the TTS training set for training, respectively. \\\"XPB\\\" abbreviates our XPhoneBERT. The MOS is reported with 95% confidence intervals (here, each MOS score difference between two models is significant with p-value < 0.05). randomly sample 5% of the <m>training audio clips</m>, and then only use those sampled audios for training (total duration of about 1.2 hours for English and about 0.9 hours for Vietnamese). We apply the same training protocol used for the first setting with an exception that we run for 100K training steps.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TTS training",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space <m>tokenizer</m>, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the fairseq library [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our <m>XPhoneBERT</m> thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the fairseq library [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training <m>XPhoneBERT</m> on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the fairseq library [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training <m>corpus</m>, we employ the RoBERTa implementation [11] from the fairseq library [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the <m>RoBERTa</m> implementation [11] from the fairseq library [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the <m>fairseq library</m> [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "fairseq",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the <m>fairseq</m> library [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "fairseq",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the fairseq <m>library</m> [29]. We set a maximum sequence length of 512. We optimize the model using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "fairseq",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the fairseq library [29]. We set a maximum sequence length of 512. We optimize the <m>model</m> using Adam [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We employ a white-space tokenizer, resulting in a vocabulary of 1960 phoneme types. Our XPhoneBERT thus has a total of 87.6M parameters. For training XPhoneBERT on our multilingual pre-training corpus, we employ the RoBERTa implementation [11] from the fairseq library [29]. We set a maximum sequence length of 512. We optimize the model using <m>Adam</m> [30] and use a batch size of 1024 sequence blocks across 8 A100 GPUs (40GB each) and a peak learning rate of 0.0001. We train for 20 epochs in about 18 days (here, the first 2 epochs are used for warming up the learning rate).",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Adam",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our <m>models</m> to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write <m>code</m> from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two <m>benchmarks</m>: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HumanEval | MBPP",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: <m>HumanEval (Chen et al., 2021) and MBPP</m> (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HumanEval | MBPP",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: <m>HumanEval</m> (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HumanEval",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and <m>MBPP</m> (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "MBPP",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the <m>model</m> receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In <m>HumanEval</m>, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "HumanEval",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural <m>code</m> with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a <m>MATH</m> +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Math",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k <m>PaLM 8B</m> docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM 8B",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k <m>PaLM</m> 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM 8B",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The <m>model</m> needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a <m>Python program</m> that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a <m>Python program</m> that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a <m>Python</m> program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Python",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python <m>program</m> that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our <m>models</m> with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language <m>models</m> that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM | LaMDA",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely <m>PaLM and LaMDA</m> (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM | LaMDA",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely <m>PaLM</m> and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and <m>LaMDA</m> (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LaMDA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). <m>PaLM and LLaMA</m> were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM | LLaMA",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). <m>PaLM</m> and LLaMA were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and <m>LLaMA</m> were trained on datasets that contain a similar number of code tokens.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLaMA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on <m>datasets</m> that contain a similar number of code tokens.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021). For both tasks, the model receives a description of the program in a few sentences, as well as a few input-output examples. In HumanEval, it also receives a function signature, and the prompt is formatted as natural code with the textual description and tests in a MATH +maj1@k GSM8k +maj1@k PaLM 8B docstring. The model needs to generate a Python program that fits the description and satisfies the test cases. In Table 8, we compare the pass@1 scores of our models with existing language models that have not been finetuned on code, namely PaLM and LaMDA (Thoppilan et al., 2022). PaLM and LLaMA were trained on datasets that contain a similar number of <m>code</m> tokens.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We introduce <m>LLaMA</m>, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLaMA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a <m>collection</m> of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language <m>models</m> ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLaMA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our <m>models</m> on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLaMA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art <m>models</m> using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available <m>datasets</m> exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible <m>datasets</m>. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, <m>LLaMA-13B</m> outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLaMA-13B",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms <m>GPT</m>-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GPT-3",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and <m>LLaMA-65B</m> is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLaMA-65B",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best <m>models</m>, Chinchilla-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Chinchilla-70B | PaLM-540B",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, <m>Chinchilla-70B and PaLM-540B</m>. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Chinchilla-70B | PaLM-540B",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, <m>Chinchilla</m>-70B and PaLM-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Chinchilla-70B",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and <m>PaLM</m>-540B. We release all our models to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "PaLM-540B",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our <m>models</m> to the research community 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LLaMA | LLaMA-13B | GPT-3 | LLaMA-65B",
  "Version": "N/A | N/A | N/A | N/A",
  "License": "N/A | N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A | N/A",
  "Ownership": "Yes | Yes | Yes | Yes",
  "Usage": "Yes | Yes | Yes | Yes"
 },
 {
  "Snippet": "We investigate multiple <m>techniques</m> to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural <m>network</m> based image classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based <m>image</m> classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification <m>pipeline</m>. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The <m>techniques</m> include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more <m>image</m> transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more image transformations to the training <m>data</m>, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary <m>models</m> applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution <m>images</m>. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the <m>Imagenet</m> Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our <m>system</m> achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techniques include adding more image transformations to the training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Vis ual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external <m>data</m> which is over a 20% relative improvement on the previous year's winner.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We present <m>XPhoneBERT</m>, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual <m>model</m> pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our <m>XPhoneBERT</m> has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same <m>model</m> architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model <m>architecture</m> as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as <m>BERT-base</m>, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as <m>BERT</m>-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the <m>RoBERTa</m> pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level <m>sentences</m> from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental <m>results</m> show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing <m>XPhoneBERT</m> as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input <m>phoneme encoder</m> significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong <m>neural TTS model</m> in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS <m>model</m> in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited <m>training data</m>. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training <m>data</m>. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained <m>XPhoneBERT</m> with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS <m>applications</m> for multiple languages.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We present XPhoneBERT, the first multilingual model pretrained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on <m>330M phoneme-level sentences</m> from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present the first large-scale pre-trained multilingual <m>model</m> for phoneme representations, which we name XPhoneBERT. \\u2022 On the downstream TTS task, XPhoneBERT helps significantly improve the performance of the strong baseline VITS, thus confirming its effectiveness.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present the first large-scale pre-trained multilingual model for phoneme representations, which we name <m>XPhoneBERT</m>. \\u2022 On the downstream TTS task, XPhoneBERT helps significantly improve the performance of the strong baseline VITS, thus confirming its effectiveness.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present the first large-scale pre-trained multilingual model for phoneme representations, which we name XPhoneBERT. \\u2022 On the downstream TTS task, <m>XPhoneBERT</m> helps significantly improve the performance of the strong baseline VITS, thus confirming its effectiveness.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present the first large-scale pre-trained multilingual model for phoneme representations, which we name XPhoneBERT. \\u2022 On the downstream TTS task, XPhoneBERT helps significantly improve the performance of the strong <m>baseline</m> VITS, thus confirming its effectiveness.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VITS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We present the first large-scale pre-trained multilingual model for phoneme representations, which we name XPhoneBERT. \\u2022 On the downstream TTS task, XPhoneBERT helps significantly improve the performance of the strong baseline <m>VITS</m>, thus confirming its effectiveness.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "VITS",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We show the efficacy of <m>HQ-SAM</m> in a suite of 9 diverse segmentation datasets across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "HQ-SAM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We show the efficacy of HQ-SAM in a suite of 9 diverse segmentation <m>datasets</m> across different downstream tasks, where 7 out of them are evaluated in a zero-shot transfer protocol.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "We study <m>model</m> extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against <m>NLP APIs</m> that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve <m>BERT-based models</m>. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve <m>BERT</m>-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based <m>models</m>. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good <m>models</m> with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language <m>models</m> simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve <m>model</m> distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input <m>data</m>; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing <m>dataset</m> complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between <m>victim models</m> as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim <m>models</m> as a method to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a <m>method</m> to identify proximity in input distribution and its incorporation into an active learning setup for model extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study model extraction attacks against NLP APIs that serve BERT-based models. These attacks are surprisingly effective at extracting good models with low query budgets, even when an attacker uses nonsensical input queries. Our results show that fine-tuning large pretrained language models simplifies the process of extraction for an attacker. Unfortunately, existing defenses against extraction, while effective in some scenarios, are generally inadequate, and further research is necessary to develop defenses robust in the face of adaptive adversaries who develop counter-attacks anticipating simple defenses. Other interesting future directions that follow from the results in this paper include (1) leveraging nonsensical inputs to improve model distillation on tasks for which it is difficult to procure input data; (2) diagnosing dataset complexity by using query efficiency as a proxy; and (3) further investigation of the agreement between victim models as a method to identify proximity in input distribution and its incorporation into an active learning setup for <m>model</m> extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of <m>model</m> extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim <m>model</m> attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that <m>model</m>. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the <m>adversary</m> and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and <m>victim model</m> fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim <m>model</m> fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language <m>model</m> such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as <m>BERT</m> (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the <m>adversary</m> does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training <m>data</m> to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for <m>model</m> extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning <m>methods</m> within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a <m>model</m> that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim <m>model</m>. Finally, we study two defense strategies against model extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against <m>model</m> extraction-membership classification and API watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al.,  2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction-membership classification and <m>API</m> watermarking-which while successful against naive adversaries, are ineffective against more sophisticated ones.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "With the recent success of contextualized pretrained representations for transfer learning, <m>NLP models</m> created by finetuning ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) have become increasingly popular (Gardner et al., 2018). Contextualized pretrained representations boost performance and reduce sample complexity (Yogatama et al., 2019), and typically require only a shallow task-specific network-sometimes just a single layer as in BERT. While these properties are advantageous for representation learning, we hypothesize that they also make model extraction easier.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "With the recent success of contextualized pretrained representations for transfer learning, NLP <m>models</m> created by finetuning ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) have become increasingly popular (Gardner et al., 2018). Contextualized pretrained representations boost performance and reduce sample complexity (Yogatama et al., 2019), and typically require only a shallow task-specific network-sometimes just a single layer as in BERT. While these properties are advantageous for representation learning, we hypothesize that they also make model extraction easier.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "With the recent success of contextualized pretrained representations for transfer learning, NLP models created by finetuning <m>ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019)</m> have become increasingly popular (Gardner et al., 2018). Contextualized pretrained representations boost performance and reduce sample complexity (Yogatama et al., 2019), and typically require only a shallow task-specific network-sometimes just a single layer as in BERT. While these properties are advantageous for representation learning, we hypothesize that they also make model extraction easier.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ELMo | BERT",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "No | No"
 },
 {
  "Snippet": "With the recent success of contextualized pretrained representations for transfer learning, NLP models created by finetuning <m>ELMo</m> (Peters et al., 2018) and BERT (Devlin et al., 2019) have become increasingly popular (Gardner et al., 2018). Contextualized pretrained representations boost performance and reduce sample complexity (Yogatama et al., 2019), and typically require only a shallow task-specific network-sometimes just a single layer as in BERT. While these properties are advantageous for representation learning, we hypothesize that they also make model extraction easier.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ELMo",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "With the recent success of contextualized pretrained representations for transfer learning, NLP models created by finetuning ELMo (Peters et al., 2018) and <m>BERT</m> (Devlin et al., 2019) have become increasingly popular (Gardner et al., 2018). Contextualized pretrained representations boost performance and reduce sample complexity (Yogatama et al., 2019), and typically require only a shallow task-specific network-sometimes just a single layer as in BERT. While these properties are advantageous for representation learning, we hypothesize that they also make model extraction easier.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "With the recent success of contextualized pretrained representations for transfer learning, NLP models created by finetuning ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) have become increasingly popular (Gardner et al., 2018). Contextualized pretrained representations boost performance and reduce sample complexity (Yogatama et al., 2019), and typically require only a shallow task-specific network-sometimes just a single layer as in <m>BERT</m>. While these properties are advantageous for representation learning, we hypothesize that they also make model extraction easier.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "With the recent success of contextualized pretrained representations for transfer learning, NLP models created by finetuning ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) have become increasingly popular (Gardner et al., 2018). Contextualized pretrained representations boost performance and reduce sample complexity (Yogatama et al., 2019), and typically require only a shallow task-specific network-sometimes just a single layer as in BERT. While these properties are advantageous for representation learning, we hypothesize that they also make <m>model</m> extraction easier.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "<m>XPhoneBERT</m> has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as <m>BERT</m>-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional <m>Transformer encoder</m> [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional <m>Transformer</m> encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer <m>encoder</m> [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT-base",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of <m>Transformer</m> blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train <m>XPhoneBERT</m>, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the <m>RoBERTa pre-training approach</m> [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the <m>RoBERTa</m> pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training <m>approach</m> [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa pre-training approach",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes <m>BERT</m> for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of <m>BERT and RoBERTa</m>, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT | RoBERTa",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "No | No"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of <m>BERT</m> and RoBERTa, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and <m>RoBERTa</m>, we do not further detail about the architecture here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RoBERTa",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "XPhoneBERT has the same model architecture as BERT-base [10]-a multi-layer bidirectional Transformer encoder [20]-in which the number of Transformer blocks, the hidden size and the number of self-attention heads are 12, 768 and 12, respectively. To pre-train XPhoneBERT, we use the masked language modeling objective [10] and follow the RoBERTa pre-training approach [11] which robustly optimizes BERT for better performance, i.e. using a dynamic masking strategy and without the next sentence prediction objective. Given the popularity of BERT and RoBERTa, we do not further detail about the <m>architecture</m> here. See [10,11] for more information.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "XPhoneBERT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "No"
 },
 {
  "Snippet": "Another direction is to apply the <m>method</m> to novel tasks and models. While an extension to sequence labeling is straightforward, other tasks with more complex interactions such as entailment or question answering may require novel ways to pretrain and fine-tune. Finally, while we have provided a series of analyses and ablations, more studies are required to better understand what knowledge a pretrained language model captures, how this changes during fine-tuning, and what information different tasks require.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Another direction is to apply the method to novel tasks and <m>models</m>. While an extension to sequence labeling is straightforward, other tasks with more complex interactions such as entailment or question answering may require novel ways to pretrain and fine-tune. Finally, while we have provided a series of analyses and ablations, more studies are required to better understand what knowledge a pretrained language model captures, how this changes during fine-tuning, and what information different tasks require.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Another direction is to apply the method to novel tasks and models. While an extension to sequence labeling is straightforward, other tasks with more complex interactions such as entailment or question answering may require novel ways to pretrain and fine-tune. Finally, while we have provided a series of analyses and ablations, more studies are required to better understand what knowledge a pretrained language <m>model</m> captures, how this changes during fine-tuning, and what information different tasks require.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "<m>BSIF</m> have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "BSIF have been used for several <m>applications</m> including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris <m>images</m> [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification <m>algorithm</m> using normalised NIR iris images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised <m>NIR iris images</m> is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NIR iris images",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised <m>NIR</m> iris images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NIR iris images",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR <m>iris</m> images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NIR iris images",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris <m>images</m> is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "NIR iris images",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris images is proposed. It uses a similar pipeline than <m>iris recognition systems</m>. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris images is proposed. It uses a similar pipeline than iris recognition <m>systems</m>. The iris is segmented and occlusions are masked. BSIF can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. <m>BSIF</m> can be sensitive to image boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "BSIF have been used for several applications including biometrics from iris images [17,12,24]. In this work, a gender classification algorithm using normalised NIR iris images is proposed. It uses a similar pipeline than iris recognition systems. The iris is segmented and occlusions are masked. BSIF can be sensitive to <m>image</m> boundaries and the occlusion mask creating artificial texture which may mislead gender classification results.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose <m>Universal Language Model Fine-tuning (ULMFiT)</m>, a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose <m>Universal Language Model Fine-tuning</m> (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (<m>ULMFiT</m>), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a <m>method</m> that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel <m>techniques</m> to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "discriminative fine-tuning | slanted triangular learning rates | gradual unfreezing",
  "Version": "N/A | N/A | N/A",
  "License": "N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A",
  "Ownership": "Yes | Yes | Yes",
  "Usage": "Yes | Yes | Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification <m>datasets</m>, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of <m>datasets</m>. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our <m>method</m> enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our code available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained <m>models and our code</m> available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A | N/A",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "Yes | Yes",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained <m>models</m> and our code available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Contributions Our contributions are the following: 1) We propose Universal Language Model Fine-tuning (ULMFiT), a method that can be used to achieve CV-like transfer learning for any task for NLP. 2) We propose discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing, novel techniques to retain previous knowledge and avoid catastrophic forgetting during fine-tuning. 3) We significantly outperform the state-of-the-art on six representative text classification datasets, with an error reduction of 18-24% on the majority of datasets. 4) We show that our method enables extremely sample-efficient transfer learning and perform an extensive ablation analysis. 5) We make the pretrained models and our <m>code</m> available to enable wider adoption.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "<m>Datasets</m> and tasks We evaluate our method on six widely-studied datasets, with varying numbers of documents and varying document length, used by state-of-the-art text classification and transfer learning approaches (Johnson and Zhang, 2017;McCann et al., 2017) as instances of three common text classification tasks: sentiment analysis, question classification, and topic classification. We show the statistics for each dataset and task in Table 1.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Datasets and tasks We evaluate our <m>method</m> on six widely-studied datasets, with varying numbers of documents and varying document length, used by state-of-the-art text classification and transfer learning approaches (Johnson and Zhang, 2017;McCann et al., 2017) as instances of three common text classification tasks: sentiment analysis, question classification, and topic classification. We show the statistics for each dataset and task in Table 1.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Datasets and tasks We evaluate our method on six widely-studied <m>datasets</m>, with varying numbers of documents and varying document length, used by state-of-the-art text classification and transfer learning approaches (Johnson and Zhang, 2017;McCann et al., 2017) as instances of three common text classification tasks: sentiment analysis, question classification, and topic classification. We show the statistics for each dataset and task in Table 1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Datasets and tasks We evaluate our method on six widely-studied datasets, with varying numbers of documents and varying document length, used by state-of-the-art text classification and transfer learning <m>approaches</m> (Johnson and Zhang, 2017;McCann et al., 2017) as instances of three common text classification tasks: sentiment analysis, question classification, and topic classification. We show the statistics for each dataset and task in Table 1.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Datasets and tasks We evaluate our method on six widely-studied datasets, with varying numbers of documents and varying document length, used by state-of-the-art text classification and transfer learning approaches (Johnson and Zhang, 2017;McCann et al., 2017) as instances of three common text classification tasks: sentiment analysis, question classification, and topic classification. We show the statistics for each <m>dataset</m> and task in Table 1.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Fine-tuning Fine-tuning has been used successfully to transfer between similar tasks, e.g. in QA (Min et al., 2017), for distantly supervised sentiment analysis (Severyn and Moschitti, 2015), or MT domains (Sennrich et al., 2015) but has been shown to fail between unrelated ones (Mou et al., 2016). Dai and Le (2015) also fine-tune a language <m>model</m>, but overfit with 10k labeled examples and require millions of in-domain documents for good performance. In contrast, ULMFiT leverages general-domain pretraining and novel finetuning techniques to prevent overfitting even with only 100 labeled examples and achieves state-ofthe-art results also on small datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Fine-tuning Fine-tuning has been used successfully to transfer between similar tasks, e.g. in QA (Min et al., 2017), for distantly supervised sentiment analysis (Severyn and Moschitti, 2015), or MT domains (Sennrich et al., 2015) but has been shown to fail between unrelated ones (Mou et al., 2016). Dai and Le (2015) also fine-tune a language model, but overfit with 10k labeled examples and require millions of in-domain documents for good performance. In contrast, <m>ULMFiT</m> leverages general-domain pretraining and novel finetuning techniques to prevent overfitting even with only 100 labeled examples and achieves state-ofthe-art results also on small datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ULMFiT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Fine-tuning Fine-tuning has been used successfully to transfer between similar tasks, e.g. in QA (Min et al., 2017), for distantly supervised sentiment analysis (Severyn and Moschitti, 2015), or MT domains (Sennrich et al., 2015) but has been shown to fail between unrelated ones (Mou et al., 2016). Dai and Le (2015) also fine-tune a language model, but overfit with 10k labeled examples and require millions of in-domain documents for good performance. In contrast, ULMFiT leverages general-domain pretraining and novel finetuning <m>techniques</m> to prevent overfitting even with only 100 labeled examples and achieves state-ofthe-art results also on small datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Fine-tuning Fine-tuning has been used successfully to transfer between similar tasks, e.g. in QA (Min et al., 2017), for distantly supervised sentiment analysis (Severyn and Moschitti, 2015), or MT domains (Sennrich et al., 2015) but has been shown to fail between unrelated ones (Mou et al., 2016). Dai and Le (2015) also fine-tune a language model, but overfit with 10k labeled examples and require millions of in-domain documents for good performance. In contrast, ULMFiT leverages general-domain pretraining and novel finetuning techniques to prevent overfitting even with only 100 labeled examples and achieves state-ofthe-art results also on small <m>datasets</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Fine-tuning Fine-tuning has been used successfully to transfer between similar tasks, e.g. in QA (Min et al., 2017), for distantly supervised sentiment analysis (Severyn and Moschitti, 2015), or MT domains (Sennrich et al., 2015) but has been shown to fail between unrelated ones (Mou et al., 2016). Dai and Le (2015) also fine-tune a language model, but overfit with 10k labeled examples and require millions of in-domain documents for good performance. In contrast, ULMFiT leverages general-domain pretraining and novel finetuning techniques to prevent overfitting even with only <m>100 labeled examples</m> and achieves state-ofthe-art results also on small datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Fine-tuning Fine-tuning has been used successfully to transfer between similar tasks, e.g. in QA (Min et al., 2017), for distantly supervised sentiment analysis (Severyn and Moschitti, 2015), or MT domains (Sennrich et al., 2015) but has been shown to fail between unrelated ones (Mou et al., 2016). Dai and Le (2015) also fine-tune a language model, but overfit with <m>10k labeled examples</m> and require millions of in-domain documents for good performance. In contrast, ULMFiT leverages general-domain pretraining and novel finetuning techniques to prevent overfitting even with only 100 labeled examples and achieves state-ofthe-art results also on small datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Gender classification based on <m>iris</m> images is promising despite challenging problems presented in terms of image analysis [20,36,30]. The human iris is an annular part between the pupil and the white sclera. The iris has an extraordinary structure and includes many interlacing minute features such as freckles, coronas, stripes, furrows, crypts and so on. These visible features, generally called the texture of the iris, are unique to each individual [1,10,11]. Research has also shown that the iris is essentially stable throughout a person's life. Furthermore, since the iris is externally visible, iris-based biometrics systems can be non-invasive to their users [10,11] which is important for practical applications. All these properties (i.e., uniqueness, stability and non-invasiveness) make gender classification suitable and attractive as a complement for achieving highly reliable personal identification.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Gender classification based on iris <m>images</m> is promising despite challenging problems presented in terms of image analysis [20,36,30]. The human iris is an annular part between the pupil and the white sclera. The iris has an extraordinary structure and includes many interlacing minute features such as freckles, coronas, stripes, furrows, crypts and so on. These visible features, generally called the texture of the iris, are unique to each individual [1,10,11]. Research has also shown that the iris is essentially stable throughout a person's life. Furthermore, since the iris is externally visible, iris-based biometrics systems can be non-invasive to their users [10,11] which is important for practical applications. All these properties (i.e., uniqueness, stability and non-invasiveness) make gender classification suitable and attractive as a complement for achieving highly reliable personal identification.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Gender classification based on iris images is promising despite challenging problems presented in terms of <m>image</m> analysis [20,36,30]. The human iris is an annular part between the pupil and the white sclera. The iris has an extraordinary structure and includes many interlacing minute features such as freckles, coronas, stripes, furrows, crypts and so on. These visible features, generally called the texture of the iris, are unique to each individual [1,10,11]. Research has also shown that the iris is essentially stable throughout a person's life. Furthermore, since the iris is externally visible, iris-based biometrics systems can be non-invasive to their users [10,11] which is important for practical applications. All these properties (i.e., uniqueness, stability and non-invasiveness) make gender classification suitable and attractive as a complement for achieving highly reliable personal identification.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Gender classification based on iris images is promising despite challenging problems presented in terms of image analysis [20,36,30]. The human iris is an annular part between the pupil and the white sclera. The iris has an extraordinary structure and includes many interlacing minute features such as freckles, coronas, stripes, furrows, crypts and so on. These visible features, generally called the texture of the iris, are unique to each individual [1,10,11]. Research has also shown that the iris is essentially stable throughout a person's life. Furthermore, since the iris is externally visible, iris-based biometrics <m>systems</m> can be non-invasive to their users [10,11] which is important for practical applications. All these properties (i.e., uniqueness, stability and non-invasiveness) make gender classification suitable and attractive as a complement for achieving highly reliable personal identification.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Gender classification based on iris images is promising despite challenging problems presented in terms of image analysis [20,36,30]. The human iris is an annular part between the pupil and the white sclera. The iris has an extraordinary structure and includes many interlacing minute features such as freckles, coronas, stripes, furrows, crypts and so on. These visible features, generally called the texture of the iris, are unique to each individual [1,10,11]. Research has also shown that the iris is essentially stable throughout a person's life. Furthermore, since the iris is externally visible, iris-based biometrics systems can be non-invasive to their users [10,11] which is important for practical <m>applications</m>. All these properties (i.e., uniqueness, stability and non-invasiveness) make gender classification suitable and attractive as a complement for achieving highly reliable personal identification.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In addition to performing the task of recognizing an individual [4], it is possible to predict attributes about the individual, such as gender, race and age, from the raw biometric <m>data</m> itself. These attributes are referred to as soft biometrics [5]. Soft biometric attributes may not be discriminative enough to uniquely identify an individual, but can be used to increase the recognition accuracy of a biometric system [6]. In addition to increased performance, there are several other motivating factors to glean these attributes from the raw biometric data.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In addition to performing the task of recognizing an individual [4], it is possible to predict attributes about the individual, such as gender, race and age, from the raw biometric data itself. These attributes are referred to as soft biometrics [5]. Soft biometric attributes may not be discriminative enough to uniquely identify an individual, but can be used to increase the recognition accuracy of a biometric <m>system</m> [6]. In addition to increased performance, there are several other motivating factors to glean these attributes from the raw biometric data.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In addition to performing the task of recognizing an individual [4], it is possible to predict attributes about the individual, such as gender, race and age, from the raw biometric data itself. These attributes are referred to as soft biometrics [5]. Soft biometric attributes may not be discriminative enough to uniquely identify an individual, but can be used to increase the recognition accuracy of a biometric system [6]. In addition to increased performance, there are several other motivating factors to glean these attributes from the raw biometric <m>data</m>.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) <m>framework</m> for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic <m>tools</m>. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic <m>framework</m> is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on <m>bidirectional long short-term memory (biLSTM) models</m>, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "biLSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on <m>bidirectional long short-term memory</m> (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "biLSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (<m>biLSTM</m>) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "biLSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) <m>models</m>, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "biLSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic <m>model</m> in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining <m>convolutional neural network</m> with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "convolutional neural network",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic <m>framework</m>. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention <m>mechanism</m> in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of <m>models</m> are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The <m>models</m> are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two <m>datasets</m>, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TREC-QA | InsuranceQA",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including <m>TREC-QA and InsuranceQA</m>. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TREC-QA | InsuranceQA",
  "Version": "N/A | N/A",
  "License": "N/A | N/A",
  "URL": "N/A | N/A",
  "Ownership": "No | No",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including <m>TREC-QA</m> and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "TREC-QA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and <m>InsuranceQA</m>. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "InsuranceQA",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed <m>models</m> substantially outperform several strong baselines.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong <m>baselines</m>.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification <m>method</m> is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised <m>iris</m> texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using <m>MBSIF</m>. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification <m>methods</m> and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the <m>BSIF algorithm</m> used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the <m>BSIF</m> algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF <m>algorithm</m> used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing <m>MBSIF algorithms</m>. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MBSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing <m>MBSIF</m> algorithms. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MBSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF <m>algorithms</m>. Experimental set-up and the results of gender classification using several classifiers and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MBSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several <m>classifiers</m> and MBSIF implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "In this work a gender classification method is proposed. It uses normalised iris texture information which is codified using MBSIF. The outline of this paper is as follows: Section 2 reviews the state of the art in gender classification methods and describes the BSIF algorithm used in this work. Section 3 describes the pipeline of this work and the challenges faced when implementing MBSIF algorithms. Experimental set-up and the results of gender classification using several classifiers and <m>MBSIF</m> implementation settings are shown in Section 4. Finally, the conclusions are presented in section 5.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "MBSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing <m>approaches</m> in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose <m>Universal Language Model Fine-tuning (ULMFiT)</m>, an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose <m>Universal Language Model Fine-tuning</m> (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (<m>ULMFiT</m>), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning <m>method</m> that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce <m>techniques</m> that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language <m>model</m>. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our <m>method</m> significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Universal Language Model Fine-tuning (ULMFiT)",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of <m>datasets</m>. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more <m>data</m>. We opensource our pretrained models and code 1 .",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained <m>models and code</m> 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A | N/A",
  "Version": "N/A | N/A",
  "License": "opensource | opensource",
  "URL": "N/A | N/A",
  "Ownership": "Yes | Yes",
  "Usage": "Yes | Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained <m>models</m> and code 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and <m>code</m> 1 .",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "opensource",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only <m>100 labeled examples</m>, it matches the performance of training from scratch on 100\\u00d7 more data. We opensource our pretrained models and code 1 .",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to <m>NIR iris images</m> have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR <m>iris</m> images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris <m>images</m> have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular <m>image</m> (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, <m>algorithms</m> for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the <m>Binarized Statistical Image Feature (BSIF) descriptor</m> has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binarized Statistical Image Feature (BSIF) descriptor",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the <m>Binarized Statistical Image Feature</m> (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binarized Statistical Image Feature (BSIF) descriptor",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical <m>Image</m> Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (<m>BSIF</m>) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binarized Statistical Image Feature (BSIF) descriptor",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) <m>descriptor</m> has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binarized Statistical Image Feature (BSIF) descriptor",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition <m>systems</m> provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone <m>algorithm</m> for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the <m>BSIF</m> code computed from NIR ocular images.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binarized Statistical Image Feature (BSIF) descriptor",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Most biometric recognition work pertaining to NIR iris images have focused on extracting the iris region from the captured ocular image (see Figure 1). Thus, algorithms for soft biometric prediction have typically focused on the iris region rather than the extended ocular region (see Figure 4). Recent work [28] based on the Binarized Statistical Image Feature (BSIF) descriptor has shown that the extended ocular region commonly imaged by iris recognition systems provides greater sex prediction accuracy than the iris-only region. Predicting soft biometric attributes from the ocular region provides one major advantage over the iris region in that it does not require a potentially error prone algorithm for iris region extraction. Bobeldyk and Ross [28] were able to achieve an 85.7% sex prediction accuracy using concatenated histograms from tesselated regions of the BSIF code computed from NIR ocular <m>images</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art <m>approaches</m>-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples <m>test set</m>. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test <m>set</m>. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our <m>model</m> performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different <m>dataset</m> sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for <m>IMDb</m>. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less <m>data</m> than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their <m>approach</m> on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the 7 million sentence pairs used by McCann et al. (2017), we consistently outperform their approach on both <m>datasets</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On TREC-6, our improvement-similar as the improvements of state-of-the-art approaches-is not statistically significant, due to the small size of the 500-examples test set. Nevertheless, the competitive performance on TREC-6 demonstrates that our model performs well across different dataset sizes and can deal with examples that range from single sentences-in the case of TREC-6to several paragraphs for IMDb. Note that despite pretraining on more than two orders of magnitude less data than the <m>7 million sentence pairs</m> used by McCann et al. (2017), we consistently outperform their approach on both datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "On all <m>datasets</m>, fine-tuning the full model leads to the lowest error comparatively early in training, e.g. already after the first epoch on IMDb. The error then increases as the model starts to overfit and knowledge captured through pretraining is lost. In contrast, ULMFiT is more stable and suffers from no such catastrophic forgetting; performance remains similar or improves until late epochs, which shows the positive effect of the learning rate schedule.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On all datasets, fine-tuning the full <m>model</m> leads to the lowest error comparatively early in training, e.g. already after the first epoch on IMDb. The error then increases as the model starts to overfit and knowledge captured through pretraining is lost. In contrast, ULMFiT is more stable and suffers from no such catastrophic forgetting; performance remains similar or improves until late epochs, which shows the positive effect of the learning rate schedule.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On all datasets, fine-tuning the full model leads to the lowest error comparatively early in training, e.g. already after the first epoch on <m>IMDb</m>. The error then increases as the model starts to overfit and knowledge captured through pretraining is lost. In contrast, ULMFiT is more stable and suffers from no such catastrophic forgetting; performance remains similar or improves until late epochs, which shows the positive effect of the learning rate schedule.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On all datasets, fine-tuning the full model leads to the lowest error comparatively early in training, e.g. already after the first epoch on IMDb. The error then increases as the <m>model</m> starts to overfit and knowledge captured through pretraining is lost. In contrast, ULMFiT is more stable and suffers from no such catastrophic forgetting; performance remains similar or improves until late epochs, which shows the positive effect of the learning rate schedule.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "On all datasets, fine-tuning the full model leads to the lowest error comparatively early in training, e.g. already after the first epoch on IMDb. The error then increases as the model starts to overfit and knowledge captured through pretraining is lost. In contrast, <m>ULMFiT</m> is more stable and suffers from no such catastrophic forgetting; performance remains similar or improves until late epochs, which shows the positive effect of the learning rate schedule.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "ULMFiT",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification <m>algorithms</m> are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Adaboost M1 | LogitBoost | GentleBoost | RobustBoost | LP-Boost | TotalBoost | RusBoost | Random Forest | Gini Index | LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "License": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "Ownership": "No | No | No | No | No | No | No | No | No | No",
  "Usage": "Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from <m>iris texture images</m>. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from <m>iris</m> texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture <m>images</m>. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those <m>algorithms</m> are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Adaboost M1 | LogitBoost | GentleBoost | RobustBoost | LP-Boost | TotalBoost | RusBoost | Random Forest | Gini Index | LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "License": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "Ownership": "No | No | No | No | No | No | No | No | No | No",
  "Usage": "Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: <m>Adaboost M1</m>, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Adaboost M1",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, <m>LogitBoost</m>, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LogitBoost",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, <m>GentleBoost</m>, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "GentleBoost",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, <m>RobustBoost</m>, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RobustBoost",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, <m>LP-Boost</m>, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LP-Boost",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, <m>TotalBoost</m> and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "TotalBoost",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and <m>RusBoost</m>. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "RusBoost",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a <m>Random Forest classifier</m> with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Random Forest classifier",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a <m>Gini Index</m>, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Gini Index",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a <m>LIB-SVM classifier</m> with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a <m>LIB-SVM</m> classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-<m>SVM</m> classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM <m>classifier</m> with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (<m>RBF</m>) were also used. A comparison of the results obtained with these classifiers is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Several classification algorithms are used to test gender information from iris texture images. Those algorithms are: Adaboost M1, LogitBoost, GentleBoost, RobustBoost, LP-Boost, TotalBoost and RusBoost. Additionally, a Random Forest classifier with 500 trees, a Gini Index, and a LIB-SVM classifier with Gaussian Kernel (RBF) were also used. A comparison of the results obtained with these <m>classifiers</m> is shown in section 4.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Adaboost M1 | LogitBoost | GentleBoost | RobustBoost | LP-Boost | TotalBoost | RusBoost | Random Forest | Gini Index | LIB-SVM classifier with Gaussian Kernel (RBF)",
  "Version": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "License": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "URL": "N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A",
  "Ownership": "No | No | No | No | No | No | No | No | No | No",
  "Usage": "Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes | Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many <m>applications</m> like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a <m>Binary Statistical Features (BSIF) algorithm</m> for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binary Statistical Features",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a <m>Binary Statistical Features (BSIF)</m> algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binary Statistical Features",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (<m>BSIF</m>) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binary Statistical Features",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) <m>algorithm</m> for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binary Statistical Features",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from <m>iris</m> texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture <m>images</m> captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for <m>iris</m> recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition <m>systems</m> consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying <m>BSIF</m> is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Binary Statistical Features",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye <m>images</m> and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a <m>subject-disjoint database</m>. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint <m>database</m>. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A <m>Modified-BSIF (MBSIF) method</m> was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Modified-BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A <m>Modified-BSIF (MBSIF)</m> method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Modified-BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (<m>MBSIF</m>) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Modified-BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) <m>method</m> was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Modified-BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The <m>latter</m> achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled database was created and it will be available upon request.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Modified-BSIF",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "Soft biometric information such as gender can contribute to many applications like as identification and security. This paper explores the use of a Binary Statistical Features (BSIF) algorithm for classifying gender from iris texture images captured with NIR sensors. It uses the same pipeline for iris recognition systems consisting of iris segmentation, normalisation and then classification. Experiments show that applying BSIF is not straightforward since it can create artificial textures causing misclassification. In order to overcome this limitation, a new set of filters was trained from eye images and different sized filters with padding bands were tested on a subject-disjoint database. A Modified-BSIF (MBSIF) method was implemented. The latter achieved better gender classification results (94.6% and 91.33% for the left and right eye respectively). These results are competitive with the state of the art in gender classification. In an additional contribution, a novel gender labelled <m>database</m> was created and it will be available upon request.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The answer selection problem can be formulated as follows: Given a question q and an answer candidate pool {a 1 , a 2 , \\u2022 \\u2022 \\u2022 , a s } for this question, we aim to search for the best answer candidate a k , where 1 \\u2264 k \\u2264 s. An answer is a token sequence with an arbitrary length, and a question can correspond to multiple ground-truth answers. In testing, the candidate answers for a question may not be observed in the training phase. Answer selection is one of the essential <m>components</m> in typical question answering (QA) systems. It is also a stand-alone task with applications in knowledge base construction and information extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The answer selection problem can be formulated as follows: Given a question q and an answer candidate pool {a 1 , a 2 , \\u2022 \\u2022 \\u2022 , a s } for this question, we aim to search for the best answer candidate a k , where 1 \\u2264 k \\u2264 s. An answer is a token sequence with an arbitrary length, and a question can correspond to multiple ground-truth answers. In testing, the candidate answers for a question may not be observed in the training phase. Answer selection is one of the essential components in typical question answering (QA) <m>systems</m>. It is also a stand-alone task with applications in knowledge base construction and information extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The answer selection problem can be formulated as follows: Given a question q and an answer candidate pool {a 1 , a 2 , \\u2022 \\u2022 \\u2022 , a s } for this question, we aim to search for the best answer candidate a k , where 1 \\u2264 k \\u2264 s. An answer is a token sequence with an arbitrary length, and a question can correspond to multiple ground-truth answers. In testing, the candidate answers for a question may not be observed in the training phase. Answer selection is one of the essential components in typical question answering (QA) systems. It is also a stand-alone task with <m>applications</m> in knowledge base construction and information extraction.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The answer selection problem can be formulated as follows: Given a question q and an answer candidate pool {a 1 , a 2 , \\u2022 \\u2022 \\u2022 , a s } for this question, we aim to search for the best answer candidate a k , where 1 \\u2264 k \\u2264 s. An answer is a token sequence with an arbitrary length, and a question can correspond to multiple ground-truth answers. In testing, the candidate answers for a question may not be observed in the training phase. Answer selection is one of the essential components in typical question answering (QA) systems. It is also a stand-alone task with applications in <m>knowledge base</m> construction and information extraction.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the <m>bidirectional LSTM models</m> must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "bidirectional LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the <m>bidirectional LSTM</m> models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "bidirectional LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional <m>LSTM</m> models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "bidirectional LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM <m>models</m> must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "bidirectional LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM models must propagate dependencies over long distances over the questions and answers. An attention <m>mechanism</m> are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. <m>Inspired</m> by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level <m>attention</m> on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic <m>model</m>. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each <m>biLSTM</m> output vector will be multiplied by a softmax weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "biLSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a <m>softmax</m> weight, which is determined by the question embedding from biLSTM.\"",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "The fixed width of hidden vectors becomes a bottleneck, when the bidirectional LSTM models must propagate dependencies over long distances over the questions and answers. An attention mechanism are used to alleviate this weakness by dynamically aligning the more informative parts of answers to the questions. This strategy has been used in many other natural language processing tasks, such as machine translation , sentence summarization  and factoid question answering. Inspired by the work , we develop a very simple but efficient word-level attention on the basic model. Figure 3 shows the structure. Prior to the average or mean pooling, each biLSTM output vector will be multiplied by a softmax weight, which is determined by the question embedding from <m>biLSTM</m>.\"",
  "Type": "software",
  "Valid": "Yes",
  "Name": "biLSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial <m>software</m> Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that iris images of different persons, or even the left and right iris images for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "Osiris",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris <m>image</m> which are not useful for gender classification. It is important to note that iris images of different persons, or even the left and right iris images for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that <m>iris images</m> of different persons, or even the left and right iris images for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that <m>iris</m> images of different persons, or even the left and right iris images for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that iris <m>images</m> of different persons, or even the left and right iris images for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that iris images of different persons, or even the left and right <m>iris images</m> for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that iris images of different persons, or even the left and right <m>iris</m> images for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that iris images of different persons, or even the left and right iris <m>images</m> for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the image. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The iris is detected from the input image using commercial software Osiris [23]. A segmentation mask occludes the eyelids, eyelashes and specular reflection portions of the iris image which are not useful for gender classification. It is important to note that iris images of different persons, or even the left and right iris images for a given person, may not present exactly the same mask and imaging conditions (see Figure 2). Illumination by LEDs during capture may come from either side of the sensor, specular highlights may be present in different places in the <m>image</m>. Eyelid and head position may also affect segmentation.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the <m>biLSTM</m> hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-LSTM/CNN with attention can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "biLSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of <m>CNN</m> structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-LSTM/CNN with attention can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of <m>CNN</m>. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-LSTM/CNN with attention can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "CNN",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different <m>datasets</m>. However, QA-LSTM/CNN with attention can outperform the baselines on both datasets.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, <m>QA-LSTM/CNN with attention</m> can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QA-LSTM/CNN with attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, <m>QA-LSTM/CNN</m> with attention can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QA-LSTM/CNN with attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-<m>LSTM/CNN</m> with attention can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QA-LSTM/CNN with attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-<m>LSTM</m>/CNN with attention can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QA-LSTM/CNN with attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-LSTM/<m>CNN</m> with attention can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QA-LSTM/CNN with attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-LSTM/CNN with <m>attention</m> can outperform the baselines on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "QA-LSTM/CNN with attention",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "Yes",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-LSTM/CNN with attention can outperform the <m>baselines</m> on both datasets.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "The two extensions introduced previously are combined in a simple manner. First, the biLSTM hidden vectors of answers h a (t) are multiplied by s a,q (t), which is computed from the question average pooling vectors o q , and updated to h a (t), illustrated in Eq. 9-11. Then, the original question and updated answer hidden vectors serve as inputs of CNN structure respectively, such that the question context can be used to evaluate the softmax weights of the input of CNN. From the experiments, we observe that the two extensions vary on their contributions on the performance improvement according to different datasets. However, QA-LSTM/CNN with attention can outperform the baselines on both <m>datasets</m>.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the <m>IMDb validation set</m>. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the <m>IMDb</m> validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb <m>validation set</m>. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation <m>set</m>. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "dataset",
  "Valid": "Yes",
  "Name": "IMDb",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the <m>AWD-LSTM language model</m> (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "AWD-LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the <m>AWD-LSTM</m> language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "WAD-LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-<m>LSTM</m> language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "AWD-LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language <m>model</m> (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "AWD-LSTM",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "Yes"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply <m>dropout</m> of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to <m>RNN</m> layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input <m>embedding</m> layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to <m>embedding</m> layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight <m>dropout</m> of 0.5 to the RNN hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the <m>RNN</m> hidden-to-hidden matrix. The classifier has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "To this end, if not mentioned otherwise, we use the same set of hyperparameters across tasks, which we tune on the IMDb validation set. We use the AWD-LSTM language model (Merity et al., 2017a) with an embedding size of 400, 3 layers, 1150 hidden activations per layer, and a BPTT batch size of 70. We apply dropout of 0.4 to layers, 0.3 to RNN layers, 0.4 to input embedding layers, 0.05 to embedding layers, and weight dropout of 0.5 to the RNN hidden-to-hidden matrix. The <m>classifier</m> has a hidden layer of size 50.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Whenever people log onto computers, access an ATM, pass through airport security, use credit cards, or enter highsecurity areas, their identities need to be verified [5,6]. There is tremendous interest in reliable and secure identification <m>methods</m>. An active research area of this involves gender classification. Algorithms for automatic gender classification have several applications. They can be used for database binning and retrieval, for intelligent user interfaces or visual surveillance. They can also be used to provide demographic information to improve social services, to facilitate payment methods and for marketing applications in general.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Whenever people log onto computers, access an ATM, pass through airport security, use credit cards, or enter highsecurity areas, their identities need to be verified [5,6]. There is tremendous interest in reliable and secure identification methods. An active research area of this involves gender classification. <m>Algorithms</m> for automatic gender classification have several applications. They can be used for database binning and retrieval, for intelligent user interfaces or visual surveillance. They can also be used to provide demographic information to improve social services, to facilitate payment methods and for marketing applications in general.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Whenever people log onto computers, access an ATM, pass through airport security, use credit cards, or enter highsecurity areas, their identities need to be verified [5,6]. There is tremendous interest in reliable and secure identification methods. An active research area of this involves gender classification. Algorithms for automatic gender classification have several <m>applications</m>. They can be used for database binning and retrieval, for intelligent user interfaces or visual surveillance. They can also be used to provide demographic information to improve social services, to facilitate payment methods and for marketing applications in general.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Whenever people log onto computers, access an ATM, pass through airport security, use credit cards, or enter highsecurity areas, their identities need to be verified [5,6]. There is tremendous interest in reliable and secure identification methods. An active research area of this involves gender classification. Algorithms for automatic gender classification have several applications. They can be used for <m>database</m> binning and retrieval, for intelligent user interfaces or visual surveillance. They can also be used to provide demographic information to improve social services, to facilitate payment methods and for marketing applications in general.",
  "Type": "dataset",
  "Valid": "No"
 },
 {
  "Snippet": "Whenever people log onto computers, access an ATM, pass through airport security, use credit cards, or enter highsecurity areas, their identities need to be verified [5,6]. There is tremendous interest in reliable and secure identification methods. An active research area of this involves gender classification. Algorithms for automatic gender classification have several applications. They can be used for database binning and retrieval, for intelligent user <m>interfaces</m> or visual surveillance. They can also be used to provide demographic information to improve social services, to facilitate payment methods and for marketing applications in general.",
  "Type": "software",
  "Valid": "Yes",
  "Name": "N/A",
  "Version": "N/A",
  "License": "N/A",
  "URL": "N/A",
  "Ownership": "No",
  "Usage": "No"
 },
 {
  "Snippet": "Whenever people log onto computers, access an ATM, pass through airport security, use credit cards, or enter highsecurity areas, their identities need to be verified [5,6]. There is tremendous interest in reliable and secure identification methods. An active research area of this involves gender classification. Algorithms for automatic gender classification have several applications. They can be used for database binning and retrieval, for intelligent user interfaces or visual surveillance. They can also be used to provide demographic information to improve social services, to facilitate payment <m>methods</m> and for marketing applications in general.",
  "Type": "software",
  "Valid": "No"
 },
 {
  "Snippet": "Whenever people log onto computers, access an ATM, pass through airport security, use credit cards, or enter highsecurity areas, their identities need to be verified [5,6]. There is tremendous interest in reliable and secure identification methods. An active research area of this involves gender classification. Algorithms for automatic gender classification have several applications. They can be used for database binning and retrieval, for intelligent user interfaces or visual surveillance. They can also be used to provide demographic information to improve social services, to facilitate payment methods and for marketing <m>applications</m> in general.",
  "Type": "software",
  "Valid": "No"
 }
]